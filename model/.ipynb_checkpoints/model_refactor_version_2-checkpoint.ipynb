{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, GraphConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC DATA**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([72790024141, 72785524114, 72789094197, 72793024233, 72785794129, 72788594266, 72797624217, 72785024157, 72797094240, 72798594276, 72792424223, 72792894263, 72781024243, 72781524237, 72788324220, 72698824219, 72793894274, 74206024207, 72782724110, 72793724222, 72792594227, 72782594239, 72794504205, 72792394225, 72784524163, 72792024227, 72785694176])\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the CSV files\n",
    "directory = '../processed-final-data-2'\n",
    "\n",
    "# Dictionary to store the dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the file name without extension and convert it to int\n",
    "        key = int(os.path.splitext(filename)[0])\n",
    "        \n",
    "        # Read the CSV file into a dataframe\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        dataframes[key] = df\n",
    "\n",
    "\n",
    "# Print the dictionary keys to verify\n",
    "print(dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72790024141: Sequential split verified.\n",
      "72785524114: Sequential split verified.\n",
      "72789094197: Sequential split verified.\n",
      "72793024233: Sequential split verified.\n",
      "72785794129: Sequential split verified.\n",
      "72788594266: Sequential split verified.\n",
      "72797624217: Sequential split verified.\n",
      "72785024157: Sequential split verified.\n",
      "72797094240: Sequential split verified.\n",
      "72798594276: Sequential split verified.\n",
      "72792424223: Sequential split verified.\n",
      "72792894263: Sequential split verified.\n",
      "72781024243: Sequential split verified.\n",
      "72781524237: Sequential split verified.\n",
      "72788324220: Sequential split verified.\n",
      "72698824219: Sequential split verified.\n",
      "72793894274: Sequential split verified.\n",
      "74206024207: Sequential split verified.\n",
      "72782724110: Sequential split verified.\n",
      "72793724222: Sequential split verified.\n",
      "72792594227: Sequential split verified.\n",
      "72782594239: Sequential split verified.\n",
      "72794504205: Sequential split verified.\n",
      "72792394225: Sequential split verified.\n",
      "72784524163: Sequential split verified.\n",
      "72792024227: Sequential split verified.\n",
      "72785694176: Sequential split verified.\n",
      "dict_keys([72790024141, 72785524114, 72789094197, 72793024233, 72785794129, 72788594266, 72797624217, 72785024157, 72797094240, 72798594276, 72792424223, 72792894263, 72781024243, 72781524237, 72788324220, 72698824219, 72793894274, 74206024207, 72782724110, 72793724222, 72792594227, 72782594239, 72794504205, 72792394225, 72784524163, 72792024227, 72785694176])\n",
      "dict_keys([72790024141, 72785524114, 72789094197, 72793024233, 72785794129, 72788594266, 72797624217, 72785024157, 72797094240, 72798594276, 72792424223, 72792894263, 72781024243, 72781524237, 72788324220, 72698824219, 72793894274, 74206024207, 72782724110, 72793724222, 72792594227, 72782594239, 72794504205, 72792394225, 72784524163, 72792024227, 72785694176])\n"
     ]
    }
   ],
   "source": [
    "# Dictionaries to store the training and testing dataframes\n",
    "train_dataframes = {}\n",
    "test_dataframes = {}\n",
    "\n",
    "# Split each dataframe into training and testing sets\n",
    "for key, df in dataframes.items():\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "    train_dataframes[key] = train_df\n",
    "    test_dataframes[key] = test_df\n",
    "    # Check if the maximum index of the training set is less than the minimum index of the testing set\n",
    "    if train_df.index.max() < test_df.index.min():\n",
    "        print(f\"{key}: Sequential split verified.\")\n",
    "    else:\n",
    "        print(f\"{key}: Sequential split NOT verified.\")\n",
    "\n",
    "# Print the keys of the training and testing dictionaries to verify\n",
    "print(train_dataframes.keys())\n",
    "print(test_dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1408, 27, 69])\n",
      "torch.Size([352, 27, 67])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.7213e-02, 9.9985e-01, 3.4560e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.7213e-02, 9.9985e-01, 3.7971e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.7213e-02, 9.9985e-01, 3.1885e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [1.7213e-02, 9.9985e-01, 3.7875e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.7213e-02, 9.9985e-01, 4.4333e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.7213e-02, 9.9985e-01, 3.4931e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[30.0000, 37.8485, 76.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [29.4688, 34.1875, 84.7500,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [26.5385, 38.6923, 63.0769,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        ...,\n",
       "        [36.7083, 46.0833, 61.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [41.2553, 43.7660, 90.9362,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [28.3333, 36.7778, 92.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_node_features_sequences(dataframes):\n",
    "    # Create a list to store the node features for each time step for input and desired output\n",
    "    node_features_sequence_input = []\n",
    "    node_features_sequence_output = []\n",
    "\n",
    "    # Iterate over the rows of the dataframes (assuming all dataframes have the same number of rows)\n",
    "    for i in range(len(next(iter(dataframes.values())))):\n",
    "        if i == len(next(iter(dataframes.values()))) - 1:\n",
    "            break\n",
    "        # Create a list to store the features of all nodes at the current time step for input\n",
    "        node_features_input = []\n",
    "        # Create a list to store the features of all nodes at the next time step for output\n",
    "        node_features_output = []\n",
    "\n",
    "        # Iterate over each dataframe and extract the features at the current row for input\n",
    "        # and the next row for output\n",
    "        for key, df in dataframes.items():\n",
    "            node_features_input.append(df.iloc[i].values)\n",
    "            node_features_output.append(df.iloc[i + 1].drop(['DayOfYear_sin', 'DayOfYear_cos']).values)\n",
    "\n",
    "        # Stack the features of all nodes to create a 2D array (num_nodes, num_features)\n",
    "        node_features_sequence_input.append(np.stack(node_features_input))\n",
    "        node_features_sequence_output.append(np.stack(node_features_output))\n",
    "\n",
    "    # Convert the lists to numpy arrays (time_steps, num_nodes, num_features)\n",
    "    node_features_sequence_input = np.array(node_features_sequence_input)\n",
    "    node_features_sequence_output = np.array(node_features_sequence_output)\n",
    "\n",
    "    # Convert the numpy arrays to torch tensors\n",
    "    node_features_sequence_input = torch.tensor(node_features_sequence_input, dtype=torch.float)\n",
    "    node_features_sequence_output = torch.tensor(node_features_sequence_output, dtype=torch.float)\n",
    "\n",
    "    return node_features_sequence_input, node_features_sequence_output\n",
    "\n",
    "# Call the function and print the shapes of the resulting tensors\n",
    "node_features_sequence_input_train, node_features_sequence_output_train = create_node_features_sequences(train_dataframes)\n",
    "node_features_sequence_input_test, node_features_sequence_output_test = create_node_features_sequences(test_dataframes)\n",
    "print(node_features_sequence_input_train.shape)\n",
    "print(node_features_sequence_output_test.shape)\n",
    "display(node_features_sequence_input_train[0])\n",
    "display(node_features_sequence_output_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC EDGE DATA**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        STATION  LONGITUDE  LATITUDE  ELEVATION\n",
      "0  7.279002e+10 -119.51551  47.30777      382.1\n",
      "1  7.278552e+10 -117.65000  47.63333      750.1\n",
      "2  7.278909e+10 -119.52091  48.46113      397.4\n",
      "3  7.279302e+10 -122.31442  47.44467      112.5\n",
      "4  7.278579e+10 -117.11581  46.74376      775.7\n"
     ]
    }
   ],
   "source": [
    "# Import the location-datamap.csv file as a dataframe\n",
    "location_datamap_df = pd.read_csv('../location-datamap.csv')\n",
    "\n",
    "# Print the first few rows of the dataframe to verify\n",
    "print(location_datamap_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2, el1=0, el2=0):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Difference in coordinates\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Haversine formula\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "\n",
    "    # Elevation difference\n",
    "    height = el2 - el1\n",
    "\n",
    "    # Calculate the total distance considering elevation\n",
    "    total_distance = sqrt(distance**2 + height**2)\n",
    "\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[72790024141, 72785524114, 0, 1],\n",
       " [72785524114, 72790024141, 1, 0],\n",
       " [72790024141, 72789094197, 0, 2],\n",
       " [72789094197, 72790024141, 2, 0],\n",
       " [72790024141, 72793024233, 0, 3],\n",
       " [72793024233, 72790024141, 3, 0],\n",
       " [72790024141, 72785794129, 0, 4],\n",
       " [72785794129, 72790024141, 4, 0],\n",
       " [72790024141, 72788594266, 0, 5],\n",
       " [72788594266, 72790024141, 5, 0],\n",
       " [72790024141, 72797624217, 0, 6],\n",
       " [72797624217, 72790024141, 6, 0],\n",
       " [72790024141, 72785024157, 0, 7],\n",
       " [72785024157, 72790024141, 7, 0],\n",
       " [72790024141, 72797094240, 0, 8],\n",
       " [72797094240, 72790024141, 8, 0],\n",
       " [72790024141, 72798594276, 0, 9],\n",
       " [72798594276, 72790024141, 9, 0],\n",
       " [72790024141, 72792424223, 0, 10],\n",
       " [72792424223, 72790024141, 10, 0],\n",
       " [72790024141, 72792894263, 0, 11],\n",
       " [72792894263, 72790024141, 11, 0],\n",
       " [72790024141, 72781024243, 0, 12],\n",
       " [72781024243, 72790024141, 12, 0],\n",
       " [72790024141, 72781524237, 0, 13],\n",
       " [72781524237, 72790024141, 13, 0],\n",
       " [72790024141, 72788324220, 0, 14],\n",
       " [72788324220, 72790024141, 14, 0],\n",
       " [72790024141, 72698824219, 0, 15],\n",
       " [72698824219, 72790024141, 15, 0],\n",
       " [72790024141, 72793894274, 0, 16],\n",
       " [72793894274, 72790024141, 16, 0],\n",
       " [72790024141, 74206024207, 0, 17],\n",
       " [74206024207, 72790024141, 17, 0],\n",
       " [72790024141, 72782724110, 0, 18],\n",
       " [72782724110, 72790024141, 18, 0],\n",
       " [72790024141, 72793724222, 0, 19],\n",
       " [72793724222, 72790024141, 19, 0],\n",
       " [72790024141, 72792594227, 0, 20],\n",
       " [72792594227, 72790024141, 20, 0],\n",
       " [72790024141, 72782594239, 0, 21],\n",
       " [72782594239, 72790024141, 21, 0],\n",
       " [72790024141, 72794504205, 0, 22],\n",
       " [72794504205, 72790024141, 22, 0],\n",
       " [72790024141, 72792394225, 0, 23],\n",
       " [72792394225, 72790024141, 23, 0],\n",
       " [72790024141, 72784524163, 0, 24],\n",
       " [72784524163, 72790024141, 24, 0],\n",
       " [72790024141, 72792024227, 0, 25],\n",
       " [72792024227, 72790024141, 25, 0],\n",
       " [72790024141, 72785694176, 0, 26],\n",
       " [72785694176, 72790024141, 26, 0],\n",
       " [72785524114, 72789094197, 1, 2],\n",
       " [72789094197, 72785524114, 2, 1],\n",
       " [72785524114, 72793024233, 1, 3],\n",
       " [72793024233, 72785524114, 3, 1],\n",
       " [72785524114, 72785794129, 1, 4],\n",
       " [72785794129, 72785524114, 4, 1],\n",
       " [72785524114, 72788594266, 1, 5],\n",
       " [72788594266, 72785524114, 5, 1],\n",
       " [72785524114, 72797624217, 1, 6],\n",
       " [72797624217, 72785524114, 6, 1],\n",
       " [72785524114, 72785024157, 1, 7],\n",
       " [72785024157, 72785524114, 7, 1],\n",
       " [72785524114, 72797094240, 1, 8],\n",
       " [72797094240, 72785524114, 8, 1],\n",
       " [72785524114, 72798594276, 1, 9],\n",
       " [72798594276, 72785524114, 9, 1],\n",
       " [72785524114, 72792424223, 1, 10],\n",
       " [72792424223, 72785524114, 10, 1],\n",
       " [72785524114, 72792894263, 1, 11],\n",
       " [72792894263, 72785524114, 11, 1],\n",
       " [72785524114, 72781024243, 1, 12],\n",
       " [72781024243, 72785524114, 12, 1],\n",
       " [72785524114, 72781524237, 1, 13],\n",
       " [72781524237, 72785524114, 13, 1],\n",
       " [72785524114, 72788324220, 1, 14],\n",
       " [72788324220, 72785524114, 14, 1],\n",
       " [72785524114, 72698824219, 1, 15],\n",
       " [72698824219, 72785524114, 15, 1],\n",
       " [72785524114, 72793894274, 1, 16],\n",
       " [72793894274, 72785524114, 16, 1],\n",
       " [72785524114, 74206024207, 1, 17],\n",
       " [74206024207, 72785524114, 17, 1],\n",
       " [72785524114, 72782724110, 1, 18],\n",
       " [72782724110, 72785524114, 18, 1],\n",
       " [72785524114, 72793724222, 1, 19],\n",
       " [72793724222, 72785524114, 19, 1],\n",
       " [72785524114, 72792594227, 1, 20],\n",
       " [72792594227, 72785524114, 20, 1],\n",
       " [72785524114, 72782594239, 1, 21],\n",
       " [72782594239, 72785524114, 21, 1],\n",
       " [72785524114, 72794504205, 1, 22],\n",
       " [72794504205, 72785524114, 22, 1],\n",
       " [72785524114, 72792394225, 1, 23],\n",
       " [72792394225, 72785524114, 23, 1],\n",
       " [72785524114, 72784524163, 1, 24],\n",
       " [72784524163, 72785524114, 24, 1],\n",
       " [72785524114, 72792024227, 1, 25],\n",
       " [72792024227, 72785524114, 25, 1],\n",
       " [72785524114, 72785694176, 1, 26],\n",
       " [72785694176, 72785524114, 26, 1],\n",
       " [72789094197, 72793024233, 2, 3],\n",
       " [72793024233, 72789094197, 3, 2],\n",
       " [72789094197, 72785794129, 2, 4],\n",
       " [72785794129, 72789094197, 4, 2],\n",
       " [72789094197, 72788594266, 2, 5],\n",
       " [72788594266, 72789094197, 5, 2],\n",
       " [72789094197, 72797624217, 2, 6],\n",
       " [72797624217, 72789094197, 6, 2],\n",
       " [72789094197, 72785024157, 2, 7],\n",
       " [72785024157, 72789094197, 7, 2],\n",
       " [72789094197, 72797094240, 2, 8],\n",
       " [72797094240, 72789094197, 8, 2],\n",
       " [72789094197, 72798594276, 2, 9],\n",
       " [72798594276, 72789094197, 9, 2],\n",
       " [72789094197, 72792424223, 2, 10],\n",
       " [72792424223, 72789094197, 10, 2],\n",
       " [72789094197, 72792894263, 2, 11],\n",
       " [72792894263, 72789094197, 11, 2],\n",
       " [72789094197, 72781024243, 2, 12],\n",
       " [72781024243, 72789094197, 12, 2],\n",
       " [72789094197, 72781524237, 2, 13],\n",
       " [72781524237, 72789094197, 13, 2],\n",
       " [72789094197, 72788324220, 2, 14],\n",
       " [72788324220, 72789094197, 14, 2],\n",
       " [72789094197, 72698824219, 2, 15],\n",
       " [72698824219, 72789094197, 15, 2],\n",
       " [72789094197, 72793894274, 2, 16],\n",
       " [72793894274, 72789094197, 16, 2],\n",
       " [72789094197, 74206024207, 2, 17],\n",
       " [74206024207, 72789094197, 17, 2],\n",
       " [72789094197, 72782724110, 2, 18],\n",
       " [72782724110, 72789094197, 18, 2],\n",
       " [72789094197, 72793724222, 2, 19],\n",
       " [72793724222, 72789094197, 19, 2],\n",
       " [72789094197, 72792594227, 2, 20],\n",
       " [72792594227, 72789094197, 20, 2],\n",
       " [72789094197, 72782594239, 2, 21],\n",
       " [72782594239, 72789094197, 21, 2],\n",
       " [72789094197, 72794504205, 2, 22],\n",
       " [72794504205, 72789094197, 22, 2],\n",
       " [72789094197, 72792394225, 2, 23],\n",
       " [72792394225, 72789094197, 23, 2],\n",
       " [72789094197, 72784524163, 2, 24],\n",
       " [72784524163, 72789094197, 24, 2],\n",
       " [72789094197, 72792024227, 2, 25],\n",
       " [72792024227, 72789094197, 25, 2],\n",
       " [72789094197, 72785694176, 2, 26],\n",
       " [72785694176, 72789094197, 26, 2],\n",
       " [72793024233, 72785794129, 3, 4],\n",
       " [72785794129, 72793024233, 4, 3],\n",
       " [72793024233, 72788594266, 3, 5],\n",
       " [72788594266, 72793024233, 5, 3],\n",
       " [72793024233, 72797624217, 3, 6],\n",
       " [72797624217, 72793024233, 6, 3],\n",
       " [72793024233, 72785024157, 3, 7],\n",
       " [72785024157, 72793024233, 7, 3],\n",
       " [72793024233, 72797094240, 3, 8],\n",
       " [72797094240, 72793024233, 8, 3],\n",
       " [72793024233, 72798594276, 3, 9],\n",
       " [72798594276, 72793024233, 9, 3],\n",
       " [72793024233, 72792424223, 3, 10],\n",
       " [72792424223, 72793024233, 10, 3],\n",
       " [72793024233, 72792894263, 3, 11],\n",
       " [72792894263, 72793024233, 11, 3],\n",
       " [72793024233, 72781024243, 3, 12],\n",
       " [72781024243, 72793024233, 12, 3],\n",
       " [72793024233, 72781524237, 3, 13],\n",
       " [72781524237, 72793024233, 13, 3],\n",
       " [72793024233, 72788324220, 3, 14],\n",
       " [72788324220, 72793024233, 14, 3],\n",
       " [72793024233, 72698824219, 3, 15],\n",
       " [72698824219, 72793024233, 15, 3],\n",
       " [72793024233, 72793894274, 3, 16],\n",
       " [72793894274, 72793024233, 16, 3],\n",
       " [72793024233, 74206024207, 3, 17],\n",
       " [74206024207, 72793024233, 17, 3],\n",
       " [72793024233, 72782724110, 3, 18],\n",
       " [72782724110, 72793024233, 18, 3],\n",
       " [72793024233, 72793724222, 3, 19],\n",
       " [72793724222, 72793024233, 19, 3],\n",
       " [72793024233, 72792594227, 3, 20],\n",
       " [72792594227, 72793024233, 20, 3],\n",
       " [72793024233, 72782594239, 3, 21],\n",
       " [72782594239, 72793024233, 21, 3],\n",
       " [72793024233, 72794504205, 3, 22],\n",
       " [72794504205, 72793024233, 22, 3],\n",
       " [72793024233, 72792394225, 3, 23],\n",
       " [72792394225, 72793024233, 23, 3],\n",
       " [72793024233, 72784524163, 3, 24],\n",
       " [72784524163, 72793024233, 24, 3],\n",
       " [72793024233, 72792024227, 3, 25],\n",
       " [72792024227, 72793024233, 25, 3],\n",
       " [72793024233, 72785694176, 3, 26],\n",
       " [72785694176, 72793024233, 26, 3],\n",
       " [72785794129, 72788594266, 4, 5],\n",
       " [72788594266, 72785794129, 5, 4],\n",
       " [72785794129, 72797624217, 4, 6],\n",
       " [72797624217, 72785794129, 6, 4],\n",
       " [72785794129, 72785024157, 4, 7],\n",
       " [72785024157, 72785794129, 7, 4],\n",
       " [72785794129, 72797094240, 4, 8],\n",
       " [72797094240, 72785794129, 8, 4],\n",
       " [72785794129, 72798594276, 4, 9],\n",
       " [72798594276, 72785794129, 9, 4],\n",
       " [72785794129, 72792424223, 4, 10],\n",
       " [72792424223, 72785794129, 10, 4],\n",
       " [72785794129, 72792894263, 4, 11],\n",
       " [72792894263, 72785794129, 11, 4],\n",
       " [72785794129, 72781024243, 4, 12],\n",
       " [72781024243, 72785794129, 12, 4],\n",
       " [72785794129, 72781524237, 4, 13],\n",
       " [72781524237, 72785794129, 13, 4],\n",
       " [72785794129, 72788324220, 4, 14],\n",
       " [72788324220, 72785794129, 14, 4],\n",
       " [72785794129, 72698824219, 4, 15],\n",
       " [72698824219, 72785794129, 15, 4],\n",
       " [72785794129, 72793894274, 4, 16],\n",
       " [72793894274, 72785794129, 16, 4],\n",
       " [72785794129, 74206024207, 4, 17],\n",
       " [74206024207, 72785794129, 17, 4],\n",
       " [72785794129, 72782724110, 4, 18],\n",
       " [72782724110, 72785794129, 18, 4],\n",
       " [72785794129, 72793724222, 4, 19],\n",
       " [72793724222, 72785794129, 19, 4],\n",
       " [72785794129, 72792594227, 4, 20],\n",
       " [72792594227, 72785794129, 20, 4],\n",
       " [72785794129, 72782594239, 4, 21],\n",
       " [72782594239, 72785794129, 21, 4],\n",
       " [72785794129, 72794504205, 4, 22],\n",
       " [72794504205, 72785794129, 22, 4],\n",
       " [72785794129, 72792394225, 4, 23],\n",
       " [72792394225, 72785794129, 23, 4],\n",
       " [72785794129, 72784524163, 4, 24],\n",
       " [72784524163, 72785794129, 24, 4],\n",
       " [72785794129, 72792024227, 4, 25],\n",
       " [72792024227, 72785794129, 25, 4],\n",
       " [72785794129, 72785694176, 4, 26],\n",
       " [72785694176, 72785794129, 26, 4],\n",
       " [72788594266, 72797624217, 5, 6],\n",
       " [72797624217, 72788594266, 6, 5],\n",
       " [72788594266, 72785024157, 5, 7],\n",
       " [72785024157, 72788594266, 7, 5],\n",
       " [72788594266, 72797094240, 5, 8],\n",
       " [72797094240, 72788594266, 8, 5],\n",
       " [72788594266, 72798594276, 5, 9],\n",
       " [72798594276, 72788594266, 9, 5],\n",
       " [72788594266, 72792424223, 5, 10],\n",
       " [72792424223, 72788594266, 10, 5],\n",
       " [72788594266, 72792894263, 5, 11],\n",
       " [72792894263, 72788594266, 11, 5],\n",
       " [72788594266, 72781024243, 5, 12],\n",
       " [72781024243, 72788594266, 12, 5],\n",
       " [72788594266, 72781524237, 5, 13],\n",
       " [72781524237, 72788594266, 13, 5],\n",
       " [72788594266, 72788324220, 5, 14],\n",
       " [72788324220, 72788594266, 14, 5],\n",
       " [72788594266, 72698824219, 5, 15],\n",
       " [72698824219, 72788594266, 15, 5],\n",
       " [72788594266, 72793894274, 5, 16],\n",
       " [72793894274, 72788594266, 16, 5],\n",
       " [72788594266, 74206024207, 5, 17],\n",
       " [74206024207, 72788594266, 17, 5],\n",
       " [72788594266, 72782724110, 5, 18],\n",
       " [72782724110, 72788594266, 18, 5],\n",
       " [72788594266, 72793724222, 5, 19],\n",
       " [72793724222, 72788594266, 19, 5],\n",
       " [72788594266, 72792594227, 5, 20],\n",
       " [72792594227, 72788594266, 20, 5],\n",
       " [72788594266, 72782594239, 5, 21],\n",
       " [72782594239, 72788594266, 21, 5],\n",
       " [72788594266, 72794504205, 5, 22],\n",
       " [72794504205, 72788594266, 22, 5],\n",
       " [72788594266, 72792394225, 5, 23],\n",
       " [72792394225, 72788594266, 23, 5],\n",
       " [72788594266, 72784524163, 5, 24],\n",
       " [72784524163, 72788594266, 24, 5],\n",
       " [72788594266, 72792024227, 5, 25],\n",
       " [72792024227, 72788594266, 25, 5],\n",
       " [72788594266, 72785694176, 5, 26],\n",
       " [72785694176, 72788594266, 26, 5],\n",
       " [72797624217, 72785024157, 6, 7],\n",
       " [72785024157, 72797624217, 7, 6],\n",
       " [72797624217, 72797094240, 6, 8],\n",
       " [72797094240, 72797624217, 8, 6],\n",
       " [72797624217, 72798594276, 6, 9],\n",
       " [72798594276, 72797624217, 9, 6],\n",
       " [72797624217, 72792424223, 6, 10],\n",
       " [72792424223, 72797624217, 10, 6],\n",
       " [72797624217, 72792894263, 6, 11],\n",
       " [72792894263, 72797624217, 11, 6],\n",
       " [72797624217, 72781024243, 6, 12],\n",
       " [72781024243, 72797624217, 12, 6],\n",
       " [72797624217, 72781524237, 6, 13],\n",
       " [72781524237, 72797624217, 13, 6],\n",
       " [72797624217, 72788324220, 6, 14],\n",
       " [72788324220, 72797624217, 14, 6],\n",
       " [72797624217, 72698824219, 6, 15],\n",
       " [72698824219, 72797624217, 15, 6],\n",
       " [72797624217, 72793894274, 6, 16],\n",
       " [72793894274, 72797624217, 16, 6],\n",
       " [72797624217, 74206024207, 6, 17],\n",
       " [74206024207, 72797624217, 17, 6],\n",
       " [72797624217, 72782724110, 6, 18],\n",
       " [72782724110, 72797624217, 18, 6],\n",
       " [72797624217, 72793724222, 6, 19],\n",
       " [72793724222, 72797624217, 19, 6],\n",
       " [72797624217, 72792594227, 6, 20],\n",
       " [72792594227, 72797624217, 20, 6],\n",
       " [72797624217, 72782594239, 6, 21],\n",
       " [72782594239, 72797624217, 21, 6],\n",
       " [72797624217, 72794504205, 6, 22],\n",
       " [72794504205, 72797624217, 22, 6],\n",
       " [72797624217, 72792394225, 6, 23],\n",
       " [72792394225, 72797624217, 23, 6],\n",
       " [72797624217, 72784524163, 6, 24],\n",
       " [72784524163, 72797624217, 24, 6],\n",
       " [72797624217, 72792024227, 6, 25],\n",
       " [72792024227, 72797624217, 25, 6],\n",
       " [72797624217, 72785694176, 6, 26],\n",
       " [72785694176, 72797624217, 26, 6],\n",
       " [72785024157, 72797094240, 7, 8],\n",
       " [72797094240, 72785024157, 8, 7],\n",
       " [72785024157, 72798594276, 7, 9],\n",
       " [72798594276, 72785024157, 9, 7],\n",
       " [72785024157, 72792424223, 7, 10],\n",
       " [72792424223, 72785024157, 10, 7],\n",
       " [72785024157, 72792894263, 7, 11],\n",
       " [72792894263, 72785024157, 11, 7],\n",
       " [72785024157, 72781024243, 7, 12],\n",
       " [72781024243, 72785024157, 12, 7],\n",
       " [72785024157, 72781524237, 7, 13],\n",
       " [72781524237, 72785024157, 13, 7],\n",
       " [72785024157, 72788324220, 7, 14],\n",
       " [72788324220, 72785024157, 14, 7],\n",
       " [72785024157, 72698824219, 7, 15],\n",
       " [72698824219, 72785024157, 15, 7],\n",
       " [72785024157, 72793894274, 7, 16],\n",
       " [72793894274, 72785024157, 16, 7],\n",
       " [72785024157, 74206024207, 7, 17],\n",
       " [74206024207, 72785024157, 17, 7],\n",
       " [72785024157, 72782724110, 7, 18],\n",
       " [72782724110, 72785024157, 18, 7],\n",
       " [72785024157, 72793724222, 7, 19],\n",
       " [72793724222, 72785024157, 19, 7],\n",
       " [72785024157, 72792594227, 7, 20],\n",
       " [72792594227, 72785024157, 20, 7],\n",
       " [72785024157, 72782594239, 7, 21],\n",
       " [72782594239, 72785024157, 21, 7],\n",
       " [72785024157, 72794504205, 7, 22],\n",
       " [72794504205, 72785024157, 22, 7],\n",
       " [72785024157, 72792394225, 7, 23],\n",
       " [72792394225, 72785024157, 23, 7],\n",
       " [72785024157, 72784524163, 7, 24],\n",
       " [72784524163, 72785024157, 24, 7],\n",
       " [72785024157, 72792024227, 7, 25],\n",
       " [72792024227, 72785024157, 25, 7],\n",
       " [72785024157, 72785694176, 7, 26],\n",
       " [72785694176, 72785024157, 26, 7],\n",
       " [72797094240, 72798594276, 8, 9],\n",
       " [72798594276, 72797094240, 9, 8],\n",
       " [72797094240, 72792424223, 8, 10],\n",
       " [72792424223, 72797094240, 10, 8],\n",
       " [72797094240, 72792894263, 8, 11],\n",
       " [72792894263, 72797094240, 11, 8],\n",
       " [72797094240, 72781024243, 8, 12],\n",
       " [72781024243, 72797094240, 12, 8],\n",
       " [72797094240, 72781524237, 8, 13],\n",
       " [72781524237, 72797094240, 13, 8],\n",
       " [72797094240, 72788324220, 8, 14],\n",
       " [72788324220, 72797094240, 14, 8],\n",
       " [72797094240, 72698824219, 8, 15],\n",
       " [72698824219, 72797094240, 15, 8],\n",
       " [72797094240, 72793894274, 8, 16],\n",
       " [72793894274, 72797094240, 16, 8],\n",
       " [72797094240, 74206024207, 8, 17],\n",
       " [74206024207, 72797094240, 17, 8],\n",
       " [72797094240, 72782724110, 8, 18],\n",
       " [72782724110, 72797094240, 18, 8],\n",
       " [72797094240, 72793724222, 8, 19],\n",
       " [72793724222, 72797094240, 19, 8],\n",
       " [72797094240, 72792594227, 8, 20],\n",
       " [72792594227, 72797094240, 20, 8],\n",
       " [72797094240, 72782594239, 8, 21],\n",
       " [72782594239, 72797094240, 21, 8],\n",
       " [72797094240, 72794504205, 8, 22],\n",
       " [72794504205, 72797094240, 22, 8],\n",
       " [72797094240, 72792394225, 8, 23],\n",
       " [72792394225, 72797094240, 23, 8],\n",
       " [72797094240, 72784524163, 8, 24],\n",
       " [72784524163, 72797094240, 24, 8],\n",
       " [72797094240, 72792024227, 8, 25],\n",
       " [72792024227, 72797094240, 25, 8],\n",
       " [72797094240, 72785694176, 8, 26],\n",
       " [72785694176, 72797094240, 26, 8],\n",
       " [72798594276, 72792424223, 9, 10],\n",
       " [72792424223, 72798594276, 10, 9],\n",
       " [72798594276, 72792894263, 9, 11],\n",
       " [72792894263, 72798594276, 11, 9],\n",
       " [72798594276, 72781024243, 9, 12],\n",
       " [72781024243, 72798594276, 12, 9],\n",
       " [72798594276, 72781524237, 9, 13],\n",
       " [72781524237, 72798594276, 13, 9],\n",
       " [72798594276, 72788324220, 9, 14],\n",
       " [72788324220, 72798594276, 14, 9],\n",
       " [72798594276, 72698824219, 9, 15],\n",
       " [72698824219, 72798594276, 15, 9],\n",
       " [72798594276, 72793894274, 9, 16],\n",
       " [72793894274, 72798594276, 16, 9],\n",
       " [72798594276, 74206024207, 9, 17],\n",
       " [74206024207, 72798594276, 17, 9],\n",
       " [72798594276, 72782724110, 9, 18],\n",
       " [72782724110, 72798594276, 18, 9],\n",
       " [72798594276, 72793724222, 9, 19],\n",
       " [72793724222, 72798594276, 19, 9],\n",
       " [72798594276, 72792594227, 9, 20],\n",
       " [72792594227, 72798594276, 20, 9],\n",
       " [72798594276, 72782594239, 9, 21],\n",
       " [72782594239, 72798594276, 21, 9],\n",
       " [72798594276, 72794504205, 9, 22],\n",
       " [72794504205, 72798594276, 22, 9],\n",
       " [72798594276, 72792394225, 9, 23],\n",
       " [72792394225, 72798594276, 23, 9],\n",
       " [72798594276, 72784524163, 9, 24],\n",
       " [72784524163, 72798594276, 24, 9],\n",
       " [72798594276, 72792024227, 9, 25],\n",
       " [72792024227, 72798594276, 25, 9],\n",
       " [72798594276, 72785694176, 9, 26],\n",
       " [72785694176, 72798594276, 26, 9],\n",
       " [72792424223, 72792894263, 10, 11],\n",
       " [72792894263, 72792424223, 11, 10],\n",
       " [72792424223, 72781024243, 10, 12],\n",
       " [72781024243, 72792424223, 12, 10],\n",
       " [72792424223, 72781524237, 10, 13],\n",
       " [72781524237, 72792424223, 13, 10],\n",
       " [72792424223, 72788324220, 10, 14],\n",
       " [72788324220, 72792424223, 14, 10],\n",
       " [72792424223, 72698824219, 10, 15],\n",
       " [72698824219, 72792424223, 15, 10],\n",
       " [72792424223, 72793894274, 10, 16],\n",
       " [72793894274, 72792424223, 16, 10],\n",
       " [72792424223, 74206024207, 10, 17],\n",
       " [74206024207, 72792424223, 17, 10],\n",
       " [72792424223, 72782724110, 10, 18],\n",
       " [72782724110, 72792424223, 18, 10],\n",
       " [72792424223, 72793724222, 10, 19],\n",
       " [72793724222, 72792424223, 19, 10],\n",
       " [72792424223, 72792594227, 10, 20],\n",
       " [72792594227, 72792424223, 20, 10],\n",
       " [72792424223, 72782594239, 10, 21],\n",
       " [72782594239, 72792424223, 21, 10],\n",
       " [72792424223, 72794504205, 10, 22],\n",
       " [72794504205, 72792424223, 22, 10],\n",
       " [72792424223, 72792394225, 10, 23],\n",
       " [72792394225, 72792424223, 23, 10],\n",
       " [72792424223, 72784524163, 10, 24],\n",
       " [72784524163, 72792424223, 24, 10],\n",
       " [72792424223, 72792024227, 10, 25],\n",
       " [72792024227, 72792424223, 25, 10],\n",
       " [72792424223, 72785694176, 10, 26],\n",
       " [72785694176, 72792424223, 26, 10],\n",
       " [72792894263, 72781024243, 11, 12],\n",
       " [72781024243, 72792894263, 12, 11],\n",
       " [72792894263, 72781524237, 11, 13],\n",
       " [72781524237, 72792894263, 13, 11],\n",
       " [72792894263, 72788324220, 11, 14],\n",
       " [72788324220, 72792894263, 14, 11],\n",
       " [72792894263, 72698824219, 11, 15],\n",
       " [72698824219, 72792894263, 15, 11],\n",
       " [72792894263, 72793894274, 11, 16],\n",
       " [72793894274, 72792894263, 16, 11],\n",
       " [72792894263, 74206024207, 11, 17],\n",
       " [74206024207, 72792894263, 17, 11],\n",
       " [72792894263, 72782724110, 11, 18],\n",
       " [72782724110, 72792894263, 18, 11],\n",
       " [72792894263, 72793724222, 11, 19],\n",
       " [72793724222, 72792894263, 19, 11],\n",
       " [72792894263, 72792594227, 11, 20],\n",
       " [72792594227, 72792894263, 20, 11],\n",
       " [72792894263, 72782594239, 11, 21],\n",
       " [72782594239, 72792894263, 21, 11],\n",
       " [72792894263, 72794504205, 11, 22],\n",
       " [72794504205, 72792894263, 22, 11],\n",
       " [72792894263, 72792394225, 11, 23],\n",
       " [72792394225, 72792894263, 23, 11],\n",
       " [72792894263, 72784524163, 11, 24],\n",
       " [72784524163, 72792894263, 24, 11],\n",
       " [72792894263, 72792024227, 11, 25],\n",
       " [72792024227, 72792894263, 25, 11],\n",
       " [72792894263, 72785694176, 11, 26],\n",
       " [72785694176, 72792894263, 26, 11],\n",
       " [72781024243, 72781524237, 12, 13],\n",
       " [72781524237, 72781024243, 13, 12],\n",
       " [72781024243, 72788324220, 12, 14],\n",
       " [72788324220, 72781024243, 14, 12],\n",
       " [72781024243, 72698824219, 12, 15],\n",
       " [72698824219, 72781024243, 15, 12],\n",
       " [72781024243, 72793894274, 12, 16],\n",
       " [72793894274, 72781024243, 16, 12],\n",
       " [72781024243, 74206024207, 12, 17],\n",
       " [74206024207, 72781024243, 17, 12],\n",
       " [72781024243, 72782724110, 12, 18],\n",
       " [72782724110, 72781024243, 18, 12],\n",
       " [72781024243, 72793724222, 12, 19],\n",
       " [72793724222, 72781024243, 19, 12],\n",
       " [72781024243, 72792594227, 12, 20],\n",
       " [72792594227, 72781024243, 20, 12],\n",
       " [72781024243, 72782594239, 12, 21],\n",
       " [72782594239, 72781024243, 21, 12],\n",
       " [72781024243, 72794504205, 12, 22],\n",
       " [72794504205, 72781024243, 22, 12],\n",
       " [72781024243, 72792394225, 12, 23],\n",
       " [72792394225, 72781024243, 23, 12],\n",
       " [72781024243, 72784524163, 12, 24],\n",
       " [72784524163, 72781024243, 24, 12],\n",
       " [72781024243, 72792024227, 12, 25],\n",
       " [72792024227, 72781024243, 25, 12],\n",
       " [72781024243, 72785694176, 12, 26],\n",
       " [72785694176, 72781024243, 26, 12],\n",
       " [72781524237, 72788324220, 13, 14],\n",
       " [72788324220, 72781524237, 14, 13],\n",
       " [72781524237, 72698824219, 13, 15],\n",
       " [72698824219, 72781524237, 15, 13],\n",
       " [72781524237, 72793894274, 13, 16],\n",
       " [72793894274, 72781524237, 16, 13],\n",
       " [72781524237, 74206024207, 13, 17],\n",
       " [74206024207, 72781524237, 17, 13],\n",
       " [72781524237, 72782724110, 13, 18],\n",
       " [72782724110, 72781524237, 18, 13],\n",
       " [72781524237, 72793724222, 13, 19],\n",
       " [72793724222, 72781524237, 19, 13],\n",
       " [72781524237, 72792594227, 13, 20],\n",
       " [72792594227, 72781524237, 20, 13],\n",
       " [72781524237, 72782594239, 13, 21],\n",
       " [72782594239, 72781524237, 21, 13],\n",
       " [72781524237, 72794504205, 13, 22],\n",
       " [72794504205, 72781524237, 22, 13],\n",
       " [72781524237, 72792394225, 13, 23],\n",
       " [72792394225, 72781524237, 23, 13],\n",
       " [72781524237, 72784524163, 13, 24],\n",
       " [72784524163, 72781524237, 24, 13],\n",
       " [72781524237, 72792024227, 13, 25],\n",
       " [72792024227, 72781524237, 25, 13],\n",
       " [72781524237, 72785694176, 13, 26],\n",
       " [72785694176, 72781524237, 26, 13],\n",
       " [72788324220, 72698824219, 14, 15],\n",
       " [72698824219, 72788324220, 15, 14],\n",
       " [72788324220, 72793894274, 14, 16],\n",
       " [72793894274, 72788324220, 16, 14],\n",
       " [72788324220, 74206024207, 14, 17],\n",
       " [74206024207, 72788324220, 17, 14],\n",
       " [72788324220, 72782724110, 14, 18],\n",
       " [72782724110, 72788324220, 18, 14],\n",
       " [72788324220, 72793724222, 14, 19],\n",
       " [72793724222, 72788324220, 19, 14],\n",
       " [72788324220, 72792594227, 14, 20],\n",
       " [72792594227, 72788324220, 20, 14],\n",
       " [72788324220, 72782594239, 14, 21],\n",
       " [72782594239, 72788324220, 21, 14],\n",
       " [72788324220, 72794504205, 14, 22],\n",
       " [72794504205, 72788324220, 22, 14],\n",
       " [72788324220, 72792394225, 14, 23],\n",
       " [72792394225, 72788324220, 23, 14],\n",
       " [72788324220, 72784524163, 14, 24],\n",
       " [72784524163, 72788324220, 24, 14],\n",
       " [72788324220, 72792024227, 14, 25],\n",
       " [72792024227, 72788324220, 25, 14],\n",
       " [72788324220, 72785694176, 14, 26],\n",
       " [72785694176, 72788324220, 26, 14],\n",
       " [72698824219, 72793894274, 15, 16],\n",
       " [72793894274, 72698824219, 16, 15],\n",
       " [72698824219, 74206024207, 15, 17],\n",
       " [74206024207, 72698824219, 17, 15],\n",
       " [72698824219, 72782724110, 15, 18],\n",
       " [72782724110, 72698824219, 18, 15],\n",
       " [72698824219, 72793724222, 15, 19],\n",
       " [72793724222, 72698824219, 19, 15],\n",
       " [72698824219, 72792594227, 15, 20],\n",
       " [72792594227, 72698824219, 20, 15],\n",
       " [72698824219, 72782594239, 15, 21],\n",
       " [72782594239, 72698824219, 21, 15],\n",
       " [72698824219, 72794504205, 15, 22],\n",
       " [72794504205, 72698824219, 22, 15],\n",
       " [72698824219, 72792394225, 15, 23],\n",
       " [72792394225, 72698824219, 23, 15],\n",
       " [72698824219, 72784524163, 15, 24],\n",
       " [72784524163, 72698824219, 24, 15],\n",
       " [72698824219, 72792024227, 15, 25],\n",
       " [72792024227, 72698824219, 25, 15],\n",
       " [72698824219, 72785694176, 15, 26],\n",
       " [72785694176, 72698824219, 26, 15],\n",
       " [72793894274, 74206024207, 16, 17],\n",
       " [74206024207, 72793894274, 17, 16],\n",
       " [72793894274, 72782724110, 16, 18],\n",
       " [72782724110, 72793894274, 18, 16],\n",
       " [72793894274, 72793724222, 16, 19],\n",
       " [72793724222, 72793894274, 19, 16],\n",
       " [72793894274, 72792594227, 16, 20],\n",
       " [72792594227, 72793894274, 20, 16],\n",
       " [72793894274, 72782594239, 16, 21],\n",
       " [72782594239, 72793894274, 21, 16],\n",
       " [72793894274, 72794504205, 16, 22],\n",
       " [72794504205, 72793894274, 22, 16],\n",
       " [72793894274, 72792394225, 16, 23],\n",
       " [72792394225, 72793894274, 23, 16],\n",
       " [72793894274, 72784524163, 16, 24],\n",
       " [72784524163, 72793894274, 24, 16],\n",
       " [72793894274, 72792024227, 16, 25],\n",
       " [72792024227, 72793894274, 25, 16],\n",
       " [72793894274, 72785694176, 16, 26],\n",
       " [72785694176, 72793894274, 26, 16],\n",
       " [74206024207, 72782724110, 17, 18],\n",
       " [72782724110, 74206024207, 18, 17],\n",
       " [74206024207, 72793724222, 17, 19],\n",
       " [72793724222, 74206024207, 19, 17],\n",
       " [74206024207, 72792594227, 17, 20],\n",
       " [72792594227, 74206024207, 20, 17],\n",
       " [74206024207, 72782594239, 17, 21],\n",
       " [72782594239, 74206024207, 21, 17],\n",
       " [74206024207, 72794504205, 17, 22],\n",
       " [72794504205, 74206024207, 22, 17],\n",
       " [74206024207, 72792394225, 17, 23],\n",
       " [72792394225, 74206024207, 23, 17],\n",
       " [74206024207, 72784524163, 17, 24],\n",
       " [72784524163, 74206024207, 24, 17],\n",
       " [74206024207, 72792024227, 17, 25],\n",
       " [72792024227, 74206024207, 25, 17],\n",
       " [74206024207, 72785694176, 17, 26],\n",
       " [72785694176, 74206024207, 26, 17],\n",
       " [72782724110, 72793724222, 18, 19],\n",
       " [72793724222, 72782724110, 19, 18],\n",
       " [72782724110, 72792594227, 18, 20],\n",
       " [72792594227, 72782724110, 20, 18],\n",
       " [72782724110, 72782594239, 18, 21],\n",
       " [72782594239, 72782724110, 21, 18],\n",
       " [72782724110, 72794504205, 18, 22],\n",
       " [72794504205, 72782724110, 22, 18],\n",
       " [72782724110, 72792394225, 18, 23],\n",
       " [72792394225, 72782724110, 23, 18],\n",
       " [72782724110, 72784524163, 18, 24],\n",
       " [72784524163, 72782724110, 24, 18],\n",
       " [72782724110, 72792024227, 18, 25],\n",
       " [72792024227, 72782724110, 25, 18],\n",
       " [72782724110, 72785694176, 18, 26],\n",
       " [72785694176, 72782724110, 26, 18],\n",
       " [72793724222, 72792594227, 19, 20],\n",
       " [72792594227, 72793724222, 20, 19],\n",
       " [72793724222, 72782594239, 19, 21],\n",
       " [72782594239, 72793724222, 21, 19],\n",
       " [72793724222, 72794504205, 19, 22],\n",
       " [72794504205, 72793724222, 22, 19],\n",
       " [72793724222, 72792394225, 19, 23],\n",
       " [72792394225, 72793724222, 23, 19],\n",
       " [72793724222, 72784524163, 19, 24],\n",
       " [72784524163, 72793724222, 24, 19],\n",
       " [72793724222, 72792024227, 19, 25],\n",
       " [72792024227, 72793724222, 25, 19],\n",
       " [72793724222, 72785694176, 19, 26],\n",
       " [72785694176, 72793724222, 26, 19],\n",
       " [72792594227, 72782594239, 20, 21],\n",
       " [72782594239, 72792594227, 21, 20],\n",
       " [72792594227, 72794504205, 20, 22],\n",
       " [72794504205, 72792594227, 22, 20],\n",
       " [72792594227, 72792394225, 20, 23],\n",
       " [72792394225, 72792594227, 23, 20],\n",
       " [72792594227, 72784524163, 20, 24],\n",
       " [72784524163, 72792594227, 24, 20],\n",
       " [72792594227, 72792024227, 20, 25],\n",
       " [72792024227, 72792594227, 25, 20],\n",
       " [72792594227, 72785694176, 20, 26],\n",
       " [72785694176, 72792594227, 26, 20],\n",
       " [72782594239, 72794504205, 21, 22],\n",
       " [72794504205, 72782594239, 22, 21],\n",
       " [72782594239, 72792394225, 21, 23],\n",
       " [72792394225, 72782594239, 23, 21],\n",
       " [72782594239, 72784524163, 21, 24],\n",
       " [72784524163, 72782594239, 24, 21],\n",
       " [72782594239, 72792024227, 21, 25],\n",
       " [72792024227, 72782594239, 25, 21],\n",
       " [72782594239, 72785694176, 21, 26],\n",
       " [72785694176, 72782594239, 26, 21],\n",
       " [72794504205, 72792394225, 22, 23],\n",
       " [72792394225, 72794504205, 23, 22],\n",
       " [72794504205, 72784524163, 22, 24],\n",
       " [72784524163, 72794504205, 24, 22],\n",
       " [72794504205, 72792024227, 22, 25],\n",
       " [72792024227, 72794504205, 25, 22],\n",
       " [72794504205, 72785694176, 22, 26],\n",
       " [72785694176, 72794504205, 26, 22],\n",
       " [72792394225, 72784524163, 23, 24],\n",
       " [72784524163, 72792394225, 24, 23],\n",
       " [72792394225, 72792024227, 23, 25],\n",
       " [72792024227, 72792394225, 25, 23],\n",
       " [72792394225, 72785694176, 23, 26],\n",
       " [72785694176, 72792394225, 26, 23],\n",
       " [72784524163, 72792024227, 24, 25],\n",
       " [72792024227, 72784524163, 25, 24],\n",
       " [72784524163, 72785694176, 24, 26],\n",
       " [72785694176, 72784524163, 26, 24],\n",
       " [72792024227, 72785694176, 25, 26],\n",
       " [72785694176, 72792024227, 26, 25]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [1, 0],\n",
       " [0, 2],\n",
       " [2, 0],\n",
       " [0, 3],\n",
       " [3, 0],\n",
       " [0, 4],\n",
       " [4, 0],\n",
       " [0, 5],\n",
       " [5, 0],\n",
       " [0, 6],\n",
       " [6, 0],\n",
       " [0, 7],\n",
       " [7, 0],\n",
       " [0, 8],\n",
       " [8, 0],\n",
       " [0, 9],\n",
       " [9, 0],\n",
       " [0, 10],\n",
       " [10, 0],\n",
       " [0, 11],\n",
       " [11, 0],\n",
       " [0, 12],\n",
       " [12, 0],\n",
       " [0, 13],\n",
       " [13, 0],\n",
       " [0, 14],\n",
       " [14, 0],\n",
       " [0, 15],\n",
       " [15, 0],\n",
       " [0, 16],\n",
       " [16, 0],\n",
       " [0, 17],\n",
       " [17, 0],\n",
       " [0, 18],\n",
       " [18, 0],\n",
       " [0, 19],\n",
       " [19, 0],\n",
       " [0, 20],\n",
       " [20, 0],\n",
       " [0, 21],\n",
       " [21, 0],\n",
       " [0, 22],\n",
       " [22, 0],\n",
       " [0, 23],\n",
       " [23, 0],\n",
       " [0, 24],\n",
       " [24, 0],\n",
       " [0, 25],\n",
       " [25, 0],\n",
       " [0, 26],\n",
       " [26, 0],\n",
       " [1, 2],\n",
       " [2, 1],\n",
       " [1, 3],\n",
       " [3, 1],\n",
       " [1, 4],\n",
       " [4, 1],\n",
       " [1, 5],\n",
       " [5, 1],\n",
       " [1, 6],\n",
       " [6, 1],\n",
       " [1, 7],\n",
       " [7, 1],\n",
       " [1, 8],\n",
       " [8, 1],\n",
       " [1, 9],\n",
       " [9, 1],\n",
       " [1, 10],\n",
       " [10, 1],\n",
       " [1, 11],\n",
       " [11, 1],\n",
       " [1, 12],\n",
       " [12, 1],\n",
       " [1, 13],\n",
       " [13, 1],\n",
       " [1, 14],\n",
       " [14, 1],\n",
       " [1, 15],\n",
       " [15, 1],\n",
       " [1, 16],\n",
       " [16, 1],\n",
       " [1, 17],\n",
       " [17, 1],\n",
       " [1, 18],\n",
       " [18, 1],\n",
       " [1, 19],\n",
       " [19, 1],\n",
       " [1, 20],\n",
       " [20, 1],\n",
       " [1, 21],\n",
       " [21, 1],\n",
       " [1, 22],\n",
       " [22, 1],\n",
       " [1, 23],\n",
       " [23, 1],\n",
       " [1, 24],\n",
       " [24, 1],\n",
       " [1, 25],\n",
       " [25, 1],\n",
       " [1, 26],\n",
       " [26, 1],\n",
       " [2, 3],\n",
       " [3, 2],\n",
       " [2, 4],\n",
       " [4, 2],\n",
       " [2, 5],\n",
       " [5, 2],\n",
       " [2, 6],\n",
       " [6, 2],\n",
       " [2, 7],\n",
       " [7, 2],\n",
       " [2, 8],\n",
       " [8, 2],\n",
       " [2, 9],\n",
       " [9, 2],\n",
       " [2, 10],\n",
       " [10, 2],\n",
       " [2, 11],\n",
       " [11, 2],\n",
       " [2, 12],\n",
       " [12, 2],\n",
       " [2, 13],\n",
       " [13, 2],\n",
       " [2, 14],\n",
       " [14, 2],\n",
       " [2, 15],\n",
       " [15, 2],\n",
       " [2, 16],\n",
       " [16, 2],\n",
       " [2, 17],\n",
       " [17, 2],\n",
       " [2, 18],\n",
       " [18, 2],\n",
       " [2, 19],\n",
       " [19, 2],\n",
       " [2, 20],\n",
       " [20, 2],\n",
       " [2, 21],\n",
       " [21, 2],\n",
       " [2, 22],\n",
       " [22, 2],\n",
       " [2, 23],\n",
       " [23, 2],\n",
       " [2, 24],\n",
       " [24, 2],\n",
       " [2, 25],\n",
       " [25, 2],\n",
       " [2, 26],\n",
       " [26, 2],\n",
       " [3, 4],\n",
       " [4, 3],\n",
       " [3, 5],\n",
       " [5, 3],\n",
       " [3, 6],\n",
       " [6, 3],\n",
       " [3, 7],\n",
       " [7, 3],\n",
       " [3, 8],\n",
       " [8, 3],\n",
       " [3, 9],\n",
       " [9, 3],\n",
       " [3, 10],\n",
       " [10, 3],\n",
       " [3, 11],\n",
       " [11, 3],\n",
       " [3, 12],\n",
       " [12, 3],\n",
       " [3, 13],\n",
       " [13, 3],\n",
       " [3, 14],\n",
       " [14, 3],\n",
       " [3, 15],\n",
       " [15, 3],\n",
       " [3, 16],\n",
       " [16, 3],\n",
       " [3, 17],\n",
       " [17, 3],\n",
       " [3, 18],\n",
       " [18, 3],\n",
       " [3, 19],\n",
       " [19, 3],\n",
       " [3, 20],\n",
       " [20, 3],\n",
       " [3, 21],\n",
       " [21, 3],\n",
       " [3, 22],\n",
       " [22, 3],\n",
       " [3, 23],\n",
       " [23, 3],\n",
       " [3, 24],\n",
       " [24, 3],\n",
       " [3, 25],\n",
       " [25, 3],\n",
       " [3, 26],\n",
       " [26, 3],\n",
       " [4, 5],\n",
       " [5, 4],\n",
       " [4, 6],\n",
       " [6, 4],\n",
       " [4, 7],\n",
       " [7, 4],\n",
       " [4, 8],\n",
       " [8, 4],\n",
       " [4, 9],\n",
       " [9, 4],\n",
       " [4, 10],\n",
       " [10, 4],\n",
       " [4, 11],\n",
       " [11, 4],\n",
       " [4, 12],\n",
       " [12, 4],\n",
       " [4, 13],\n",
       " [13, 4],\n",
       " [4, 14],\n",
       " [14, 4],\n",
       " [4, 15],\n",
       " [15, 4],\n",
       " [4, 16],\n",
       " [16, 4],\n",
       " [4, 17],\n",
       " [17, 4],\n",
       " [4, 18],\n",
       " [18, 4],\n",
       " [4, 19],\n",
       " [19, 4],\n",
       " [4, 20],\n",
       " [20, 4],\n",
       " [4, 21],\n",
       " [21, 4],\n",
       " [4, 22],\n",
       " [22, 4],\n",
       " [4, 23],\n",
       " [23, 4],\n",
       " [4, 24],\n",
       " [24, 4],\n",
       " [4, 25],\n",
       " [25, 4],\n",
       " [4, 26],\n",
       " [26, 4],\n",
       " [5, 6],\n",
       " [6, 5],\n",
       " [5, 7],\n",
       " [7, 5],\n",
       " [5, 8],\n",
       " [8, 5],\n",
       " [5, 9],\n",
       " [9, 5],\n",
       " [5, 10],\n",
       " [10, 5],\n",
       " [5, 11],\n",
       " [11, 5],\n",
       " [5, 12],\n",
       " [12, 5],\n",
       " [5, 13],\n",
       " [13, 5],\n",
       " [5, 14],\n",
       " [14, 5],\n",
       " [5, 15],\n",
       " [15, 5],\n",
       " [5, 16],\n",
       " [16, 5],\n",
       " [5, 17],\n",
       " [17, 5],\n",
       " [5, 18],\n",
       " [18, 5],\n",
       " [5, 19],\n",
       " [19, 5],\n",
       " [5, 20],\n",
       " [20, 5],\n",
       " [5, 21],\n",
       " [21, 5],\n",
       " [5, 22],\n",
       " [22, 5],\n",
       " [5, 23],\n",
       " [23, 5],\n",
       " [5, 24],\n",
       " [24, 5],\n",
       " [5, 25],\n",
       " [25, 5],\n",
       " [5, 26],\n",
       " [26, 5],\n",
       " [6, 7],\n",
       " [7, 6],\n",
       " [6, 8],\n",
       " [8, 6],\n",
       " [6, 9],\n",
       " [9, 6],\n",
       " [6, 10],\n",
       " [10, 6],\n",
       " [6, 11],\n",
       " [11, 6],\n",
       " [6, 12],\n",
       " [12, 6],\n",
       " [6, 13],\n",
       " [13, 6],\n",
       " [6, 14],\n",
       " [14, 6],\n",
       " [6, 15],\n",
       " [15, 6],\n",
       " [6, 16],\n",
       " [16, 6],\n",
       " [6, 17],\n",
       " [17, 6],\n",
       " [6, 18],\n",
       " [18, 6],\n",
       " [6, 19],\n",
       " [19, 6],\n",
       " [6, 20],\n",
       " [20, 6],\n",
       " [6, 21],\n",
       " [21, 6],\n",
       " [6, 22],\n",
       " [22, 6],\n",
       " [6, 23],\n",
       " [23, 6],\n",
       " [6, 24],\n",
       " [24, 6],\n",
       " [6, 25],\n",
       " [25, 6],\n",
       " [6, 26],\n",
       " [26, 6],\n",
       " [7, 8],\n",
       " [8, 7],\n",
       " [7, 9],\n",
       " [9, 7],\n",
       " [7, 10],\n",
       " [10, 7],\n",
       " [7, 11],\n",
       " [11, 7],\n",
       " [7, 12],\n",
       " [12, 7],\n",
       " [7, 13],\n",
       " [13, 7],\n",
       " [7, 14],\n",
       " [14, 7],\n",
       " [7, 15],\n",
       " [15, 7],\n",
       " [7, 16],\n",
       " [16, 7],\n",
       " [7, 17],\n",
       " [17, 7],\n",
       " [7, 18],\n",
       " [18, 7],\n",
       " [7, 19],\n",
       " [19, 7],\n",
       " [7, 20],\n",
       " [20, 7],\n",
       " [7, 21],\n",
       " [21, 7],\n",
       " [7, 22],\n",
       " [22, 7],\n",
       " [7, 23],\n",
       " [23, 7],\n",
       " [7, 24],\n",
       " [24, 7],\n",
       " [7, 25],\n",
       " [25, 7],\n",
       " [7, 26],\n",
       " [26, 7],\n",
       " [8, 9],\n",
       " [9, 8],\n",
       " [8, 10],\n",
       " [10, 8],\n",
       " [8, 11],\n",
       " [11, 8],\n",
       " [8, 12],\n",
       " [12, 8],\n",
       " [8, 13],\n",
       " [13, 8],\n",
       " [8, 14],\n",
       " [14, 8],\n",
       " [8, 15],\n",
       " [15, 8],\n",
       " [8, 16],\n",
       " [16, 8],\n",
       " [8, 17],\n",
       " [17, 8],\n",
       " [8, 18],\n",
       " [18, 8],\n",
       " [8, 19],\n",
       " [19, 8],\n",
       " [8, 20],\n",
       " [20, 8],\n",
       " [8, 21],\n",
       " [21, 8],\n",
       " [8, 22],\n",
       " [22, 8],\n",
       " [8, 23],\n",
       " [23, 8],\n",
       " [8, 24],\n",
       " [24, 8],\n",
       " [8, 25],\n",
       " [25, 8],\n",
       " [8, 26],\n",
       " [26, 8],\n",
       " [9, 10],\n",
       " [10, 9],\n",
       " [9, 11],\n",
       " [11, 9],\n",
       " [9, 12],\n",
       " [12, 9],\n",
       " [9, 13],\n",
       " [13, 9],\n",
       " [9, 14],\n",
       " [14, 9],\n",
       " [9, 15],\n",
       " [15, 9],\n",
       " [9, 16],\n",
       " [16, 9],\n",
       " [9, 17],\n",
       " [17, 9],\n",
       " [9, 18],\n",
       " [18, 9],\n",
       " [9, 19],\n",
       " [19, 9],\n",
       " [9, 20],\n",
       " [20, 9],\n",
       " [9, 21],\n",
       " [21, 9],\n",
       " [9, 22],\n",
       " [22, 9],\n",
       " [9, 23],\n",
       " [23, 9],\n",
       " [9, 24],\n",
       " [24, 9],\n",
       " [9, 25],\n",
       " [25, 9],\n",
       " [9, 26],\n",
       " [26, 9],\n",
       " [10, 11],\n",
       " [11, 10],\n",
       " [10, 12],\n",
       " [12, 10],\n",
       " [10, 13],\n",
       " [13, 10],\n",
       " [10, 14],\n",
       " [14, 10],\n",
       " [10, 15],\n",
       " [15, 10],\n",
       " [10, 16],\n",
       " [16, 10],\n",
       " [10, 17],\n",
       " [17, 10],\n",
       " [10, 18],\n",
       " [18, 10],\n",
       " [10, 19],\n",
       " [19, 10],\n",
       " [10, 20],\n",
       " [20, 10],\n",
       " [10, 21],\n",
       " [21, 10],\n",
       " [10, 22],\n",
       " [22, 10],\n",
       " [10, 23],\n",
       " [23, 10],\n",
       " [10, 24],\n",
       " [24, 10],\n",
       " [10, 25],\n",
       " [25, 10],\n",
       " [10, 26],\n",
       " [26, 10],\n",
       " [11, 12],\n",
       " [12, 11],\n",
       " [11, 13],\n",
       " [13, 11],\n",
       " [11, 14],\n",
       " [14, 11],\n",
       " [11, 15],\n",
       " [15, 11],\n",
       " [11, 16],\n",
       " [16, 11],\n",
       " [11, 17],\n",
       " [17, 11],\n",
       " [11, 18],\n",
       " [18, 11],\n",
       " [11, 19],\n",
       " [19, 11],\n",
       " [11, 20],\n",
       " [20, 11],\n",
       " [11, 21],\n",
       " [21, 11],\n",
       " [11, 22],\n",
       " [22, 11],\n",
       " [11, 23],\n",
       " [23, 11],\n",
       " [11, 24],\n",
       " [24, 11],\n",
       " [11, 25],\n",
       " [25, 11],\n",
       " [11, 26],\n",
       " [26, 11],\n",
       " [12, 13],\n",
       " [13, 12],\n",
       " [12, 14],\n",
       " [14, 12],\n",
       " [12, 15],\n",
       " [15, 12],\n",
       " [12, 16],\n",
       " [16, 12],\n",
       " [12, 17],\n",
       " [17, 12],\n",
       " [12, 18],\n",
       " [18, 12],\n",
       " [12, 19],\n",
       " [19, 12],\n",
       " [12, 20],\n",
       " [20, 12],\n",
       " [12, 21],\n",
       " [21, 12],\n",
       " [12, 22],\n",
       " [22, 12],\n",
       " [12, 23],\n",
       " [23, 12],\n",
       " [12, 24],\n",
       " [24, 12],\n",
       " [12, 25],\n",
       " [25, 12],\n",
       " [12, 26],\n",
       " [26, 12],\n",
       " [13, 14],\n",
       " [14, 13],\n",
       " [13, 15],\n",
       " [15, 13],\n",
       " [13, 16],\n",
       " [16, 13],\n",
       " [13, 17],\n",
       " [17, 13],\n",
       " [13, 18],\n",
       " [18, 13],\n",
       " [13, 19],\n",
       " [19, 13],\n",
       " [13, 20],\n",
       " [20, 13],\n",
       " [13, 21],\n",
       " [21, 13],\n",
       " [13, 22],\n",
       " [22, 13],\n",
       " [13, 23],\n",
       " [23, 13],\n",
       " [13, 24],\n",
       " [24, 13],\n",
       " [13, 25],\n",
       " [25, 13],\n",
       " [13, 26],\n",
       " [26, 13],\n",
       " [14, 15],\n",
       " [15, 14],\n",
       " [14, 16],\n",
       " [16, 14],\n",
       " [14, 17],\n",
       " [17, 14],\n",
       " [14, 18],\n",
       " [18, 14],\n",
       " [14, 19],\n",
       " [19, 14],\n",
       " [14, 20],\n",
       " [20, 14],\n",
       " [14, 21],\n",
       " [21, 14],\n",
       " [14, 22],\n",
       " [22, 14],\n",
       " [14, 23],\n",
       " [23, 14],\n",
       " [14, 24],\n",
       " [24, 14],\n",
       " [14, 25],\n",
       " [25, 14],\n",
       " [14, 26],\n",
       " [26, 14],\n",
       " [15, 16],\n",
       " [16, 15],\n",
       " [15, 17],\n",
       " [17, 15],\n",
       " [15, 18],\n",
       " [18, 15],\n",
       " [15, 19],\n",
       " [19, 15],\n",
       " [15, 20],\n",
       " [20, 15],\n",
       " [15, 21],\n",
       " [21, 15],\n",
       " [15, 22],\n",
       " [22, 15],\n",
       " [15, 23],\n",
       " [23, 15],\n",
       " [15, 24],\n",
       " [24, 15],\n",
       " [15, 25],\n",
       " [25, 15],\n",
       " [15, 26],\n",
       " [26, 15],\n",
       " [16, 17],\n",
       " [17, 16],\n",
       " [16, 18],\n",
       " [18, 16],\n",
       " [16, 19],\n",
       " [19, 16],\n",
       " [16, 20],\n",
       " [20, 16],\n",
       " [16, 21],\n",
       " [21, 16],\n",
       " [16, 22],\n",
       " [22, 16],\n",
       " [16, 23],\n",
       " [23, 16],\n",
       " [16, 24],\n",
       " [24, 16],\n",
       " [16, 25],\n",
       " [25, 16],\n",
       " [16, 26],\n",
       " [26, 16],\n",
       " [17, 18],\n",
       " [18, 17],\n",
       " [17, 19],\n",
       " [19, 17],\n",
       " [17, 20],\n",
       " [20, 17],\n",
       " [17, 21],\n",
       " [21, 17],\n",
       " [17, 22],\n",
       " [22, 17],\n",
       " [17, 23],\n",
       " [23, 17],\n",
       " [17, 24],\n",
       " [24, 17],\n",
       " [17, 25],\n",
       " [25, 17],\n",
       " [17, 26],\n",
       " [26, 17],\n",
       " [18, 19],\n",
       " [19, 18],\n",
       " [18, 20],\n",
       " [20, 18],\n",
       " [18, 21],\n",
       " [21, 18],\n",
       " [18, 22],\n",
       " [22, 18],\n",
       " [18, 23],\n",
       " [23, 18],\n",
       " [18, 24],\n",
       " [24, 18],\n",
       " [18, 25],\n",
       " [25, 18],\n",
       " [18, 26],\n",
       " [26, 18],\n",
       " [19, 20],\n",
       " [20, 19],\n",
       " [19, 21],\n",
       " [21, 19],\n",
       " [19, 22],\n",
       " [22, 19],\n",
       " [19, 23],\n",
       " [23, 19],\n",
       " [19, 24],\n",
       " [24, 19],\n",
       " [19, 25],\n",
       " [25, 19],\n",
       " [19, 26],\n",
       " [26, 19],\n",
       " [20, 21],\n",
       " [21, 20],\n",
       " [20, 22],\n",
       " [22, 20],\n",
       " [20, 23],\n",
       " [23, 20],\n",
       " [20, 24],\n",
       " [24, 20],\n",
       " [20, 25],\n",
       " [25, 20],\n",
       " [20, 26],\n",
       " [26, 20],\n",
       " [21, 22],\n",
       " [22, 21],\n",
       " [21, 23],\n",
       " [23, 21],\n",
       " [21, 24],\n",
       " [24, 21],\n",
       " [21, 25],\n",
       " [25, 21],\n",
       " [21, 26],\n",
       " [26, 21],\n",
       " [22, 23],\n",
       " [23, 22],\n",
       " [22, 24],\n",
       " [24, 22],\n",
       " [22, 25],\n",
       " [25, 22],\n",
       " [22, 26],\n",
       " [26, 22],\n",
       " [23, 24],\n",
       " [24, 23],\n",
       " [23, 25],\n",
       " [25, 23],\n",
       " [23, 26],\n",
       " [26, 23],\n",
       " [24, 25],\n",
       " [25, 24],\n",
       " [24, 26],\n",
       " [26, 24],\n",
       " [25, 26],\n",
       " [26, 25]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_edge_index(dataframes):\n",
    "    edges = []\n",
    "    edges_verifications = []\n",
    "    keys = list(dataframes.keys())\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i + 1, len(keys)):\n",
    "            if i != j:\n",
    "                edges.append(([i, j]))\n",
    "                edges.append(([j, i]))\n",
    "                edges_verifications.append(([keys[i],keys[j],i, j]))\n",
    "                edges_verifications.append(([keys[j],keys[i],j, i]))\n",
    "    display(edges_verifications)\n",
    "    return edges\n",
    "\n",
    "edge_index = create_edge_index(dataframes)\n",
    "display(edge_index)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[72790024141, 72785524114, 0, 1, 395.4679457314314],\n",
       " [72785524114, 72790024141, 1, 0, 395.4679457314314],\n",
       " [72790024141, 72789094197, 0, 2, 129.15783117310457],\n",
       " [72789094197, 72790024141, 2, 0, 129.15783117310457],\n",
       " [72790024141, 72793024233, 0, 3, 342.5330553210191],\n",
       " [72793024233, 72790024141, 3, 0, 342.5330553210191],\n",
       " [72790024141, 72785794129, 0, 4, 438.10430559873856],\n",
       " [72785794129, 72790024141, 4, 0, 438.10430559873856],\n",
       " [72790024141, 72788594266, 0, 5, 432.0504921333856],\n",
       " [72788594266, 72790024141, 5, 0, 432.0504921333856],\n",
       " [72790024141, 72797624217, 0, 6, 437.11321302131137],\n",
       " [72797624217, 72790024141, 6, 0, 437.11321302131137],\n",
       " [72790024141, 72785024157, 0, 7, 369.0087247919059],\n",
       " [72785024157, 72790024141, 7, 0, 369.0087247919059],\n",
       " [72790024141, 72797094240, 0, 8, 503.7031148557305],\n",
       " [72797094240, 72790024141, 8, 0, 503.7031148557305],\n",
       " [72790024141, 72798594276, 0, 9, 455.6811328123654],\n",
       " [72798594276, 72790024141, 9, 0, 455.6811328123654],\n",
       " [72790024141, 72792424223, 0, 10, 474.59654599988056],\n",
       " [72792424223, 72790024141, 10, 0, 474.59654599988056],\n",
       " [72790024141, 72792894263, 0, 11, 348.0950737502581],\n",
       " [72792894263, 72790024141, 11, 0, 348.0950737502581],\n",
       " [72790024141, 72781024243, 0, 12, 128.6980383337319],\n",
       " [72781024243, 72790024141, 12, 0, 128.6980383337319],\n",
       " [72790024141, 72781524237, 0, 13, 835.9738346074198],\n",
       " [72781524237, 72790024141, 13, 0, 835.9738346074198],\n",
       " [72790024141, 72788324220, 0, 14, 171.59537540199554],\n",
       " [72788324220, 72790024141, 14, 0, 171.59537540199554],\n",
       " [72790024141, 72698824219, 0, 15, 384.56540064951065],\n",
       " [72698824219, 72790024141, 15, 0, 384.56540064951065],\n",
       " [72790024141, 72793894274, 0, 16, 373.58764051749137],\n",
       " [72793894274, 72790024141, 16, 0, 373.58764051749137],\n",
       " [72790024141, 74206024207, 0, 17, 362.1843030623904],\n",
       " [74206024207, 72790024141, 17, 0, 362.1843030623904],\n",
       " [72790024141, 72782724110, 0, 18, 32.53657446575969],\n",
       " [72782724110, 72790024141, 18, 0, 32.53657446575969],\n",
       " [72790024141, 72793724222, 0, 19, 306.4908073667999],\n",
       " [72793724222, 72790024141, 19, 0, 306.4908073667999],\n",
       " [72790024141, 72792594227, 0, 20, 404.50991220772727],\n",
       " [72792594227, 72790024141, 20, 0, 404.50991220772727],\n",
       " [72790024141, 72782594239, 0, 21, 52.81240627430448],\n",
       " [72782594239, 72790024141, 21, 0, 52.81240627430448],\n",
       " [72790024141, 72794504205, 0, 22, 404.8085057270694],\n",
       " [72794504205, 72790024141, 22, 0, 404.8085057270694],\n",
       " [72790024141, 72792394225, 0, 23, 505.4288197147213],\n",
       " [72792394225, 72790024141, 23, 0, 505.4288197147213],\n",
       " [72790024141, 72784524163, 0, 24, 286.0836462058196],\n",
       " [72784524163, 72790024141, 24, 0, 286.0836462058196],\n",
       " [72790024141, 72792024227, 0, 25, 412.6227567328569],\n",
       " [72792024227, 72790024141, 25, 0, 412.6227567328569],\n",
       " [72790024141, 72785694176, 0, 26, 272.19719043646785],\n",
       " [72785694176, 72790024141, 26, 0, 272.19719043646785],\n",
       " [72785524114, 72789094197, 1, 2, 390.14029117618804],\n",
       " [72789094197, 72785524114, 2, 1, 390.14029117618804],\n",
       " [72785524114, 72793024233, 1, 3, 727.6917541369755],\n",
       " [72793024233, 72785524114, 3, 1, 727.6917541369755],\n",
       " [72785524114, 72785794129, 1, 4, 109.85904921372176],\n",
       " [72785794129, 72785524114, 4, 1, 109.85904921372176],\n",
       " [72785524114, 72788594266, 1, 5, 798.995937782049],\n",
       " [72788594266, 72785524114, 5, 1, 798.995937782049],\n",
       " [72785524114, 72797624217, 1, 6, 802.4581375032445],\n",
       " [72797624217, 72785524114, 6, 1, 802.4581375032445],\n",
       " [72785524114, 72785024157, 1, 7, 33.690956835057186],\n",
       " [72785024157, 72785524114, 7, 1, 33.690956835057186],\n",
       " [72785524114, 72797094240, 1, 8, 865.1737430163511],\n",
       " [72797094240, 72785524114, 8, 1, 865.1737430163511],\n",
       " [72785524114, 72798594276, 1, 9, 825.6499844120128],\n",
       " [72798594276, 72785524114, 9, 1, 825.6499844120128],\n",
       " [72785524114, 72792424223, 1, 10, 860.6728795779842],\n",
       " [72792424223, 72785524114, 10, 1, 860.6728795779842],\n",
       " [72785524114, 72792894263, 1, 11, 724.9963923066945],\n",
       " [72792894263, 72785524114, 11, 1, 724.9963923066945],\n",
       " [72785524114, 72781024243, 1, 12, 495.92270395996894],\n",
       " [72781024243, 72785524114, 12, 1, 495.92270395996894],\n",
       " [72785524114, 72781524237, 1, 13, 535.6266022869553],\n",
       " [72781524237, 72785524114, 13, 1, 535.6266022869553],\n",
       " [72785524114, 72788324220, 1, 14, 314.54161595295784],\n",
       " [72788324220, 72785524114, 14, 1, 314.54161595295784],\n",
       " [72785524114, 72698824219, 1, 15, 763.6141112163369],\n",
       " [72698824219, 72785524114, 15, 1, 763.6141112163369],\n",
       " [72785524114, 72793894274, 1, 16, 759.3841400612968],\n",
       " [72793894274, 72785524114, 16, 1, 759.3841400612968],\n",
       " [72785524114, 74206024207, 1, 17, 748.5486591666476],\n",
       " [74206024207, 72785524114, 17, 1, 748.5486591666476],\n",
       " [72785524114, 72782724110, 1, 18, 416.12981588895354],\n",
       " [72782724110, 72785524114, 18, 1, 416.12981588895354],\n",
       " [72785524114, 72793724222, 1, 19, 678.7815012654146],\n",
       " [72793724222, 72785524114, 19, 1, 678.7815012654146],\n",
       " [72785524114, 72792594227, 1, 20, 784.7770299622911],\n",
       " [72792594227, 72785524114, 20, 1, 784.7770299622911],\n",
       " [72785524114, 72782594239, 1, 21, 419.79175595055284],\n",
       " [72782594239, 72785524114, 21, 1, 419.79175595055284],\n",
       " [72785524114, 72794504205, 1, 22, 786.18443118649],\n",
       " [72794504205, 72785524114, 22, 1, 786.18443118649],\n",
       " [72785524114, 72792394225, 1, 23, 886.2658783050533],\n",
       " [72792394225, 72785524114, 23, 1, 886.2658783050533],\n",
       " [72785524114, 72784524163, 1, 24, 655.5895444605051],\n",
       " [72784524163, 72785524114, 24, 1, 655.5895444605051],\n",
       " [72785524114, 72792024227, 1, 25, 798.318691116012],\n",
       " [72792024227, 72785524114, 25, 1, 798.318691116012],\n",
       " [72785524114, 72785694176, 1, 26, 157.5431429141368],\n",
       " [72785694176, 72785524114, 26, 1, 157.5431429141368],\n",
       " [72789094197, 72793024233, 2, 3, 370.42190175405364],\n",
       " [72793024233, 72789094197, 3, 2, 370.42190175405364],\n",
       " [72789094197, 72785794129, 2, 4, 460.5219705003162],\n",
       " [72785794129, 72789094197, 4, 2, 460.5219705003162],\n",
       " [72789094197, 72788594266, 2, 5, 432.51979230044606],\n",
       " [72788594266, 72789094197, 5, 2, 432.51979230044606],\n",
       " [72789094197, 72797624217, 2, 6, 417.3828379309705],\n",
       " [72797624217, 72789094197, 6, 2, 417.3828379309705],\n",
       " [72789094197, 72785024157, 2, 7, 365.04041085309774],\n",
       " [72785024157, 72789094197, 7, 2, 365.04041085309774],\n",
       " [72789094197, 72797094240, 2, 8, 508.89691489063597],\n",
       " [72797094240, 72789094197, 8, 2, 508.89691489063597],\n",
       " [72789094197, 72798594276, 2, 9, 445.736559884783],\n",
       " [72798594276, 72789094197, 9, 2, 445.736559884783],\n",
       " [72789094197, 72792424223, 2, 10, 534.5520542530354],\n",
       " [72792424223, 72789094197, 10, 2, 534.5520542530354],\n",
       " [72789094197, 72792894263, 2, 11, 372.6745336577991],\n",
       " [72792894263, 72789094197, 11, 2, 372.6745336577991],\n",
       " [72789094197, 72781024243, 2, 12, 236.9285970548754],\n",
       " [72781024243, 72789094197, 12, 2, 236.9285970548754],\n",
       " [72789094197, 72781524237, 2, 13, 831.0617187024466],\n",
       " [72781524237, 72789094197, 13, 2, 831.0617187024466],\n",
       " [72789094197, 72788324220, 2, 14, 221.69557651346355],\n",
       " [72788324220, 72789094197, 14, 2, 221.69557651346355],\n",
       " [72789094197, 72698824219, 2, 15, 470.9577296531585],\n",
       " [72698824219, 72789094197, 15, 2, 470.9577296531585],\n",
       " [72789094197, 72793894274, 2, 16, 406.24280451088293],\n",
       " [72793894274, 72789094197, 16, 2, 406.24280451088293],\n",
       " [72789094197, 74206024207, 2, 17, 399.71114545506987],\n",
       " [74206024207, 72789094197, 17, 2, 399.71114545506987],\n",
       " [72789094197, 72782724110, 2, 18, 147.68778122386612],\n",
       " [72782724110, 72789094197, 18, 2, 147.68778122386612],\n",
       " [72789094197, 72793724222, 2, 19, 313.8982068438734],\n",
       " [72793724222, 72789094197, 19, 2, 313.8982068438734],\n",
       " [72789094197, 72792594227, 2, 20, 435.3656912848407],\n",
       " [72792594227, 72789094197, 20, 2, 435.3656912848407],\n",
       " [72789094197, 72782594239, 2, 21, 130.20708355028395],\n",
       " [72782594239, 72789094197, 21, 2, 130.20708355028395],\n",
       " [72789094197, 72794504205, 2, 22, 406.9699486305622],\n",
       " [72794504205, 72789094197, 22, 2, 406.9699486305622],\n",
       " [72789094197, 72792394225, 2, 23, 539.0132078425393],\n",
       " [72792394225, 72789094197, 23, 2, 539.0132078425393],\n",
       " [72789094197, 72784524163, 2, 24, 368.91523621650714],\n",
       " [72784524163, 72789094197, 24, 2, 368.91523621650714],\n",
       " [72789094197, 72792024227, 2, 25, 452.3832910640423],\n",
       " [72792024227, 72789094197, 25, 2, 452.3832910640423],\n",
       " [72789094197, 72785694176, 2, 26, 270.2281521689557],\n",
       " [72785694176, 72789094197, 26, 2, 270.2281521689557],\n",
       " [72793024233, 72785794129, 3, 4, 775.0588941479449],\n",
       " [72785794129, 72793024233, 4, 3, 775.0588941479449],\n",
       " [72793024233, 72788594266, 3, 5, 120.26611512741678],\n",
       " [72788594266, 72793024233, 5, 3, 120.26611512741678],\n",
       " [72793024233, 72797624217, 3, 6, 165.52848353942377],\n",
       " [72797624217, 72793024233, 6, 3, 165.52848353942377],\n",
       " [72793024233, 72785024157, 3, 7, 704.0879836514051],\n",
       " [72785024157, 72793024233, 7, 3, 704.0879836514051],\n",
       " [72793024233, 72797094240, 3, 8, 185.28412975619443],\n",
       " [72797094240, 72793024233, 8, 3, 185.28412975619443],\n",
       " [72793024233, 72798594276, 3, 9, 152.43166309928537],\n",
       " [72798594276, 72793024233, 9, 3, 152.43166309928537],\n",
       " [72793024233, 72792424223, 3, 10, 187.27787071696568],\n",
       " [72792424223, 72793024233, 10, 3, 187.27787071696568],\n",
       " [72793024233, 72792894263, 3, 11, 41.159846544112625],\n",
       " [72792894263, 72793024233, 11, 3, 41.159846544112625],\n",
       " [72793024233, 72781024243, 3, 12, 266.9618608270944],\n",
       " [72781024243, 72793024233, 12, 3, 266.9618608270944],\n",
       " [72793024233, 72781524237, 3, 13, 1096.8318771247875],\n",
       " [72781524237, 72793024233, 13, 3, 1096.8318771247875],\n",
       " [72793024233, 72788324220, 3, 14, 443.4038293955239],\n",
       " [72788324220, 72793024233, 14, 3, 443.4038293955239],\n",
       " [72793024233, 72698824219, 3, 15, 225.02216925780087],\n",
       " [72698824219, 72793024233, 15, 3, 225.02216925780087],\n",
       " [72793024233, 72793894274, 3, 16, 36.85266364881154],\n",
       " [72793894274, 72793024233, 16, 3, 36.85266364881154],\n",
       " [72793024233, 74206024207, 3, 17, 37.9895765777111],\n",
       " [74206024207, 72793024233, 17, 3, 37.9895765777111],\n",
       " [72793024233, 72782724110, 3, 18, 333.6917238582668],\n",
       " [72782724110, 72793024233, 18, 3, 333.6917238582668],\n",
       " [72793024233, 72793724222, 3, 19, 76.27723241526142],\n",
       " [72793724222, 72793024233, 19, 3, 76.27723241526142],\n",
       " [72793024233, 72792594227, 3, 20, 72.18185980856553],\n",
       " [72792594227, 72793024233, 20, 3, 72.18185980856553],\n",
       " [72793024233, 72782594239, 3, 21, 309.0749255571238],\n",
       " [72782594239, 72793024233, 21, 3, 309.0749255571238],\n",
       " [72793024233, 72794504205, 3, 22, 107.09860018045799],\n",
       " [72794504205, 72793024233, 22, 3, 107.09860018045799],\n",
       " [72793024233, 72792394225, 3, 23, 171.23674671831446],\n",
       " [72792394225, 72793024233, 23, 3, 171.23674671831446],\n",
       " [72793024233, 72784524163, 3, 24, 276.0731537992283],\n",
       " [72784524163, 72793024233, 24, 3, 276.0731537992283],\n",
       " [72793024233, 72792024227, 3, 25, 85.99186556469607],\n",
       " [72792024227, 72793024233, 25, 3, 85.99186556469607],\n",
       " [72793024233, 72785694176, 3, 26, 611.0889227645558],\n",
       " [72785694176, 72793024233, 26, 3, 611.0889227645558],\n",
       " [72785794129, 72788594266, 4, 5, 856.701667766572],\n",
       " [72788594266, 72785794129, 5, 4, 856.701667766572],\n",
       " [72785794129, 72797624217, 4, 6, 865.4792367557994],\n",
       " [72797624217, 72785794129, 6, 4, 865.4792367557994],\n",
       " [72785794129, 72785024157, 4, 7, 117.74480456011335],\n",
       " [72785024157, 72785794129, 7, 4, 117.74480456011335],\n",
       " [72785794129, 72797094240, 4, 8, 921.4842980890041],\n",
       " [72797094240, 72785794129, 8, 4, 921.4842980890041],\n",
       " [72785794129, 72798594276, 4, 9, 885.9031028312606],\n",
       " [72798594276, 72785794129, 9, 4, 885.9031028312606],\n",
       " [72785794129, 72792424223, 4, 10, 890.5893542480043],\n",
       " [72792424223, 72785794129, 10, 4, 890.5893542480043],\n",
       " [72785794129, 72792894263, 4, 11, 774.366157782777],\n",
       " [72792894263, 72785794129, 11, 4, 774.366157782777],\n",
       " [72785794129, 72781024243, 4, 12, 524.6337306289196],\n",
       " [72781024243, 72785794129, 12, 4, 524.6337306289196],\n",
       " [72785794129, 72781524237, 4, 13, 540.0809528724242],\n",
       " [72781524237, 72785794129, 13, 4, 540.0809528724242],\n",
       " [72785794129, 72788324220, 4, 14, 357.13279391570444],\n",
       " [72788324220, 72785794129, 14, 4, 357.13279391570444],\n",
       " [72785794129, 72698824219, 4, 15, 780.4774458332262],\n",
       " [72698824219, 72785794129, 15, 4, 780.4774458332262],\n",
       " [72785794129, 72793894274, 4, 16, 804.444912957628],\n",
       " [72793894274, 72785794129, 16, 4, 804.444912957628],\n",
       " [72785794129, 74206024207, 4, 17, 791.9148221844617],\n",
       " [74206024207, 72785794129, 17, 4, 791.9148221844617],\n",
       " [72785794129, 72782724110, 4, 18, 454.1201925958629],\n",
       " [72782724110, 72785794129, 18, 4, 454.1201925958629],\n",
       " [72785794129, 72793724222, 4, 19, 734.2694292819892],\n",
       " [72793724222, 72785794129, 19, 4, 734.2694292819892],\n",
       " [72785794129, 72792594227, 4, 20, 830.6418814848106],\n",
       " [72792594227, 72785794129, 20, 4, 830.6418814848106],\n",
       " [72785794129, 72782594239, 4, 21, 467.37603414879794],\n",
       " [72782594239, 72785794129, 21, 4, 467.37603414879794],\n",
       " [72785794129, 72794504205, 4, 22, 840.9110561664348],\n",
       " [72794504205, 72785794129, 22, 4, 840.9110561664348],\n",
       " [72785794129, 72792394225, 4, 23, 929.3740741921883],\n",
       " [72792394225, 72785794129, 23, 4, 929.3740741921883],\n",
       " [72785794129, 72784524163, 4, 24, 673.3913688173589],\n",
       " [72784524163, 72785794129, 24, 4, 673.3913688173589],\n",
       " [72785794129, 72792024227, 4, 25, 839.7968409183139],\n",
       " [72792024227, 72785794129, 25, 4, 839.7968409183139],\n",
       " [72785794129, 72785694176, 4, 26, 209.78499150005845],\n",
       " [72785694176, 72785794129, 26, 4, 209.78499150005845],\n",
       " [72788594266, 72797624217, 5, 6, 110.15242913456197],\n",
       " [72797624217, 72788594266, 6, 5, 110.15242913456197],\n",
       " [72788594266, 72785024157, 5, 7, 777.4585937545535],\n",
       " [72785024157, 72788594266, 7, 5, 777.4585937545535],\n",
       " [72788594266, 72797094240, 5, 8, 85.13925057078639],\n",
       " [72797094240, 72788594266, 8, 5, 85.13925057078639],\n",
       " [72788594266, 72798594276, 5, 9, 74.97130998219406],\n",
       " [72798594276, 72788594266, 9, 5, 74.97130998219406],\n",
       " [72788594266, 72792424223, 5, 10, 240.43942234567194],\n",
       " [72792424223, 72788594266, 10, 5, 240.43942234567194],\n",
       " [72788594266, 72792894263, 5, 11, 103.9757703201679],\n",
       " [72792894263, 72788594266, 11, 5, 103.9757703201679],\n",
       " [72788594266, 72781024243, 5, 12, 369.69695959787833],\n",
       " [72781024243, 72788594266, 12, 5, 369.69695959787833],\n",
       " [72788594266, 72781524237, 5, 13, 1139.0521959187856],\n",
       " [72781524237, 72788594266, 13, 5, 1139.0521959187856],\n",
       " [72788594266, 72788324220, 5, 14, 516.0490346912795],\n",
       " [72788324220, 72788594266, 14, 5, 516.0490346912795],\n",
       " [72788594266, 72698824219, 5, 15, 330.5216959336131],\n",
       " [72698824219, 72788594266, 15, 5, 330.5216959336131],\n",
       " [72788594266, 72793894274, 5, 16, 117.91278236100351],\n",
       " [72793894274, 72788594266, 16, 5, 117.91278236100351],\n",
       " [72788594266, 74206024207, 5, 17, 133.34207595548997],\n",
       " [74206024207, 72788594266, 17, 5, 133.34207595548997],\n",
       " [72788594266, 72782724110, 5, 18, 428.7153028579556],\n",
       " [72782724110, 72788594266, 18, 5, 428.7153028579556],\n",
       " [72788594266, 72793724222, 5, 19, 125.7282441840991],\n",
       " [72793724222, 72788594266, 19, 5, 125.7282441840991],\n",
       " [72788594266, 72792594227, 5, 20, 101.97987733596389],\n",
       " [72792594227, 72788594266, 20, 5, 101.97987733596389],\n",
       " [72788594266, 72782594239, 5, 21, 392.60154297249403],\n",
       " [72782594239, 72788594266, 21, 5, 392.60154297249403],\n",
       " [72788594266, 72794504205, 5, 22, 108.31645122446824],\n",
       " [72794504205, 72788594266, 22, 5, 108.31645122446824],\n",
       " [72788594266, 72792394225, 5, 23, 153.40108385187867],\n",
       " [72792394225, 72788594266, 23, 5, 153.40108385187867],\n",
       " [72788594266, 72784524163, 5, 24, 392.1898886399527],\n",
       " [72784524163, 72788594266, 24, 5, 392.1898886399527],\n",
       " [72788594266, 72792024227, 5, 25, 137.25092367847324],\n",
       " [72792024227, 72788594266, 25, 5, 137.25092367847324],\n",
       " [72788594266, 72785694176, 5, 26, 690.174750212649],\n",
       " [72785694176, 72788594266, 26, 5, 690.174750212649],\n",
       " [72797624217, 72785024157, 6, 7, 778.6874797868297],\n",
       " [72785024157, 72797624217, 7, 6, 778.6874797868297],\n",
       " [72797624217, 72797094240, 6, 8, 177.46961023734613],\n",
       " [72797094240, 72797624217, 8, 6, 177.46961023734613],\n",
       " [72797624217, 72798594276, 6, 9, 48.71149879169117],\n",
       " [72798594276, 72797624217, 9, 6, 48.71149879169117],\n",
       " [72797624217, 72792424223, 6, 10, 302.0846527899822],\n",
       " [72792424223, 72797624217, 10, 6, 302.0846527899822],\n",
       " [72797624217, 72792894263, 6, 11, 172.27646695285324],\n",
       " [72792894263, 72797624217, 11, 6, 172.27646695285324],\n",
       " [72797624217, 72781024243, 6, 12, 399.97805818217563],\n",
       " [72781024243, 72797624217, 12, 6, 399.97805818217563],\n",
       " [72797624217, 72781524237, 6, 13, 1176.4852153080844],\n",
       " [72781524237, 72797624217, 13, 6, 1176.4852153080844],\n",
       " [72797624217, 72788324220, 6, 14, 545.6427005439592],\n",
       " [72788324220, 72797624217, 14, 6, 545.6427005439592],\n",
       " [72797624217, 72698824219, 6, 15, 369.3977887607593],\n",
       " [72698824219, 72797624217, 15, 6, 369.3977887607593],\n",
       " [72797624217, 72793894274, 6, 16, 175.55537172802033],\n",
       " [72793894274, 72797624217, 16, 6, 175.55537172802033],\n",
       " [72797624217, 74206024207, 6, 17, 190.70446482220075],\n",
       " [74206024207, 72797624217, 17, 6, 190.70446482220075],\n",
       " [72797624217, 72782724110, 6, 18, 431.096161984872],\n",
       " [72782724110, 72797624217, 18, 6, 431.096161984872],\n",
       " [72797624217, 72793724222, 6, 19, 156.64330089805705],\n",
       " [72793724222, 72797624217, 19, 6, 156.64330089805705],\n",
       " [72797624217, 72792594227, 6, 20, 183.24573042058552],\n",
       " [72792594227, 72797624217, 20, 6, 183.24573042058552],\n",
       " [72797624217, 72782594239, 6, 21, 405.4909815288361],\n",
       " [72782594239, 72797624217, 21, 6, 405.4909815288361],\n",
       " [72797624217, 72794504205, 6, 22, 76.4859126118275],\n",
       " [72794504205, 72797624217, 22, 6, 76.4859126118275],\n",
       " [72797624217, 72792394225, 6, 23, 231.7098185991757],\n",
       " [72792394225, 72797624217, 23, 6, 231.7098185991757],\n",
       " [72797624217, 72784524163, 6, 24, 388.4359336032824],\n",
       " [72784524163, 72797624217, 24, 6, 388.4359336032824],\n",
       " [72797624217, 72792024227, 6, 25, 205.33116784821942],\n",
       " [72792024227, 72797624217, 25, 6, 205.33116784821942],\n",
       " [72797624217, 72785694176, 6, 26, 682.4260680955291],\n",
       " [72785694176, 72797624217, 26, 6, 682.4260680955291],\n",
       " [72785024157, 72797094240, 7, 8, 845.1366146343045],\n",
       " [72797094240, 72785024157, 8, 7, 845.1366146343045],\n",
       " [72785024157, 72798594276, 7, 9, 802.4776134962176],\n",
       " [72798594276, 72785024157, 9, 7, 802.4776134962176],\n",
       " [72785024157, 72792424223, 7, 10, 837.0612376685274],\n",
       " [72792424223, 72785024157, 10, 7, 837.0612376685274],\n",
       " [72785024157, 72792894263, 7, 11, 702.8044715545802],\n",
       " [72792894263, 72785024157, 11, 7, 702.8044715545802],\n",
       " [72785024157, 72781024243, 7, 12, 472.23598917705993],\n",
       " [72781024243, 72785024157, 12, 7, 472.23598917705993],\n",
       " [72785024157, 72781524237, 7, 13, 567.9966156275789],\n",
       " [72781524237, 72785024157, 13, 7, 567.9966156275789],\n",
       " [72785024157, 72788324220, 7, 14, 299.672336109386],\n",
       " [72788324220, 72785024157, 14, 7, 299.672336109386],\n",
       " [72785024157, 72698824219, 7, 15, 738.0303386253106],\n",
       " [72698824219, 72785024157, 15, 7, 738.0303386253106],\n",
       " [72785024157, 72793894274, 7, 16, 735.9632694864449],\n",
       " [72793894274, 72785024157, 16, 7, 735.9632694864449],\n",
       " [72785024157, 74206024207, 7, 17, 725.1092500944276],\n",
       " [74206024207, 72785024157, 17, 7, 725.1092500944276],\n",
       " [72785024157, 72782724110, 7, 18, 388.53428759844127],\n",
       " [72782724110, 72785024157, 18, 7, 388.53428759844127],\n",
       " [72785024157, 72793724222, 7, 19, 656.1420174916371],\n",
       " [72793724222, 72785024157, 19, 7, 656.1420174916371],\n",
       " [72785024157, 72792594227, 7, 20, 762.4710980022056],\n",
       " [72792594227, 72785024157, 20, 7, 762.4710980022056],\n",
       " [72785024157, 72782594239, 7, 21, 395.81370216605853],\n",
       " [72782594239, 72785024157, 21, 7, 395.81370216605853],\n",
       " [72785024157, 72794504205, 7, 22, 761.3237576215986],\n",
       " [72794504205, 72785024157, 22, 7, 761.3237576215986],\n",
       " [72785024157, 72792394225, 7, 23, 864.2082908552868],\n",
       " [72792394225, 72785024157, 23, 7, 864.2082908552868],\n",
       " [72785024157, 72784524163, 7, 24, 626.0309963149288],\n",
       " [72784524163, 72785024157, 24, 7, 626.0309963149288],\n",
       " [72785024157, 72792024227, 7, 25, 775.1913077729471],\n",
       " [72792024227, 72785024157, 25, 7, 775.1913077729471],\n",
       " [72785024157, 72785694176, 7, 26, 124.27275180830249],\n",
       " [72785694176, 72785024157, 26, 7, 124.27275180830249],\n",
       " [72797094240, 72798594276, 8, 9, 132.5097212349861],\n",
       " [72798594276, 72797094240, 9, 8, 132.5097212349861],\n",
       " [72797094240, 72792424223, 8, 10, 243.7073144688935],\n",
       " [72792424223, 72797094240, 10, 8, 243.7073144688935],\n",
       " [72797094240, 72792894263, 8, 11, 163.47287592761103],\n",
       " [72792894263, 72797094240, 11, 8, 163.47287592761103],\n",
       " [72797094240, 72781024243, 8, 12, 430.6615227573649],\n",
       " [72781024243, 72797094240, 12, 8, 430.6615227573649],\n",
       " [72797094240, 72781524237, 8, 13, 1177.64872286148],\n",
       " [72781524237, 72797094240, 13, 8, 1177.64872286148],\n",
       " [72797094240, 72788324220, 8, 14, 572.9402144031785],\n",
       " [72788324220, 72797094240, 14, 8, 572.9402144031785],\n",
       " [72797094240, 72698824219, 8, 15, 365.1202761234219],\n",
       " [72698824219, 72797094240, 15, 8, 365.1202761234219],\n",
       " [72797094240, 72793894274, 8, 16, 169.20923499165121],\n",
       " [72793894274, 72797094240, 16, 8, 169.20923499165121],\n",
       " [72797094240, 74206024207, 8, 17, 183.39281681071296],\n",
       " [74206024207, 72797094240, 17, 8, 183.39281681071296],\n",
       " [72797094240, 72782724110, 8, 18, 501.4584011725272],\n",
       " [72782724110, 72797094240, 18, 8, 501.4584011725272],\n",
       " [72797094240, 72793724222, 8, 19, 202.41419212127153],\n",
       " [72793724222, 72797094240, 19, 8, 202.41419212127153],\n",
       " [72797094240, 72792594227, 8, 20, 134.47678138943274],\n",
       " [72792594227, 72797094240, 20, 8, 134.47678138943274],\n",
       " [72797094240, 72782594239, 8, 21, 461.61393826175714],\n",
       " [72782594239, 72797094240, 21, 8, 461.61393826175714],\n",
       " [72797094240, 72794504205, 8, 22, 180.6112148305096],\n",
       " [72794504205, 72797094240, 22, 8, 180.6112148305096],\n",
       " [72797094240, 72792394225, 8, 23, 128.08708542091654],\n",
       " [72792394225, 72797094240, 23, 8, 128.08708542091654],\n",
       " [72797094240, 72784524163, 8, 24, 456.1447880245876],\n",
       " [72784524163, 72797094240, 24, 8, 456.1447880245876],\n",
       " [72797094240, 72792024227, 8, 25, 164.101942102309],\n",
       " [72792024227, 72797094240, 25, 8, 164.101942102309],\n",
       " [72797094240, 72785694176, 8, 26, 763.0321197403028],\n",
       " [72785694176, 72797094240, 26, 8, 763.0321197403028],\n",
       " [72798594276, 72792424223, 9, 10, 268.89465547374556],\n",
       " [72792424223, 72798594276, 10, 9, 268.89465547374556],\n",
       " [72798594276, 72792894263, 9, 11, 154.53742133091865],\n",
       " [72792894263, 72798594276, 11, 9, 154.53742133091865],\n",
       " [72798594276, 72781024243, 9, 12, 405.60664848136616],\n",
       " [72781024243, 72798594276, 12, 9, 405.60664848136616],\n",
       " [72798594276, 72781524237, 9, 13, 1187.3176896736784],\n",
       " [72781524237, 72798594276, 13, 9, 1187.3176896736784],\n",
       " [72798594276, 72788324220, 9, 14, 557.1020923327553],\n",
       " [72788324220, 72798594276, 14, 9, 557.1020923327553],\n",
       " [72798594276, 72698824219, 9, 15, 353.92282978101207],\n",
       " [72698824219, 72798594276, 15, 9, 353.92282978101207],\n",
       " [72798594276, 72793894274, 9, 16, 153.1723115228679],\n",
       " [72793894274, 72798594276, 16, 9, 153.1723115228679],\n",
       " [72798594276, 74206024207, 9, 17, 170.09372061722416],\n",
       " [74206024207, 72798594276, 17, 9, 170.09372061722416],\n",
       " [72798594276, 72782724110, 9, 18, 449.65266636740307],\n",
       " [72782724110, 72798594276, 18, 9, 449.65266636740307],\n",
       " [72798594276, 72793724222, 9, 19, 158.4233084920311],\n",
       " [72793724222, 72798594276, 19, 9, 158.4233084920311],\n",
       " [72798594276, 72792594227, 9, 20, 151.2637681156068],\n",
       " [72792594227, 72798594276, 20, 9, 151.2637681156068],\n",
       " [72798594276, 72782594239, 9, 21, 421.5198568724629],\n",
       " [72782594239, 72798594276, 21, 9, 421.5198568724629],\n",
       " [72798594276, 72794504205, 9, 22, 75.9354339763056],\n",
       " [72794504205, 72798594276, 22, 9, 75.9354339763056],\n",
       " [72798594276, 72792394225, 9, 23, 187.20830867381414],\n",
       " [72792394225, 72798594276, 23, 9, 187.20830867381414],\n",
       " [72798594276, 72784524163, 9, 24, 396.00851322484175],\n",
       " [72784524163, 72798594276, 24, 9, 396.00851322484175],\n",
       " [72798594276, 72792024227, 9, 25, 174.23493854899442],\n",
       " [72792024227, 72798594276, 25, 9, 174.23493854899442],\n",
       " [72798594276, 72785694176, 9, 26, 708.5304039928845],\n",
       " [72785694176, 72798594276, 26, 9, 708.5304039928845],\n",
       " [72792424223, 72792894263, 10, 11, 199.69966656538062],\n",
       " [72792894263, 72792424223, 11, 10, 199.69966656538062],\n",
       " [72792424223, 72781024243, 10, 12, 366.6429361022303],\n",
       " [72781024243, 72792424223, 12, 10, 366.6429361022303],\n",
       " [72792424223, 72781524237, 10, 13, 1213.3303112543872],\n",
       " [72781524237, 72792424223, 13, 10, 1213.3303112543872],\n",
       " [72792424223, 72788324220, 10, 14, 565.7742092205691],\n",
       " [72788324220, 72792424223, 14, 10, 565.7742092205691],\n",
       " [72792424223, 72698824219, 10, 15, 158.75602862100996],\n",
       " [72698824219, 72792424223, 15, 10, 158.75602862100996],\n",
       " [72792424223, 72793894274, 10, 16, 154.05814985745886],\n",
       " [72793894274, 72792424223, 16, 10, 154.05814985745886],\n",
       " [72792424223, 74206024207, 10, 17, 150.49523188191975],\n",
       " [74206024207, 72792424223, 17, 10, 150.49523188191975],\n",
       " [72792424223, 72782724110, 10, 18, 459.96707604415764],\n",
       " [72782724110, 72792424223, 18, 10, 459.96707604415764],\n",
       " [72792424223, 72793724222, 10, 19, 261.56576121699044],\n",
       " [72793724222, 72792424223, 19, 10, 261.56576121699044],\n",
       " [72792424223, 72792594227, 10, 20, 148.37325199067052],\n",
       " [72792594227, 72792424223, 20, 10, 148.37325199067052],\n",
       " [72792424223, 72782594239, 10, 21, 447.531376407682],\n",
       " [72782594239, 72792424223, 21, 10, 447.531376407682],\n",
       " [72792424223, 72794504205, 10, 22, 236.6757463314917],\n",
       " [72794504205, 72792424223, 22, 10, 236.6757463314917],\n",
       " [72792424223, 72792394225, 10, 23, 123.91187323342717],\n",
       " [72792394225, 72792424223, 23, 10, 123.91187323342717],\n",
       " [72792424223, 72784524163, 10, 24, 313.3574949442864],\n",
       " [72784524163, 72792424223, 24, 10, 313.3574949442864],\n",
       " [72792424223, 72792024227, 10, 25, 109.93432994721853],\n",
       " [72792024227, 72792424223, 25, 10, 109.93432994721853],\n",
       " [72792424223, 72785694176, 10, 26, 745.579780595948],\n",
       " [72785694176, 72792424223, 26, 10, 745.579780595948],\n",
       " [72792894263, 72781024243, 11, 12, 271.20003239227077],\n",
       " [72781024243, 72792894263, 12, 11, 271.20003239227077],\n",
       " [72792894263, 72781524237, 11, 13, 1077.0374760399814],\n",
       " [72781524237, 72792894263, 13, 11, 1077.0374760399814],\n",
       " [72792894263, 72788324220, 11, 14, 434.420916611982],\n",
       " [72788324220, 72792894263, 14, 11, 434.420916611982],\n",
       " [72792894263, 72698824219, 11, 15, 249.12813853110475],\n",
       " [72698824219, 72792894263, 15, 11, 249.12813853110475],\n",
       " [72792894263, 72793894274, 11, 16, 54.60340565924095],\n",
       " [72793894274, 72792894263, 16, 11, 54.60340565924095],\n",
       " [72792894263, 74206024207, 11, 17, 56.69074125354086],\n",
       " [74206024207, 72792894263, 17, 11, 56.69074125354086],\n",
       " [72792894263, 72782724110, 11, 18, 342.83747887822733],\n",
       " [72782724110, 72792894263, 18, 11, 342.83747887822733],\n",
       " [72792894263, 72793724222, 11, 19, 68.6532776654429],\n",
       " [72793724222, 72792894263, 19, 11, 68.6532776654429],\n",
       " [72792894263, 72792594227, 11, 20, 64.41876337172579],\n",
       " [72792594227, 72792894263, 20, 11, 64.41876337172579],\n",
       " [72792894263, 72782594239, 11, 21, 309.79708423419913],\n",
       " [72782594239, 72792894263, 21, 11, 309.79708423419913],\n",
       " [72792894263, 72794504205, 11, 22, 128.34321457181807],\n",
       " [72794504205, 72792894263, 22, 11, 128.34321457181807],\n",
       " [72792894263, 72792394225, 11, 23, 167.4998627149666],\n",
       " [72792394225, 72792894263, 23, 11, 167.4998627149666],\n",
       " [72792894263, 72784524163, 11, 24, 308.66359444651886],\n",
       " [72784524163, 72792894263, 24, 11, 308.66359444651886],\n",
       " [72792894263, 72792024227, 11, 25, 94.10375597750865],\n",
       " [72792024227, 72792894263, 25, 11, 94.10375597750865],\n",
       " [72792894263, 72785694176, 11, 26, 614.9675457923169],\n",
       " [72785694176, 72792894263, 26, 11, 614.9675457923169],\n",
       " [72781024243, 72781524237, 12, 13, 891.3237029023409],\n",
       " [72781524237, 72781024243, 13, 12, 891.3237029023409],\n",
       " [72781024243, 72788324220, 12, 14, 217.85555378560997],\n",
       " [72788324220, 72781024243, 14, 12, 217.85555378560997],\n",
       " [72781024243, 72698824219, 12, 15, 275.33106494313824],\n",
       " [72698824219, 72781024243, 15, 12, 275.33106494313824],\n",
       " [72781024243, 72793894274, 12, 16, 290.27386357894756],\n",
       " [72793894274, 72781024243, 16, 12, 290.27386357894756],\n",
       " [72781024243, 74206024207, 12, 17, 275.46064771106325],\n",
       " [74206024207, 72781024243, 17, 12, 275.46064771106325],\n",
       " [72781024243, 72782724110, 12, 18, 121.40670159689395],\n",
       " [72782724110, 72781024243, 18, 12, 121.40670159689395],\n",
       " [72781024243, 72793724222, 12, 19, 252.86361822595595],\n",
       " [72793724222, 72781024243, 19, 12, 252.86361822595595],\n",
       " [72781024243, 72792594227, 12, 20, 317.66456605180196],\n",
       " [72792594227, 72781024243, 20, 12, 317.66456605180196],\n",
       " [72781024243, 72782594239, 12, 21, 111.45482222908821],\n",
       " [72782594239, 72781024243, 21, 12, 111.45482222908821],\n",
       " [72781024243, 72794504205, 12, 22, 352.74223587837065],\n",
       " [72794504205, 72781024243, 22, 12, 352.74223587837065],\n",
       " [72781024243, 72792394225, 12, 23, 411.2440393694844],\n",
       " [72792394225, 72781024243, 23, 12, 411.2440393694844],\n",
       " [72781024243, 72784524163, 12, 24, 228.97116863460516],\n",
       " [72784524163, 72781024243, 24, 12, 228.97116863460516],\n",
       " [72781024243, 72792024227, 12, 25, 319.85603194172165],\n",
       " [72792024227, 72781024243, 25, 12, 319.85603194172165],\n",
       " [72781024243, 72785694176, 12, 26, 386.6621826263452],\n",
       " [72785694176, 72781024243, 26, 12, 386.6621826263452],\n",
       " [72781524237, 72788324220, 13, 14, 677.4867035602812],\n",
       " [72788324220, 72781524237, 14, 13, 677.4867035602812],\n",
       " [72781524237, 72698824219, 13, 15, 1150.4386824494006],\n",
       " [72698824219, 72781524237, 15, 13, 1150.4386824494006],\n",
       " [72781524237, 72793894274, 13, 16, 1122.20080799066],\n",
       " [72793894274, 72781524237, 16, 13, 1122.20080799066],\n",
       " [72781524237, 74206024207, 13, 17, 1112.0640517140919],\n",
       " [74206024207, 72781524237, 17, 13, 1112.0640517140919],\n",
       " [72781524237, 72782724110, 13, 18, 864.0517998527835],\n",
       " [72782724110, 72781524237, 18, 13, 864.0517998527835],\n",
       " [72781524237, 72793724222, 13, 19, 1044.4930844703567],\n",
       " [72793724222, 72781524237, 19, 13, 1044.4930844703567],\n",
       " [72781524237, 72792594227, 13, 20, 1130.7362905229766],\n",
       " [72792594227, 72781524237, 20, 13, 1130.7362905229766],\n",
       " [72781524237, 72782594239, 13, 21, 833.7147080759753],\n",
       " [72782594239, 72781524237, 21, 13, 833.7147080759753],\n",
       " [72781524237, 72794504205, 13, 22, 1170.6533446424978],\n",
       " [72794504205, 72781524237, 22, 13, 1170.6533446424978],\n",
       " [72781524237, 72792394225, 13, 23, 1218.574885845403],\n",
       " [72792394225, 72781524237, 23, 13, 1218.574885845403],\n",
       " [72781524237, 72784524163, 13, 24, 1103.3829323700534],\n",
       " [72784524163, 72781524237, 24, 13, 1103.3829323700534],\n",
       " [72781524237, 72792024227, 13, 25, 1152.414996794818],\n",
       " [72792024227, 72781524237, 25, 13, 1152.414996794818],\n",
       " [72781524237, 72785694176, 13, 26, 683.9489018806388],\n",
       " [72785694176, 72781524237, 26, 13, 683.9489018806388],\n",
       " [72788324220, 72698824219, 14, 15, 489.8134161401565],\n",
       " [72698824219, 72788324220, 15, 14, 489.8134161401565],\n",
       " [72788324220, 72793894274, 14, 16, 470.9676802550459],\n",
       " [72793894274, 72788324220, 16, 14, 470.9676802550459],\n",
       " [72788324220, 74206024207, 14, 17, 459.0274176052015],\n",
       " [74206024207, 72788324220, 17, 14, 459.0274176052015],\n",
       " [72788324220, 72782724110, 14, 18, 199.59384465449898],\n",
       " [72782724110, 72788324220, 18, 14, 199.59384465449898],\n",
       " [72788324220, 72793724222, 14, 19, 400.7840441174383],\n",
       " [72793724222, 72788324220, 19, 14, 400.7840441174383],\n",
       " [72788324220, 72792594227, 14, 20, 490.3741382897129],\n",
       " [72792594227, 72788324220, 20, 14, 490.3741382897129],\n",
       " [72788324220, 72782594239, 14, 21, 162.11769623669784],\n",
       " [72782594239, 72788324220, 21, 14, 162.11769623669784],\n",
       " [72788324220, 72794504205, 14, 22, 520.9373250801362],\n",
       " [72794504205, 72788324220, 22, 14, 520.9373250801362],\n",
       " [72788324220, 72792394225, 14, 23, 587.5949150283049],\n",
       " [72792394225, 72788324220, 23, 14, 587.5949150283049],\n",
       " [72788324220, 72784524163, 14, 24, 432.7632336033511],\n",
       " [72784524163, 72788324220, 24, 14, 432.7632336033511],\n",
       " [72788324220, 72792024227, 14, 25, 504.8208347435879],\n",
       " [72792024227, 72788324220, 25, 14, 504.8208347435879],\n",
       " [72788324220, 72785694176, 14, 26, 259.92185050812566],\n",
       " [72785694176, 72788324220, 26, 14, 259.92185050812566],\n",
       " [72698824219, 72793894274, 15, 16, 213.47199631168857],\n",
       " [72793894274, 72698824219, 16, 15, 213.47199631168857],\n",
       " [72698824219, 74206024207, 15, 17, 199.7906856396986],\n",
       " [74206024207, 72698824219, 17, 15, 199.7906856396986],\n",
       " [72698824219, 72782724110, 15, 18, 363.3873739871944],\n",
       " [72782724110, 72698824219, 18, 15, 363.3873739871944],\n",
       " [72698824219, 72793724222, 15, 19, 286.49766075950384],\n",
       " [72793724222, 72698824219, 19, 15, 286.49766075950384],\n",
       " [72698824219, 72792594227, 15, 20, 235.6189290359573],\n",
       " [72792594227, 72698824219, 20, 15, 235.6189290359573],\n",
       " [72698824219, 72782594239, 15, 21, 371.98475050597],\n",
       " [72782594239, 72698824219, 21, 15, 371.98475050597],\n",
       " [72698824219, 72794504205, 15, 22, 293.97835633481196],\n",
       " [72794504205, 72698824219, 22, 15, 293.97835633481196],\n",
       " [72698824219, 72792394225, 15, 23, 268.7494270590419],\n",
       " [72792394225, 72698824219, 23, 15, 268.7494270590419],\n",
       " [72698824219, 72784524163, 15, 24, 181.34059793217904],\n",
       " [72784524163, 72698824219, 24, 15, 181.34059793217904],\n",
       " [72698824219, 72792024227, 15, 25, 201.61183866011444],\n",
       " [72792024227, 72698824219, 25, 15, 201.61183866011444],\n",
       " [72698824219, 72785694176, 15, 26, 642.4950004501114],\n",
       " [72785694176, 72698824219, 26, 15, 642.4950004501114],\n",
       " [72793894274, 74206024207, 16, 17, 17.716247962574563],\n",
       " [74206024207, 72793894274, 17, 16, 17.716247962574563],\n",
       " [72793894274, 72782724110, 16, 18, 363.9821600522806],\n",
       " [72782724110, 72793894274, 18, 16, 363.9821600522806],\n",
       " [72793894274, 72793724222, 16, 19, 109.51765254130393],\n",
       " [72793724222, 72793894274, 19, 16, 109.51765254130393],\n",
       " [72793894274, 72792594227, 16, 20, 42.988933127483634],\n",
       " [72792594227, 72793894274, 20, 16, 42.988933127483634],\n",
       " [72793894274, 72782594239, 16, 21, 340.3237239231559],\n",
       " [72782594239, 72793894274, 21, 16, 340.3237239231559],\n",
       " [72793894274, 72794504205, 16, 22, 114.05670021657697],\n",
       " [72794504205, 72793894274, 22, 16, 114.05670021657697],\n",
       " [72793894274, 72792394225, 16, 23, 136.43815241862657],\n",
       " [72792394225, 72793894274, 23, 16, 136.43815241862657],\n",
       " [72793894274, 72784524163, 16, 24, 287.7450730575042],\n",
       " [72784524163, 72793894274, 24, 16, 287.7450730575042],\n",
       " [72793894274, 72792024227, 16, 25, 49.41202473657626],\n",
       " [72792024227, 72793894274, 25, 16, 49.41202473657626],\n",
       " [72793894274, 72785694176, 16, 26, 643.6682517559431],\n",
       " [72785694176, 72793894274, 26, 16, 643.6682517559431],\n",
       " [74206024207, 72782724110, 17, 18, 352.2158347034709],\n",
       " [72782724110, 74206024207, 18, 17, 352.2158347034709],\n",
       " [74206024207, 72793724222, 17, 19, 111.26188855442645],\n",
       " [72793724222, 74206024207, 19, 17, 111.26188855442645],\n",
       " [74206024207, 72792594227, 17, 20, 52.561875466910436],\n",
       " [72792594227, 74206024207, 20, 17, 52.561875466910436],\n",
       " [74206024207, 72782594239, 17, 21, 329.3368670529716],\n",
       " [72782594239, 74206024207, 21, 17, 329.3368670529716],\n",
       " [74206024207, 72794504205, 17, 22, 128.01154758942099],\n",
       " [72794504205, 74206024207, 22, 17, 128.01154758942099],\n",
       " [74206024207, 72792394225, 17, 23, 145.49531716211806],\n",
       " [72792394225, 74206024207, 23, 17, 145.49531716211806],\n",
       " [74206024207, 72784524163, 17, 24, 275.6435250697721],\n",
       " [72784524163, 74206024207, 24, 17, 275.6435250697721],\n",
       " [74206024207, 72792024227, 17, 25, 52.80087090274467],\n",
       " [72792024227, 74206024207, 25, 17, 52.80087090274467],\n",
       " [74206024207, 72785694176, 17, 26, 633.1197418989807],\n",
       " [72785694176, 74206024207, 26, 17, 633.1197418989807],\n",
       " [72782724110, 72793724222, 18, 19, 303.31516235822005],\n",
       " [72793724222, 72782724110, 19, 18, 303.31516235822005],\n",
       " [72782724110, 72792594227, 18, 20, 396.9755284116139],\n",
       " [72792594227, 72782724110, 20, 18, 396.9755284116139],\n",
       " [72782724110, 72782594239, 18, 21, 73.74026824660453],\n",
       " [72782594239, 72782724110, 21, 18, 73.74026824660453],\n",
       " [72782724110, 72794504205, 18, 22, 394.74559894207687],\n",
       " [72794504205, 72782724110, 22, 18, 394.74559894207687],\n",
       " [72782724110, 72792394225, 18, 23, 496.478460291939],\n",
       " [72792394225, 72782724110, 23, 18, 496.478460291939],\n",
       " [72782724110, 72784524163, 18, 24, 256.1592053257525],\n",
       " [72784524163, 72782724110, 24, 18, 256.1592053257525],\n",
       " [72782724110, 72792024227, 18, 25, 402.1731282608459],\n",
       " [72792024227, 72782724110, 25, 18, 402.1731282608459],\n",
       " [72782724110, 72785694176, 18, 26, 286.80868520838226],\n",
       " [72785694176, 72782724110, 26, 18, 286.80868520838226],\n",
       " [72793724222, 72792594227, 19, 20, 129.67576043022495],\n",
       " [72792594227, 72793724222, 20, 19, 129.67576043022495],\n",
       " [72793724222, 72782594239, 19, 21, 268.31498195846285],\n",
       " [72782594239, 72793724222, 21, 19, 268.31498195846285],\n",
       " [72793724222, 72794504205, 19, 22, 128.38153131965652],\n",
       " [72794504205, 72793724222, 22, 19, 128.38153131965652],\n",
       " [72793724222, 72792394225, 19, 23, 230.11767302669344],\n",
       " [72792394225, 72793724222, 23, 19, 230.11767302669344],\n",
       " [72793724222, 72784524163, 19, 24, 305.30416194483115],\n",
       " [72784524163, 72793724222, 24, 19, 305.30416194483115],\n",
       " [72793724222, 72792024227, 19, 25, 156.88223261226412],\n",
       " [72792024227, 72793724222, 25, 19, 156.88223261226412],\n",
       " [72793724222, 72785694176, 19, 26, 566.3246868369048],\n",
       " [72785694176, 72793724222, 26, 19, 566.3246868369048],\n",
       " [72792594227, 72782594239, 20, 21, 368.04423285388],\n",
       " [72782594239, 72792594227, 21, 20, 368.04423285388],\n",
       " [72792594227, 72794504205, 20, 22, 133.10933796080906],\n",
       " [72794504205, 72792594227, 22, 20, 133.10933796080906],\n",
       " [72792594227, 72792394225, 20, 23, 103.88553424589651],\n",
       " [72792394225, 72792594227, 23, 20, 103.88553424589651],\n",
       " [72792594227, 72784524163, 20, 24, 327.04970158433304],\n",
       " [72784524163, 72792594227, 24, 20, 327.04970158433304],\n",
       " [72792594227, 72792024227, 20, 25, 41.59043713208587],\n",
       " [72792024227, 72792594227, 25, 20, 41.59043713208587],\n",
       " [72792594227, 72785694176, 20, 26, 674.0342619771884],\n",
       " [72785694176, 72792594227, 26, 20, 674.0342619771884],\n",
       " [72782594239, 72794504205, 21, 22, 375.88513957717953],\n",
       " [72794504205, 72782594239, 22, 21, 375.88513957717953],\n",
       " [72782594239, 72792394225, 21, 23, 469.86938496204897],\n",
       " [72792394225, 72782594239, 23, 21, 469.86938496204897],\n",
       " [72782594239, 72784524163, 21, 24, 296.22180486691445],\n",
       " [72784524163, 72782594239, 24, 21, 296.22180486691445],\n",
       " [72782594239, 72792024227, 21, 25, 379.7335338263519],\n",
       " [72792024227, 72782594239, 25, 21, 379.7335338263519],\n",
       " [72782594239, 72785694176, 21, 26, 308.0303254221726],\n",
       " [72785694176, 72782594239, 26, 21, 308.0303254221726],\n",
       " [72794504205, 72792394225, 22, 23, 191.05105434406818],\n",
       " [72792394225, 72794504205, 23, 22, 191.05105434406818],\n",
       " [72794504205, 72784524163, 22, 24, 321.52952520777865],\n",
       " [72784524163, 72794504205, 24, 22, 321.52952520777865],\n",
       " [72794504205, 72792024227, 22, 25, 144.61575947894278],\n",
       " [72792024227, 72794504205, 25, 22, 144.61575947894278],\n",
       " [72794504205, 72785694176, 22, 26, 662.014427725483],\n",
       " [72785694176, 72794504205, 26, 22, 662.014427725483],\n",
       " [72792394225, 72784524163, 23, 24, 393.67944122771735],\n",
       " [72784524163, 72792394225, 24, 23, 393.67944122771735],\n",
       " [72792394225, 72792024227, 23, 25, 96.11729883125135],\n",
       " [72792024227, 72792394225, 25, 23, 96.11729883125135],\n",
       " [72792394225, 72785694176, 23, 26, 776.1835969743106],\n",
       " [72785694176, 72792394225, 26, 23, 776.1835969743106],\n",
       " [72784524163, 72792024227, 24, 25, 305.7627599001508],\n",
       " [72792024227, 72784524163, 25, 24, 305.7627599001508],\n",
       " [72784524163, 72785694176, 24, 26, 516.3645983655035],\n",
       " [72785694176, 72784524163, 26, 24, 516.3645983655035],\n",
       " [72792024227, 72785694176, 25, 26, 684.1746652775099],\n",
       " [72785694176, 72792024227, 26, 25, 684.1746652775099]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[395.4679457314314,\n",
       " 395.4679457314314,\n",
       " 129.15783117310457,\n",
       " 129.15783117310457,\n",
       " 342.5330553210191,\n",
       " 342.5330553210191,\n",
       " 438.10430559873856,\n",
       " 438.10430559873856,\n",
       " 432.0504921333856,\n",
       " 432.0504921333856,\n",
       " 437.11321302131137,\n",
       " 437.11321302131137,\n",
       " 369.0087247919059,\n",
       " 369.0087247919059,\n",
       " 503.7031148557305,\n",
       " 503.7031148557305,\n",
       " 455.6811328123654,\n",
       " 455.6811328123654,\n",
       " 474.59654599988056,\n",
       " 474.59654599988056,\n",
       " 348.0950737502581,\n",
       " 348.0950737502581,\n",
       " 128.6980383337319,\n",
       " 128.6980383337319,\n",
       " 835.9738346074198,\n",
       " 835.9738346074198,\n",
       " 171.59537540199554,\n",
       " 171.59537540199554,\n",
       " 384.56540064951065,\n",
       " 384.56540064951065,\n",
       " 373.58764051749137,\n",
       " 373.58764051749137,\n",
       " 362.1843030623904,\n",
       " 362.1843030623904,\n",
       " 32.53657446575969,\n",
       " 32.53657446575969,\n",
       " 306.4908073667999,\n",
       " 306.4908073667999,\n",
       " 404.50991220772727,\n",
       " 404.50991220772727,\n",
       " 52.81240627430448,\n",
       " 52.81240627430448,\n",
       " 404.8085057270694,\n",
       " 404.8085057270694,\n",
       " 505.4288197147213,\n",
       " 505.4288197147213,\n",
       " 286.0836462058196,\n",
       " 286.0836462058196,\n",
       " 412.6227567328569,\n",
       " 412.6227567328569,\n",
       " 272.19719043646785,\n",
       " 272.19719043646785,\n",
       " 390.14029117618804,\n",
       " 390.14029117618804,\n",
       " 727.6917541369755,\n",
       " 727.6917541369755,\n",
       " 109.85904921372176,\n",
       " 109.85904921372176,\n",
       " 798.995937782049,\n",
       " 798.995937782049,\n",
       " 802.4581375032445,\n",
       " 802.4581375032445,\n",
       " 33.690956835057186,\n",
       " 33.690956835057186,\n",
       " 865.1737430163511,\n",
       " 865.1737430163511,\n",
       " 825.6499844120128,\n",
       " 825.6499844120128,\n",
       " 860.6728795779842,\n",
       " 860.6728795779842,\n",
       " 724.9963923066945,\n",
       " 724.9963923066945,\n",
       " 495.92270395996894,\n",
       " 495.92270395996894,\n",
       " 535.6266022869553,\n",
       " 535.6266022869553,\n",
       " 314.54161595295784,\n",
       " 314.54161595295784,\n",
       " 763.6141112163369,\n",
       " 763.6141112163369,\n",
       " 759.3841400612968,\n",
       " 759.3841400612968,\n",
       " 748.5486591666476,\n",
       " 748.5486591666476,\n",
       " 416.12981588895354,\n",
       " 416.12981588895354,\n",
       " 678.7815012654146,\n",
       " 678.7815012654146,\n",
       " 784.7770299622911,\n",
       " 784.7770299622911,\n",
       " 419.79175595055284,\n",
       " 419.79175595055284,\n",
       " 786.18443118649,\n",
       " 786.18443118649,\n",
       " 886.2658783050533,\n",
       " 886.2658783050533,\n",
       " 655.5895444605051,\n",
       " 655.5895444605051,\n",
       " 798.318691116012,\n",
       " 798.318691116012,\n",
       " 157.5431429141368,\n",
       " 157.5431429141368,\n",
       " 370.42190175405364,\n",
       " 370.42190175405364,\n",
       " 460.5219705003162,\n",
       " 460.5219705003162,\n",
       " 432.51979230044606,\n",
       " 432.51979230044606,\n",
       " 417.3828379309705,\n",
       " 417.3828379309705,\n",
       " 365.04041085309774,\n",
       " 365.04041085309774,\n",
       " 508.89691489063597,\n",
       " 508.89691489063597,\n",
       " 445.736559884783,\n",
       " 445.736559884783,\n",
       " 534.5520542530354,\n",
       " 534.5520542530354,\n",
       " 372.6745336577991,\n",
       " 372.6745336577991,\n",
       " 236.9285970548754,\n",
       " 236.9285970548754,\n",
       " 831.0617187024466,\n",
       " 831.0617187024466,\n",
       " 221.69557651346355,\n",
       " 221.69557651346355,\n",
       " 470.9577296531585,\n",
       " 470.9577296531585,\n",
       " 406.24280451088293,\n",
       " 406.24280451088293,\n",
       " 399.71114545506987,\n",
       " 399.71114545506987,\n",
       " 147.68778122386612,\n",
       " 147.68778122386612,\n",
       " 313.8982068438734,\n",
       " 313.8982068438734,\n",
       " 435.3656912848407,\n",
       " 435.3656912848407,\n",
       " 130.20708355028395,\n",
       " 130.20708355028395,\n",
       " 406.9699486305622,\n",
       " 406.9699486305622,\n",
       " 539.0132078425393,\n",
       " 539.0132078425393,\n",
       " 368.91523621650714,\n",
       " 368.91523621650714,\n",
       " 452.3832910640423,\n",
       " 452.3832910640423,\n",
       " 270.2281521689557,\n",
       " 270.2281521689557,\n",
       " 775.0588941479449,\n",
       " 775.0588941479449,\n",
       " 120.26611512741678,\n",
       " 120.26611512741678,\n",
       " 165.52848353942377,\n",
       " 165.52848353942377,\n",
       " 704.0879836514051,\n",
       " 704.0879836514051,\n",
       " 185.28412975619443,\n",
       " 185.28412975619443,\n",
       " 152.43166309928537,\n",
       " 152.43166309928537,\n",
       " 187.27787071696568,\n",
       " 187.27787071696568,\n",
       " 41.159846544112625,\n",
       " 41.159846544112625,\n",
       " 266.9618608270944,\n",
       " 266.9618608270944,\n",
       " 1096.8318771247875,\n",
       " 1096.8318771247875,\n",
       " 443.4038293955239,\n",
       " 443.4038293955239,\n",
       " 225.02216925780087,\n",
       " 225.02216925780087,\n",
       " 36.85266364881154,\n",
       " 36.85266364881154,\n",
       " 37.9895765777111,\n",
       " 37.9895765777111,\n",
       " 333.6917238582668,\n",
       " 333.6917238582668,\n",
       " 76.27723241526142,\n",
       " 76.27723241526142,\n",
       " 72.18185980856553,\n",
       " 72.18185980856553,\n",
       " 309.0749255571238,\n",
       " 309.0749255571238,\n",
       " 107.09860018045799,\n",
       " 107.09860018045799,\n",
       " 171.23674671831446,\n",
       " 171.23674671831446,\n",
       " 276.0731537992283,\n",
       " 276.0731537992283,\n",
       " 85.99186556469607,\n",
       " 85.99186556469607,\n",
       " 611.0889227645558,\n",
       " 611.0889227645558,\n",
       " 856.701667766572,\n",
       " 856.701667766572,\n",
       " 865.4792367557994,\n",
       " 865.4792367557994,\n",
       " 117.74480456011335,\n",
       " 117.74480456011335,\n",
       " 921.4842980890041,\n",
       " 921.4842980890041,\n",
       " 885.9031028312606,\n",
       " 885.9031028312606,\n",
       " 890.5893542480043,\n",
       " 890.5893542480043,\n",
       " 774.366157782777,\n",
       " 774.366157782777,\n",
       " 524.6337306289196,\n",
       " 524.6337306289196,\n",
       " 540.0809528724242,\n",
       " 540.0809528724242,\n",
       " 357.13279391570444,\n",
       " 357.13279391570444,\n",
       " 780.4774458332262,\n",
       " 780.4774458332262,\n",
       " 804.444912957628,\n",
       " 804.444912957628,\n",
       " 791.9148221844617,\n",
       " 791.9148221844617,\n",
       " 454.1201925958629,\n",
       " 454.1201925958629,\n",
       " 734.2694292819892,\n",
       " 734.2694292819892,\n",
       " 830.6418814848106,\n",
       " 830.6418814848106,\n",
       " 467.37603414879794,\n",
       " 467.37603414879794,\n",
       " 840.9110561664348,\n",
       " 840.9110561664348,\n",
       " 929.3740741921883,\n",
       " 929.3740741921883,\n",
       " 673.3913688173589,\n",
       " 673.3913688173589,\n",
       " 839.7968409183139,\n",
       " 839.7968409183139,\n",
       " 209.78499150005845,\n",
       " 209.78499150005845,\n",
       " 110.15242913456197,\n",
       " 110.15242913456197,\n",
       " 777.4585937545535,\n",
       " 777.4585937545535,\n",
       " 85.13925057078639,\n",
       " 85.13925057078639,\n",
       " 74.97130998219406,\n",
       " 74.97130998219406,\n",
       " 240.43942234567194,\n",
       " 240.43942234567194,\n",
       " 103.9757703201679,\n",
       " 103.9757703201679,\n",
       " 369.69695959787833,\n",
       " 369.69695959787833,\n",
       " 1139.0521959187856,\n",
       " 1139.0521959187856,\n",
       " 516.0490346912795,\n",
       " 516.0490346912795,\n",
       " 330.5216959336131,\n",
       " 330.5216959336131,\n",
       " 117.91278236100351,\n",
       " 117.91278236100351,\n",
       " 133.34207595548997,\n",
       " 133.34207595548997,\n",
       " 428.7153028579556,\n",
       " 428.7153028579556,\n",
       " 125.7282441840991,\n",
       " 125.7282441840991,\n",
       " 101.97987733596389,\n",
       " 101.97987733596389,\n",
       " 392.60154297249403,\n",
       " 392.60154297249403,\n",
       " 108.31645122446824,\n",
       " 108.31645122446824,\n",
       " 153.40108385187867,\n",
       " 153.40108385187867,\n",
       " 392.1898886399527,\n",
       " 392.1898886399527,\n",
       " 137.25092367847324,\n",
       " 137.25092367847324,\n",
       " 690.174750212649,\n",
       " 690.174750212649,\n",
       " 778.6874797868297,\n",
       " 778.6874797868297,\n",
       " 177.46961023734613,\n",
       " 177.46961023734613,\n",
       " 48.71149879169117,\n",
       " 48.71149879169117,\n",
       " 302.0846527899822,\n",
       " 302.0846527899822,\n",
       " 172.27646695285324,\n",
       " 172.27646695285324,\n",
       " 399.97805818217563,\n",
       " 399.97805818217563,\n",
       " 1176.4852153080844,\n",
       " 1176.4852153080844,\n",
       " 545.6427005439592,\n",
       " 545.6427005439592,\n",
       " 369.3977887607593,\n",
       " 369.3977887607593,\n",
       " 175.55537172802033,\n",
       " 175.55537172802033,\n",
       " 190.70446482220075,\n",
       " 190.70446482220075,\n",
       " 431.096161984872,\n",
       " 431.096161984872,\n",
       " 156.64330089805705,\n",
       " 156.64330089805705,\n",
       " 183.24573042058552,\n",
       " 183.24573042058552,\n",
       " 405.4909815288361,\n",
       " 405.4909815288361,\n",
       " 76.4859126118275,\n",
       " 76.4859126118275,\n",
       " 231.7098185991757,\n",
       " 231.7098185991757,\n",
       " 388.4359336032824,\n",
       " 388.4359336032824,\n",
       " 205.33116784821942,\n",
       " 205.33116784821942,\n",
       " 682.4260680955291,\n",
       " 682.4260680955291,\n",
       " 845.1366146343045,\n",
       " 845.1366146343045,\n",
       " 802.4776134962176,\n",
       " 802.4776134962176,\n",
       " 837.0612376685274,\n",
       " 837.0612376685274,\n",
       " 702.8044715545802,\n",
       " 702.8044715545802,\n",
       " 472.23598917705993,\n",
       " 472.23598917705993,\n",
       " 567.9966156275789,\n",
       " 567.9966156275789,\n",
       " 299.672336109386,\n",
       " 299.672336109386,\n",
       " 738.0303386253106,\n",
       " 738.0303386253106,\n",
       " 735.9632694864449,\n",
       " 735.9632694864449,\n",
       " 725.1092500944276,\n",
       " 725.1092500944276,\n",
       " 388.53428759844127,\n",
       " 388.53428759844127,\n",
       " 656.1420174916371,\n",
       " 656.1420174916371,\n",
       " 762.4710980022056,\n",
       " 762.4710980022056,\n",
       " 395.81370216605853,\n",
       " 395.81370216605853,\n",
       " 761.3237576215986,\n",
       " 761.3237576215986,\n",
       " 864.2082908552868,\n",
       " 864.2082908552868,\n",
       " 626.0309963149288,\n",
       " 626.0309963149288,\n",
       " 775.1913077729471,\n",
       " 775.1913077729471,\n",
       " 124.27275180830249,\n",
       " 124.27275180830249,\n",
       " 132.5097212349861,\n",
       " 132.5097212349861,\n",
       " 243.7073144688935,\n",
       " 243.7073144688935,\n",
       " 163.47287592761103,\n",
       " 163.47287592761103,\n",
       " 430.6615227573649,\n",
       " 430.6615227573649,\n",
       " 1177.64872286148,\n",
       " 1177.64872286148,\n",
       " 572.9402144031785,\n",
       " 572.9402144031785,\n",
       " 365.1202761234219,\n",
       " 365.1202761234219,\n",
       " 169.20923499165121,\n",
       " 169.20923499165121,\n",
       " 183.39281681071296,\n",
       " 183.39281681071296,\n",
       " 501.4584011725272,\n",
       " 501.4584011725272,\n",
       " 202.41419212127153,\n",
       " 202.41419212127153,\n",
       " 134.47678138943274,\n",
       " 134.47678138943274,\n",
       " 461.61393826175714,\n",
       " 461.61393826175714,\n",
       " 180.6112148305096,\n",
       " 180.6112148305096,\n",
       " 128.08708542091654,\n",
       " 128.08708542091654,\n",
       " 456.1447880245876,\n",
       " 456.1447880245876,\n",
       " 164.101942102309,\n",
       " 164.101942102309,\n",
       " 763.0321197403028,\n",
       " 763.0321197403028,\n",
       " 268.89465547374556,\n",
       " 268.89465547374556,\n",
       " 154.53742133091865,\n",
       " 154.53742133091865,\n",
       " 405.60664848136616,\n",
       " 405.60664848136616,\n",
       " 1187.3176896736784,\n",
       " 1187.3176896736784,\n",
       " 557.1020923327553,\n",
       " 557.1020923327553,\n",
       " 353.92282978101207,\n",
       " 353.92282978101207,\n",
       " 153.1723115228679,\n",
       " 153.1723115228679,\n",
       " 170.09372061722416,\n",
       " 170.09372061722416,\n",
       " 449.65266636740307,\n",
       " 449.65266636740307,\n",
       " 158.4233084920311,\n",
       " 158.4233084920311,\n",
       " 151.2637681156068,\n",
       " 151.2637681156068,\n",
       " 421.5198568724629,\n",
       " 421.5198568724629,\n",
       " 75.9354339763056,\n",
       " 75.9354339763056,\n",
       " 187.20830867381414,\n",
       " 187.20830867381414,\n",
       " 396.00851322484175,\n",
       " 396.00851322484175,\n",
       " 174.23493854899442,\n",
       " 174.23493854899442,\n",
       " 708.5304039928845,\n",
       " 708.5304039928845,\n",
       " 199.69966656538062,\n",
       " 199.69966656538062,\n",
       " 366.6429361022303,\n",
       " 366.6429361022303,\n",
       " 1213.3303112543872,\n",
       " 1213.3303112543872,\n",
       " 565.7742092205691,\n",
       " 565.7742092205691,\n",
       " 158.75602862100996,\n",
       " 158.75602862100996,\n",
       " 154.05814985745886,\n",
       " 154.05814985745886,\n",
       " 150.49523188191975,\n",
       " 150.49523188191975,\n",
       " 459.96707604415764,\n",
       " 459.96707604415764,\n",
       " 261.56576121699044,\n",
       " 261.56576121699044,\n",
       " 148.37325199067052,\n",
       " 148.37325199067052,\n",
       " 447.531376407682,\n",
       " 447.531376407682,\n",
       " 236.6757463314917,\n",
       " 236.6757463314917,\n",
       " 123.91187323342717,\n",
       " 123.91187323342717,\n",
       " 313.3574949442864,\n",
       " 313.3574949442864,\n",
       " 109.93432994721853,\n",
       " 109.93432994721853,\n",
       " 745.579780595948,\n",
       " 745.579780595948,\n",
       " 271.20003239227077,\n",
       " 271.20003239227077,\n",
       " 1077.0374760399814,\n",
       " 1077.0374760399814,\n",
       " 434.420916611982,\n",
       " 434.420916611982,\n",
       " 249.12813853110475,\n",
       " 249.12813853110475,\n",
       " 54.60340565924095,\n",
       " 54.60340565924095,\n",
       " 56.69074125354086,\n",
       " 56.69074125354086,\n",
       " 342.83747887822733,\n",
       " 342.83747887822733,\n",
       " 68.6532776654429,\n",
       " 68.6532776654429,\n",
       " 64.41876337172579,\n",
       " 64.41876337172579,\n",
       " 309.79708423419913,\n",
       " 309.79708423419913,\n",
       " 128.34321457181807,\n",
       " 128.34321457181807,\n",
       " 167.4998627149666,\n",
       " 167.4998627149666,\n",
       " 308.66359444651886,\n",
       " 308.66359444651886,\n",
       " 94.10375597750865,\n",
       " 94.10375597750865,\n",
       " 614.9675457923169,\n",
       " 614.9675457923169,\n",
       " 891.3237029023409,\n",
       " 891.3237029023409,\n",
       " 217.85555378560997,\n",
       " 217.85555378560997,\n",
       " 275.33106494313824,\n",
       " 275.33106494313824,\n",
       " 290.27386357894756,\n",
       " 290.27386357894756,\n",
       " 275.46064771106325,\n",
       " 275.46064771106325,\n",
       " 121.40670159689395,\n",
       " 121.40670159689395,\n",
       " 252.86361822595595,\n",
       " 252.86361822595595,\n",
       " 317.66456605180196,\n",
       " 317.66456605180196,\n",
       " 111.45482222908821,\n",
       " 111.45482222908821,\n",
       " 352.74223587837065,\n",
       " 352.74223587837065,\n",
       " 411.2440393694844,\n",
       " 411.2440393694844,\n",
       " 228.97116863460516,\n",
       " 228.97116863460516,\n",
       " 319.85603194172165,\n",
       " 319.85603194172165,\n",
       " 386.6621826263452,\n",
       " 386.6621826263452,\n",
       " 677.4867035602812,\n",
       " 677.4867035602812,\n",
       " 1150.4386824494006,\n",
       " 1150.4386824494006,\n",
       " 1122.20080799066,\n",
       " 1122.20080799066,\n",
       " 1112.0640517140919,\n",
       " 1112.0640517140919,\n",
       " 864.0517998527835,\n",
       " 864.0517998527835,\n",
       " 1044.4930844703567,\n",
       " 1044.4930844703567,\n",
       " 1130.7362905229766,\n",
       " 1130.7362905229766,\n",
       " 833.7147080759753,\n",
       " 833.7147080759753,\n",
       " 1170.6533446424978,\n",
       " 1170.6533446424978,\n",
       " 1218.574885845403,\n",
       " 1218.574885845403,\n",
       " 1103.3829323700534,\n",
       " 1103.3829323700534,\n",
       " 1152.414996794818,\n",
       " 1152.414996794818,\n",
       " 683.9489018806388,\n",
       " 683.9489018806388,\n",
       " 489.8134161401565,\n",
       " 489.8134161401565,\n",
       " 470.9676802550459,\n",
       " 470.9676802550459,\n",
       " 459.0274176052015,\n",
       " 459.0274176052015,\n",
       " 199.59384465449898,\n",
       " 199.59384465449898,\n",
       " 400.7840441174383,\n",
       " 400.7840441174383,\n",
       " 490.3741382897129,\n",
       " 490.3741382897129,\n",
       " 162.11769623669784,\n",
       " 162.11769623669784,\n",
       " 520.9373250801362,\n",
       " 520.9373250801362,\n",
       " 587.5949150283049,\n",
       " 587.5949150283049,\n",
       " 432.7632336033511,\n",
       " 432.7632336033511,\n",
       " 504.8208347435879,\n",
       " 504.8208347435879,\n",
       " 259.92185050812566,\n",
       " 259.92185050812566,\n",
       " 213.47199631168857,\n",
       " 213.47199631168857,\n",
       " 199.7906856396986,\n",
       " 199.7906856396986,\n",
       " 363.3873739871944,\n",
       " 363.3873739871944,\n",
       " 286.49766075950384,\n",
       " 286.49766075950384,\n",
       " 235.6189290359573,\n",
       " 235.6189290359573,\n",
       " 371.98475050597,\n",
       " 371.98475050597,\n",
       " 293.97835633481196,\n",
       " 293.97835633481196,\n",
       " 268.7494270590419,\n",
       " 268.7494270590419,\n",
       " 181.34059793217904,\n",
       " 181.34059793217904,\n",
       " 201.61183866011444,\n",
       " 201.61183866011444,\n",
       " 642.4950004501114,\n",
       " 642.4950004501114,\n",
       " 17.716247962574563,\n",
       " 17.716247962574563,\n",
       " 363.9821600522806,\n",
       " 363.9821600522806,\n",
       " 109.51765254130393,\n",
       " 109.51765254130393,\n",
       " 42.988933127483634,\n",
       " 42.988933127483634,\n",
       " 340.3237239231559,\n",
       " 340.3237239231559,\n",
       " 114.05670021657697,\n",
       " 114.05670021657697,\n",
       " 136.43815241862657,\n",
       " 136.43815241862657,\n",
       " 287.7450730575042,\n",
       " 287.7450730575042,\n",
       " 49.41202473657626,\n",
       " 49.41202473657626,\n",
       " 643.6682517559431,\n",
       " 643.6682517559431,\n",
       " 352.2158347034709,\n",
       " 352.2158347034709,\n",
       " 111.26188855442645,\n",
       " 111.26188855442645,\n",
       " 52.561875466910436,\n",
       " 52.561875466910436,\n",
       " 329.3368670529716,\n",
       " 329.3368670529716,\n",
       " 128.01154758942099,\n",
       " 128.01154758942099,\n",
       " 145.49531716211806,\n",
       " 145.49531716211806,\n",
       " 275.6435250697721,\n",
       " 275.6435250697721,\n",
       " 52.80087090274467,\n",
       " 52.80087090274467,\n",
       " 633.1197418989807,\n",
       " 633.1197418989807,\n",
       " 303.31516235822005,\n",
       " 303.31516235822005,\n",
       " 396.9755284116139,\n",
       " 396.9755284116139,\n",
       " 73.74026824660453,\n",
       " 73.74026824660453,\n",
       " 394.74559894207687,\n",
       " 394.74559894207687,\n",
       " 496.478460291939,\n",
       " 496.478460291939,\n",
       " 256.1592053257525,\n",
       " 256.1592053257525,\n",
       " 402.1731282608459,\n",
       " 402.1731282608459,\n",
       " 286.80868520838226,\n",
       " 286.80868520838226,\n",
       " 129.67576043022495,\n",
       " 129.67576043022495,\n",
       " 268.31498195846285,\n",
       " 268.31498195846285,\n",
       " 128.38153131965652,\n",
       " 128.38153131965652,\n",
       " 230.11767302669344,\n",
       " 230.11767302669344,\n",
       " 305.30416194483115,\n",
       " 305.30416194483115,\n",
       " 156.88223261226412,\n",
       " 156.88223261226412,\n",
       " 566.3246868369048,\n",
       " 566.3246868369048,\n",
       " 368.04423285388,\n",
       " 368.04423285388,\n",
       " 133.10933796080906,\n",
       " 133.10933796080906,\n",
       " 103.88553424589651,\n",
       " 103.88553424589651,\n",
       " 327.04970158433304,\n",
       " 327.04970158433304,\n",
       " 41.59043713208587,\n",
       " 41.59043713208587,\n",
       " 674.0342619771884,\n",
       " 674.0342619771884,\n",
       " 375.88513957717953,\n",
       " 375.88513957717953,\n",
       " 469.86938496204897,\n",
       " 469.86938496204897,\n",
       " 296.22180486691445,\n",
       " 296.22180486691445,\n",
       " 379.7335338263519,\n",
       " 379.7335338263519,\n",
       " 308.0303254221726,\n",
       " 308.0303254221726,\n",
       " 191.05105434406818,\n",
       " 191.05105434406818,\n",
       " 321.52952520777865,\n",
       " 321.52952520777865,\n",
       " 144.61575947894278,\n",
       " 144.61575947894278,\n",
       " 662.014427725483,\n",
       " 662.014427725483,\n",
       " 393.67944122771735,\n",
       " 393.67944122771735,\n",
       " 96.11729883125135,\n",
       " 96.11729883125135,\n",
       " 776.1835969743106,\n",
       " 776.1835969743106,\n",
       " 305.7627599001508,\n",
       " 305.7627599001508,\n",
       " 516.3645983655035,\n",
       " 516.3645983655035,\n",
       " 684.1746652775099,\n",
       " 684.1746652775099]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_edge_attributes(dataframes, location_datamap_df, edge_index):\n",
    "    edge_attr = []\n",
    "    edge_attr_verifications = []\n",
    "    keys = list(dataframes.keys())\n",
    "    for i, j in edge_index:\n",
    "        station_i = location_datamap_df[location_datamap_df['STATION'] == keys[i]]\n",
    "        station_j = location_datamap_df[location_datamap_df['STATION'] == keys[j]]\n",
    "        lati, loni, eli = station_i['LATITUDE'].values[0], station_i['LONGITUDE'].values[0], station_i['ELEVATION'].values[0]\n",
    "        latj, lonj, elj = station_j['LATITUDE'].values[0], station_j['LONGITUDE'].values[0], station_j['ELEVATION'].values[0]\n",
    "        edge_attr_verifications.append(([keys[i], keys[j], i, j, haversine_distance(lati, loni, latj, lonj, eli, elj)]))\n",
    "        edge_attr.append(haversine_distance(lati, loni, latj, lonj, eli, elj))\n",
    "    display(edge_attr_verifications)\n",
    "    return edge_attr\n",
    "\n",
    "edge_attr = create_edge_attributes(dataframes, location_datamap_df, edge_index)\n",
    "display(edge_attr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 702])\n",
      "tensor([[ 0,  1,  0,  ..., 26, 25, 26],\n",
      "        [ 1,  0,  2,  ..., 24, 26, 25]])\n"
     ]
    }
   ],
   "source": [
    "# Convert edge_index to a torch tensor\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Print the shape to verify\n",
    "print(edge_index.shape)\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([702])\n",
      "tensor([0.3146, 0.3146, 0.0928, 0.0928, 0.2705, 0.2705, 0.3501, 0.3501, 0.3450,\n",
      "        0.3450, 0.3492, 0.3492, 0.2925, 0.2925, 0.4047, 0.4047, 0.3647, 0.3647,\n",
      "        0.3805, 0.3805, 0.2751, 0.2751, 0.0924, 0.0924, 0.6814, 0.6814, 0.1281,\n",
      "        0.1281, 0.3055, 0.3055, 0.2963, 0.2963, 0.2869, 0.2869, 0.0123, 0.0123,\n",
      "        0.2405, 0.2405, 0.3221, 0.3221, 0.0292, 0.0292, 0.3223, 0.3223, 0.4061,\n",
      "        0.4061, 0.2235, 0.2235, 0.3289, 0.3289, 0.2119, 0.2119, 0.3101, 0.3101,\n",
      "        0.5912, 0.5912, 0.0767, 0.0767, 0.6506, 0.6506, 0.6535, 0.6535, 0.0133,\n",
      "        0.0133, 0.7057, 0.7057, 0.6728, 0.6728, 0.7020, 0.7020, 0.5890, 0.5890,\n",
      "        0.3982, 0.3982, 0.4313, 0.4313, 0.2472, 0.2472, 0.6211, 0.6211, 0.6176,\n",
      "        0.6176, 0.6086, 0.6086, 0.3318, 0.3318, 0.5505, 0.5505, 0.6388, 0.6388,\n",
      "        0.3348, 0.3348, 0.6399, 0.6399, 0.7233, 0.7233, 0.5312, 0.5312, 0.6500,\n",
      "        0.6500, 0.1164, 0.1164, 0.2937, 0.2937, 0.3687, 0.3687, 0.3454, 0.3454,\n",
      "        0.3328, 0.3328, 0.2892, 0.2892, 0.4090, 0.4090, 0.3564, 0.3564, 0.4304,\n",
      "        0.4304, 0.2956, 0.2956, 0.1825, 0.1825, 0.6773, 0.6773, 0.1699, 0.1699,\n",
      "        0.3774, 0.3774, 0.3235, 0.3235, 0.3181, 0.3181, 0.1082, 0.1082, 0.2466,\n",
      "        0.2466, 0.3478, 0.3478, 0.0937, 0.0937, 0.3241, 0.3241, 0.4341, 0.4341,\n",
      "        0.2925, 0.2925, 0.3620, 0.3620, 0.2103, 0.2103, 0.6307, 0.6307, 0.0854,\n",
      "        0.0854, 0.1231, 0.1231, 0.5716, 0.5716, 0.1395, 0.1395, 0.1122, 0.1122,\n",
      "        0.1412, 0.1412, 0.0195, 0.0195, 0.2076, 0.2076, 0.8986, 0.8986, 0.3545,\n",
      "        0.3545, 0.1726, 0.1726, 0.0159, 0.0159, 0.0169, 0.0169, 0.2631, 0.2631,\n",
      "        0.0488, 0.0488, 0.0454, 0.0454, 0.2426, 0.2426, 0.0744, 0.0744, 0.1278,\n",
      "        0.1278, 0.2151, 0.2151, 0.0569, 0.0569, 0.4941, 0.4941, 0.6987, 0.6987,\n",
      "        0.7060, 0.7060, 0.0833, 0.0833, 0.7526, 0.7526, 0.7230, 0.7230, 0.7269,\n",
      "        0.7269, 0.6301, 0.6301, 0.4221, 0.4221, 0.4350, 0.4350, 0.2826, 0.2826,\n",
      "        0.6352, 0.6352, 0.6551, 0.6551, 0.6447, 0.6447, 0.3634, 0.3634, 0.5967,\n",
      "        0.5967, 0.6770, 0.6770, 0.3744, 0.3744, 0.6855, 0.6855, 0.7592, 0.7592,\n",
      "        0.5460, 0.5460, 0.6846, 0.6846, 0.1599, 0.1599, 0.0770, 0.0770, 0.6327,\n",
      "        0.6327, 0.0561, 0.0561, 0.0477, 0.0477, 0.1855, 0.1855, 0.0718, 0.0718,\n",
      "        0.2931, 0.2931, 0.9338, 0.9338, 0.4150, 0.4150, 0.2605, 0.2605, 0.0834,\n",
      "        0.0834, 0.0963, 0.0963, 0.3423, 0.3423, 0.0899, 0.0899, 0.0702, 0.0702,\n",
      "        0.3122, 0.3122, 0.0754, 0.0754, 0.1130, 0.1130, 0.3118, 0.3118, 0.0995,\n",
      "        0.0995, 0.5600, 0.5600, 0.6337, 0.6337, 0.1330, 0.1330, 0.0258, 0.0258,\n",
      "        0.2368, 0.2368, 0.1287, 0.1287, 0.3183, 0.3183, 0.9650, 0.9650, 0.4396,\n",
      "        0.4396, 0.2929, 0.2929, 0.1314, 0.1314, 0.1441, 0.1441, 0.3442, 0.3442,\n",
      "        0.1157, 0.1157, 0.1378, 0.1378, 0.3229, 0.3229, 0.0489, 0.0489, 0.1782,\n",
      "        0.1782, 0.3087, 0.3087, 0.1562, 0.1562, 0.5535, 0.5535, 0.6890, 0.6890,\n",
      "        0.6535, 0.6535, 0.6823, 0.6823, 0.5705, 0.5705, 0.3785, 0.3785, 0.4582,\n",
      "        0.4582, 0.2348, 0.2348, 0.5998, 0.5998, 0.5981, 0.5981, 0.5891, 0.5891,\n",
      "        0.3088, 0.3088, 0.5316, 0.5316, 0.6202, 0.6202, 0.3149, 0.3149, 0.6192,\n",
      "        0.6192, 0.7049, 0.7049, 0.5066, 0.5066, 0.6308, 0.6308, 0.0887, 0.0887,\n",
      "        0.0956, 0.0956, 0.1882, 0.1882, 0.1214, 0.1214, 0.3439, 0.3439, 0.9659,\n",
      "        0.9659, 0.4624, 0.4624, 0.2893, 0.2893, 0.1262, 0.1262, 0.1380, 0.1380,\n",
      "        0.4028, 0.4028, 0.1538, 0.1538, 0.0972, 0.0972, 0.3697, 0.3697, 0.1356,\n",
      "        0.1356, 0.0919, 0.0919, 0.3651, 0.3651, 0.1219, 0.1219, 0.6207, 0.6207,\n",
      "        0.2092, 0.2092, 0.1139, 0.1139, 0.3230, 0.3230, 0.9740, 0.9740, 0.4492,\n",
      "        0.4492, 0.2800, 0.2800, 0.1128, 0.1128, 0.1269, 0.1269, 0.3597, 0.3597,\n",
      "        0.1172, 0.1172, 0.1112, 0.1112, 0.3363, 0.3363, 0.0485, 0.0485, 0.1411,\n",
      "        0.1411, 0.3150, 0.3150, 0.1303, 0.1303, 0.5753, 0.5753, 0.1515, 0.1515,\n",
      "        0.2906, 0.2906, 0.9956, 0.9956, 0.4564, 0.4564, 0.1174, 0.1174, 0.1135,\n",
      "        0.1135, 0.1106, 0.1106, 0.3683, 0.3683, 0.2031, 0.2031, 0.1088, 0.1088,\n",
      "        0.3579, 0.3579, 0.1823, 0.1823, 0.0884, 0.0884, 0.2462, 0.2462, 0.0768,\n",
      "        0.0768, 0.6061, 0.6061, 0.2111, 0.2111, 0.8821, 0.8821, 0.3470, 0.3470,\n",
      "        0.1927, 0.1927, 0.0307, 0.0307, 0.0325, 0.0325, 0.2707, 0.2707, 0.0424,\n",
      "        0.0424, 0.0389, 0.0389, 0.2432, 0.2432, 0.0921, 0.0921, 0.1247, 0.1247,\n",
      "        0.2423, 0.2423, 0.0636, 0.0636, 0.4974, 0.4974, 0.7275, 0.7275, 0.1667,\n",
      "        0.1667, 0.2145, 0.2145, 0.2270, 0.2270, 0.2146, 0.2146, 0.0863, 0.0863,\n",
      "        0.1958, 0.1958, 0.2498, 0.2498, 0.0781, 0.0781, 0.2790, 0.2790, 0.3277,\n",
      "        0.3277, 0.1759, 0.1759, 0.2516, 0.2516, 0.3072, 0.3072, 0.5494, 0.5494,\n",
      "        0.9433, 0.9433, 0.9197, 0.9197, 0.9113, 0.9113, 0.7048, 0.7048, 0.8550,\n",
      "        0.8550, 0.9269, 0.9269, 0.6795, 0.6795, 0.9601, 0.9601, 1.0000, 1.0000,\n",
      "        0.9041, 0.9041, 0.9449, 0.9449, 0.5548, 0.5548, 0.3931, 0.3931, 0.3774,\n",
      "        0.3774, 0.3675, 0.3675, 0.1515, 0.1515, 0.3190, 0.3190, 0.3936, 0.3936,\n",
      "        0.1202, 0.1202, 0.4191, 0.4191, 0.4746, 0.4746, 0.3456, 0.3456, 0.4056,\n",
      "        0.4056, 0.2017, 0.2017, 0.1630, 0.1630, 0.1516, 0.1516, 0.2879, 0.2879,\n",
      "        0.2238, 0.2238, 0.1815, 0.1815, 0.2950, 0.2950, 0.2301, 0.2301, 0.2090,\n",
      "        0.2090, 0.1363, 0.1363, 0.1531, 0.1531, 0.5203, 0.5203, 0.0000, 0.0000,\n",
      "        0.2883, 0.2883, 0.0764, 0.0764, 0.0210, 0.0210, 0.2686, 0.2686, 0.0802,\n",
      "        0.0802, 0.0989, 0.0989, 0.2249, 0.2249, 0.0264, 0.0264, 0.5213, 0.5213,\n",
      "        0.2786, 0.2786, 0.0779, 0.0779, 0.0290, 0.0290, 0.2595, 0.2595, 0.0918,\n",
      "        0.0918, 0.1064, 0.1064, 0.2148, 0.2148, 0.0292, 0.0292, 0.5125, 0.5125,\n",
      "        0.2378, 0.2378, 0.3158, 0.3158, 0.0467, 0.0467, 0.3140, 0.3140, 0.3987,\n",
      "        0.3987, 0.1986, 0.1986, 0.3202, 0.3202, 0.2241, 0.2241, 0.0932, 0.0932,\n",
      "        0.2087, 0.2087, 0.0922, 0.0922, 0.1769, 0.1769, 0.2395, 0.2395, 0.1159,\n",
      "        0.1159, 0.4568, 0.4568, 0.2917, 0.2917, 0.0961, 0.0961, 0.0718, 0.0718,\n",
      "        0.2576, 0.2576, 0.0199, 0.0199, 0.5465, 0.5465, 0.2983, 0.2983, 0.3765,\n",
      "        0.3765, 0.2319, 0.2319, 0.3015, 0.3015, 0.2418, 0.2418, 0.1443, 0.1443,\n",
      "        0.2530, 0.2530, 0.1057, 0.1057, 0.5365, 0.5365, 0.3131, 0.3131, 0.0653,\n",
      "        0.0653, 0.6316, 0.6316, 0.2399, 0.2399, 0.4152, 0.4152, 0.5550, 0.5550])\n"
     ]
    }
   ],
   "source": [
    "# Convert edge_attr to a torch tensor\n",
    "edge_attr_tensor = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "# Min-Max normalization to scale the values to the range [0, 1]\n",
    "edge_attr_min = edge_attr_tensor.min()\n",
    "edge_attr_max = edge_attr_tensor.max()\n",
    "edge_attr = (edge_attr_tensor - edge_attr_min) / (edge_attr_max - edge_attr_min)\n",
    "\n",
    "# Print the normalized edge_attr tensor to verify\n",
    "print(edge_attr.shape)\n",
    "print(edge_attr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC GPU IMPORT**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to device\n",
    "edge_index = edge_index.to(device)\n",
    "edge_attr = edge_attr.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC BATCHING**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 117\n",
      "Number of full batches: 1404\n",
      "Batched input train dimensionality: torch.Size([12, 117, 27, 69])\n",
      "Batched output train dimensionality: torch.Size([12, 117, 27, 67])\n",
      "Batched input train dimensionality: torch.Size([117, 27, 69])\n",
      "Batched output train dimensionality: torch.Size([117, 27, 67])\n"
     ]
    }
   ],
   "source": [
    "batch_size = node_features_sequence_input_train.shape[0] // 8 # Adjust this value based on your GPU memory capacity\n",
    "# Calculate the number of full batches\n",
    "num_full_batches_train = (node_features_sequence_input_train.size(0) // batch_size) * batch_size\n",
    "\n",
    "# Trim the input and output tensors to have a size divisible by the batch size\n",
    "trimmed_input_train = node_features_sequence_input_train[:num_full_batches_train]\n",
    "trimmed_output_train = node_features_sequence_output_train[:num_full_batches_train]\n",
    "\n",
    "# Create batches of data\n",
    "batched_input_train = trimmed_input_train.view(-1, batch_size, trimmed_input_train.size(1), trimmed_input_train.size(2))\n",
    "batched_output_train = trimmed_output_train.view(-1, batch_size, trimmed_output_train.size(1), trimmed_output_train.size(2))\n",
    "\n",
    "# Adjust the number of batches\n",
    "num_batches_train = batched_input_train.size(0)\n",
    "\n",
    "# Print the batch size and number of full batches to verify\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"Number of full batches:\", num_full_batches_train)\n",
    "\n",
    "print(\"Batched input train dimensionality:\", batched_input_train.shape)\n",
    "print(\"Batched output train dimensionality:\", batched_output_train.shape)\n",
    "print(\"Batched input train dimensionality:\", batched_input_train[0].shape)\n",
    "print(\"Batched output train dimensionality:\", batched_output_train[0].shape)\n",
    "\n",
    "# Check for NaN or Inf in input data\n",
    "assert not torch.isnan(batched_input_train).any(), \"NaN values found in batched_input_train\"\n",
    "assert not torch.isinf(batched_input_train).any(), \"Inf values found in batched_input_train\"\n",
    "\n",
    "# Check for NaN or Inf in output data\n",
    "assert not torch.isnan(batched_output_train).any(), \"NaN values found in batched_output_train\"\n",
    "assert not torch.isinf(batched_output_train).any(), \"Inf values found in batched_output_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 88\n",
      "Number of full batches: 1404\n",
      "Batched input test dimensionality: torch.Size([4, 88, 27, 69])\n",
      "Batched output test dimensionality: torch.Size([4, 88, 27, 67])\n"
     ]
    }
   ],
   "source": [
    "batch_size = node_features_sequence_input_test.shape[0] // 4# Adjust this value based on your GPU memory capacity\n",
    "# Calculate the number of full batches\n",
    "num_full_batches_test = (node_features_sequence_input_test.size(0) // batch_size) * batch_size\n",
    "\n",
    "# Trim the input and output tensors to have a size divisible by the batch size\n",
    "trimmed_input_test = node_features_sequence_input_test[:num_full_batches_test]\n",
    "trimmed_output_test = node_features_sequence_output_test[:num_full_batches_test]\n",
    "\n",
    "# Create batches of data\n",
    "batched_input_test = trimmed_input_test.view(-1, batch_size, trimmed_input_test.size(1), trimmed_input_test.size(2))\n",
    "batched_output_test = trimmed_output_test.view(-1, batch_size, trimmed_output_test.size(1), trimmed_output_test.size(2))\n",
    "\n",
    "# Adjust the number of batches\n",
    "num_batches_test = batched_input_test.size(0)\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"Number of full batches:\", num_full_batches_train)\n",
    "\n",
    "print(\"Batched input test dimensionality:\", batched_input_test.shape)\n",
    "print(\"Batched output test dimensionality:\", batched_output_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC MODEL**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model for the hybrid model\n",
    "# Input Dimension: [batch_length ,num_nodes, num_features]\n",
    "# Output Dimension: [batch_length, num_nodes, hidden_channels]\n",
    "class TransformerModule(nn.Module):\n",
    "    def __init__(self, features_channels, out_channels, transformer_layers):\n",
    "        super(TransformerModule, self).__init__()\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=features_channels, nhead=features_channels, batch_first=True),\n",
    "            num_layers=transformer_layers\n",
    "        )\n",
    "        self.output_linear = nn.Linear(features_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        temporal_outputs = self.transformer_encoder(x)  # Shape: [num_timesteps, num_nodes, hidden_channels]\n",
    "        x = self.output_linear(temporal_outputs)  # Shape: [num_timesteps, num_nodes, out_channels]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN module for the hybrid model\n",
    "# Input Dimension: [batch_length ,num_nodes, num_features]\n",
    "# Output Dimension: [batch_length, num_nodes, hidden_channels]\n",
    "class GNNModule(torch.nn.Module):\n",
    "    def __init__(self, features_channels, hidden_channels, edge_in_channels):\n",
    "        super(GNNModule, self).__init__()\n",
    "        self.conv1 = GATv2Conv(features_channels, hidden_channels, edge_dim=edge_in_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.batch_norm1 = BatchNorm(hidden_channels)\n",
    "        self.batch_norm2 = BatchNorm(hidden_channels)\n",
    "        self.batch_norm3 = BatchNorm(hidden_channels)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "    def gnn_forward(self, x, edge_index, edge_attr):\n",
    "\n",
    "        # print(\"input\",x.shape)\n",
    "        # print(torch.isnan(x).any())\n",
    "        # print(torch.isinf(x).any())\n",
    "\n",
    "        edge_weight = 1.0 / (edge_attr + 1e-6)\n",
    "        x1 = self.conv1(x, edge_index, edge_attr=edge_weight)\n",
    "        x1 = self.batch_norm1(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "\n",
    "        # print(\"Gat\",x1.shape)\n",
    "        # print(torch.isnan(x1).any())\n",
    "        # print(torch.isinf(x1).any())\n",
    "\n",
    "        x2 = self.conv2(x1, edge_index, edge_weight=edge_attr)\n",
    "        x2 = self.batch_norm2(x2)\n",
    "        x2 = F.relu(x2)        \n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        # print(\"gnc\",x2.shape)\n",
    "        # print(torch.isnan(x2).any())\n",
    "        # print(torch.isinf(x2).any())\n",
    "\n",
    "        x3 = self.conv3(x2, edge_index)\n",
    "        x3 = self.batch_norm3(x3)\n",
    "        x3 = F.relu(x3)\n",
    "        x3 = self.dropout(x3)\n",
    "\n",
    "        # print(\"graph\",x3.shape)\n",
    "        # print(torch.isnan(x3).any())\n",
    "        # print(torch.isinf(x3).any())\n",
    "\n",
    "        x = x1 + x2 + x3  # Residual connection\n",
    "\n",
    "        # print(\"residual\",x.shape)\n",
    "        # print(torch.isnan(x).any())\n",
    "        # print(torch.isinf(x).any())\n",
    "\n",
    "        return x  # Shape: [num_nodes, hidden_channels]\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        spatial_outputs = []\n",
    "        for t in range(x.size(0)):\n",
    "            x_t = self.gnn_forward(x[t], edge_index, edge_attr)\n",
    "            spatial_outputs.append(x_t)\n",
    "\n",
    "        x = torch.stack(spatial_outputs, dim=0)  # Shape: [num_timesteps, num_nodes, hidden_channels]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid model combining the Transformer and GNN modules\n",
    "# Input Dimension: [batch_length ,num_nodes, num_features]\n",
    "# Output Dimension: [batch_length, num_nodes, out_channels]\n",
    "class HybridModel_Transformer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers):\n",
    "        super(HybridModel_Transformer, self).__init__()\n",
    "        self.transformer = TransformerModule(features_channels, hidden_channels, transformer_layers)\n",
    "        self.gnn = GNNModule(hidden_channels, hidden_channels, edge_in_channels)\n",
    "        self.output_layer = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Project the input features to the hidden dimension\n",
    "        # Transform the input features using the transformer\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # print(\"transformer forward\",x.shape)\n",
    "        # print(torch.isnan(x).any())\n",
    "        # print(torch.isinf(x).any())\n",
    "\n",
    "        # Pass the transformed features to the GNN\n",
    "        x = self.gnn(x, edge_index, edge_attr)\n",
    "\n",
    "        # print(\"gnn\",x.shape)\n",
    "        # print(torch.isnan(x).any())\n",
    "        # print(torch.isinf(x).any())\n",
    "\n",
    "        # Pass the GNN outputs through a linear layer\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel_GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers):\n",
    "        super(HybridModel_GNN, self).__init__()\n",
    "        self.gnn = GNNModule(features_channels, hidden_channels, edge_in_channels)\n",
    "        self.transformer = TransformerModule(hidden_channels, out_channels, transformer_layers)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Apply GNN first\n",
    "        x = self.gnn(x, edge_index, edge_attr)\n",
    "\n",
    "        # Apply transformer\n",
    "        x = self.transformer(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel_Parallel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers):\n",
    "        super(HybridModel_Parallel, self).__init__()\n",
    "        self.gnn = GNNModule(features_channels, hidden_channels, edge_in_channels)\n",
    "        self.transformer = TransformerModule(features_channels, hidden_channels, transformer_layers)\n",
    "        self.output_layer = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Project the input features to the hidden dimension\n",
    "        # Transform the input features using the transformer\n",
    "        x_gnn = self.gnn(x, edge_index, edge_attr)\n",
    "        x_transformer = self.transformer(x)\n",
    "\n",
    "        # Pass the transformed features to the GNN\n",
    "        x = x_gnn + x_transformer\n",
    "\n",
    "        # Pass the GNN outputs through a linear layer\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleModel_Transformer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers):\n",
    "        super(SingleModel_Transformer, self).__init__()\n",
    "        self.transformer = TransformerModule(features_channels, out_channels, transformer_layers)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Project the input features to the hidden dimension\n",
    "        # Transform the input features using the transformer\n",
    "        x = self.transformer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleModel_GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers):\n",
    "        super(SingleModel_GNN, self).__init__()\n",
    "        self.gnn = GNNModule(features_channels, hidden_channels, edge_in_channels)\n",
    "        self.output_layer = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Apply GNN first\n",
    "        x = self.gnn(x, edge_index, edge_attr)\n",
    "\n",
    "        # Apply transformer\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC MODEL SETUP**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 200\n",
      "Learning rate: 0.01\n",
      "Scheduler mode: min\n",
      "Scheduler factor: 0.8\n",
      "Scheduler patience: 5\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "num_epochs = 200  # Adjust the number of epochs as needed\n",
    "learning_rate = 0.01\n",
    "scheduler_mode = 'min'\n",
    "scheduler_factor = 0.8\n",
    "scheduler_patience = 5\n",
    "\n",
    "#Print all parameter \n",
    "print(\"Number of epochs:\", num_epochs)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "print(\"Scheduler mode:\", scheduler_mode)\n",
    "print(\"Scheduler factor:\", scheduler_factor)\n",
    "print(\"Scheduler patience:\", scheduler_patience)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC MODEL TRAIN**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, loss_fn, num_epochs, num_batches_train, batched_input_train, batched_output_train, device):\n",
    "    epoch_losses = []\n",
    "    epoch_maes = []\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_mae = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for b in range(num_batches_train):\n",
    "            # Get the batched node features and desired output\n",
    "            node_features_batch = batched_input_train[b].to(device)\n",
    "            desired_output_batch = batched_output_train[b].to(device)\n",
    "\n",
    "            # print(\"Node features batch: \", node_features_batch.shape)\n",
    "            # print(torch.isnan(node_features_batch).any())\n",
    "            # print(torch.isinf(node_features_batch).any())\n",
    "            # Forward pass with batch_size parameter\n",
    "\n",
    "            model_output_batch = model(node_features_batch, edge_index, edge_attr)\n",
    "            \n",
    "            # print(\"Model be outputing: \", model_output_batch.shape)\n",
    "            # print(torch.isnan(model_output_batch).any())\n",
    "            # print(torch.isinf(model_output_batch).any())\n",
    "\n",
    "            # print(\"Desired output: \", desired_output_batch.shape)\n",
    "            # print(torch.isnan(desired_output_batch).any())\n",
    "            # print(torch.isinf(desired_output_batch).any())\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(model_output_batch, desired_output_batch)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the optimizer\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute MAE for debugging\n",
    "            mae = torch.mean(torch.abs(model_output_batch - desired_output_batch))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_mae += mae.item()\n",
    "\n",
    "        average_loss = total_loss / num_batches_train\n",
    "        average_mae = total_mae / num_batches_train\n",
    "        epoch_losses.append(average_loss)\n",
    "        epoch_maes.append(average_mae)\n",
    "\n",
    "        scheduler.step(average_loss)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        current_patience = scheduler.num_bad_epochs\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {average_loss}, Average MAE: {average_mae}, Learning Rate: {current_lr}, Current Patience: {current_patience}\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_losses, epoch_maes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Train Toggle\n",
    "run_model_parallel = True\n",
    "run_model_transformer_gnn = True\n",
    "run_model_gnn_transformer = True\n",
    "run_model_single_transformer = True\n",
    "run_model_single_gnn = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def save_model_data(model, optimizer, scheduler, epoch_losses, epoch_maes, model_name):\n",
    "    # Create the directory if it doesn't exist\n",
    "    current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    folder_path = f'saved_models/{model_name}_{current_time}'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Save the model, optimizer, and scheduler states\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "    }, os.path.join(folder_path, f'{model_name}.pt'))\n",
    "\n",
    "    # Save epoch losses and MAEs to a CSV file\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, len(epoch_losses) + 1),\n",
    "        'loss': epoch_losses,\n",
    "        'mae': epoch_maes\n",
    "    })\n",
    "    df.to_csv(os.path.join(folder_path, f'{model_name}_metrics.csv'), index=False)\n",
    "    print(f\"Model data saved in {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Channels: 27\n",
      "Features Channels: 69\n",
      "Output Channels: 67\n",
      "Edge Input Channels: 1\n",
      "Hidden Channels: 1024\n",
      "Transformer Layers: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n",
      "/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 84.01651318868001, Average MAE: 5.26824567715327, Learning Rate: 0.01, Current Patience: 0\n",
      "Epoch 2, Average Loss: 23.363933722178142, Average MAE: 2.152394324541092, Learning Rate: 0.01, Current Patience: 0\n",
      "Epoch 3, Average Loss: 16.53970154126485, Average MAE: 1.5879664719104767, Learning Rate: 0.01, Current Patience: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if run_model_parallel:\n",
    "    # Call the function\n",
    "    # Define the parameters\n",
    "    in_channels = batched_input_train.shape[2]\n",
    "    features_channels = batched_input_train.shape[3]\n",
    "    out_channels = batched_output_train.shape[3]\n",
    "    edge_in_channels = 1\n",
    "    hidden_channels = 1024\n",
    "    transformer_layers = 8\n",
    "\n",
    "    # Print the parameters to verify\n",
    "    print(\"Input Channels:\", in_channels)\n",
    "    print(\"Features Channels:\", features_channels)\n",
    "    print(\"Output Channels:\", out_channels)\n",
    "    print(\"Edge Input Channels:\", edge_in_channels)\n",
    "    print(\"Hidden Channels:\", hidden_channels)\n",
    "    print(\"Transformer Layers:\", transformer_layers)\n",
    "\n",
    "    model_parallel = HybridModel_Parallel(in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers).to(device)\n",
    "\n",
    "    # Define the optimizer and loss function for model_parallel\n",
    "    optimizer_parallel = torch.optim.Adam(model_parallel.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler_parallel = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_parallel, mode=scheduler_mode, factor=scheduler_factor, patience=scheduler_patience, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    parallel_epoch_losses, parallel_epoch_maes = train_model(model_parallel, optimizer_parallel, scheduler_parallel, loss_fn, num_epochs, num_batches_train, batched_input_train, batched_output_train, device)\n",
    "    save_model_data(model_parallel, optimizer_parallel, scheduler_parallel, parallel_epoch_losses, parallel_epoch_maes, 'model_parallel')\n",
    "    del model_parallel\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle to run the code\n",
    "if run_model_transformer_gnn:\n",
    "    # Call the function\n",
    "    # Define the parameters\n",
    "    in_channels = batched_input_train.shape[2]\n",
    "    features_channels = batched_input_train.shape[3]\n",
    "    out_channels = batched_output_train.shape[3]  \n",
    "    edge_in_channels = 1\n",
    "    hidden_channels = 1024\n",
    "    transformer_layers = 8\n",
    "\n",
    "    # Print the parameters to verify\n",
    "    print(\"Input Channels:\", in_channels)\n",
    "    print(\"Features Channels:\", features_channels)\n",
    "    print(\"Output Channels:\", out_channels)\n",
    "    print(\"Edge Input Channels:\", edge_in_channels)\n",
    "    print(\"Hidden Channels:\", hidden_channels)\n",
    "    print(\"Transformer Layers:\", transformer_layers)\n",
    "\n",
    "    model_transformer_gnn = HybridModel_Transformer(in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers).to(device)\n",
    "\n",
    "    # Define the optimizer and loss function for model_transformer_gnn\n",
    "    optimizer_transformer_gnn = torch.optim.Adam(model_transformer_gnn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler_transformer_gnn = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_transformer_gnn, mode=scheduler_mode, factor=scheduler_factor, patience=scheduler_patience, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    transformer_gnn_epoch_losses, transformer_gnn_epoch_maes = train_model(model_transformer_gnn, optimizer_transformer_gnn, scheduler_transformer_gnn, loss_fn, num_epochs, num_batches_train, batched_input_train, batched_output_train, device)\n",
    "    save_model_data(model_transformer_gnn, optimizer_transformer_gnn, scheduler_transformer_gnn, transformer_gnn_epoch_losses, transformer_gnn_epoch_maes, 'model_transformer_gnn')\n",
    "    del model_transformer_gnn\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle to run the code\n",
    "if run_model_gnn_transformer:\n",
    "    # Define the parameters\n",
    "    in_channels = batched_input_train.shape[2]\n",
    "    features_channels = batched_input_train.shape[3]\n",
    "    out_channels = batched_output_train.shape[3]  \n",
    "    edge_in_channels = 1\n",
    "    hidden_channels = 1024\n",
    "    transformer_layers = 8\n",
    "\n",
    "    # Print the parameters to verify\n",
    "    print(\"Input Channels:\", in_channels)\n",
    "    print(\"Features Channels:\", features_channels)\n",
    "    print(\"Output Channels:\", out_channels)\n",
    "    print(\"Edge Input Channels:\", edge_in_channels)\n",
    "    print(\"Hidden Channels:\", hidden_channels)\n",
    "    print(\"Transformer Layers:\", transformer_layers)\n",
    "\n",
    "    model_gnn_transformer = HybridModel_GNN(in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers).to(device)\n",
    "\n",
    "    # Define the optimizer and loss function for model_gnn_transformer\n",
    "    optimizer_gnn_transformer = torch.optim.Adam(model_gnn_transformer.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler_gnn_transformer = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_gnn_transformer, mode=scheduler_mode, factor=scheduler_factor, patience=scheduler_patience, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    gnn_transformer_epoch_losses, gnn_transformer_epoch_maes = train_model(model_gnn_transformer, optimizer_gnn_transformer, scheduler_gnn_transformer, loss_fn, num_epochs, num_batches_train, batched_input_train, batched_output_train, device)\n",
    "    save_model_data(model_gnn_transformer, optimizer_gnn_transformer, scheduler_gnn_transformer, gnn_transformer_epoch_losses, gnn_transformer_epoch_maes, 'model_gnn_transformer')\n",
    "    del model_gnn_transformer\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_model_single_transformer:\n",
    "    # Define the parameters\n",
    "    in_channels = batched_input_train.shape[2]\n",
    "    features_channels = batched_input_train.shape[3]\n",
    "    out_channels = batched_output_train.shape[3]  \n",
    "    edge_in_channels = 1\n",
    "    hidden_channels = 1024\n",
    "    transformer_layers = 8\n",
    "\n",
    "    # Print the parameters to verify\n",
    "    print(\"Input Channels:\", in_channels)\n",
    "    print(\"Features Channels:\", features_channels)\n",
    "    print(\"Output Channels:\", out_channels)\n",
    "    print(\"Edge Input Channels:\", edge_in_channels)\n",
    "    print(\"Hidden Channels:\", hidden_channels)\n",
    "    print(\"Transformer Layers:\", transformer_layers)\n",
    "\n",
    "    model_single_transformer = SingleModel_Transformer(in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers).to(device)\n",
    "\n",
    "    # Define the optimizer and loss function for model_transformer\n",
    "    optimizer_single_transformer = torch.optim.Adam(model_single_transformer.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler_single_transformer = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_single_transformer, mode=scheduler_mode, factor=scheduler_factor, patience=scheduler_patience, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    single_transformer_epoch_losses, single_transformer_epoch_maes = train_model(model_single_transformer, optimizer_single_transformer, scheduler_single_transformer, loss_fn, num_epochs, num_batches_train, batched_input_train, batched_output_train, device)\n",
    "    save_model_data(model_single_transformer, optimizer_single_transformer, scheduler_single_transformer, single_transformer_epoch_losses, single_transformer_epoch_maes, 'model_single_transformer')\n",
    "    del model_single_transformer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_model_single_gnn:\n",
    "    torch.cuda.empty_cache()\n",
    "    # Define the parameters\n",
    "    in_channels = batched_input_train.shape[2]\n",
    "    features_channels = batched_input_train.shape[3]\n",
    "    out_channels = batched_output_train.shape[3]  \n",
    "    edge_in_channels = 1\n",
    "    hidden_channels = 1024\n",
    "    transformer_layers = 8\n",
    "\n",
    "    # Print the parameters to verify\n",
    "    print(\"Input Channels:\", in_channels)\n",
    "    print(\"Features Channels:\", features_channels)\n",
    "    print(\"Output Channels:\", out_channels)\n",
    "    print(\"Edge Input Channels:\", edge_in_channels)\n",
    "    print(\"Hidden Channels:\", hidden_channels)\n",
    "    print(\"Transformer Layers:\", transformer_layers)\n",
    "\n",
    "    model_single_gnn = SingleModel_GNN(in_channels, out_channels, features_channels, edge_in_channels, hidden_channels, transformer_layers).to(device)\n",
    "    \n",
    "    # Define the optimizer and loss function for model_gnn\n",
    "    optimizer_single_gnn = torch.optim.Adam(model_single_gnn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler_single_gnn = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_single_gnn, mode=scheduler_mode, factor=scheduler_factor, patience=scheduler_patience, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    single_gnn_epoch_losses, single_gnn_epoch_maes = train_model(model_single_gnn, optimizer_single_gnn, scheduler_single_gnn, loss_fn, num_epochs, num_batches_train, batched_input_train, batched_output_train, device)\n",
    "    save_model_data(model_single_gnn, optimizer_single_gnn, scheduler_single_gnn, single_gnn_epoch_losses, single_gnn_epoch_maes, 'model_single_gnn')\n",
    "    del model_single_gnn\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">**ZE EPIC GRAPHS**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of each variable\n",
    "print(\"Shape of gnn_transformer_epoch_losses:\", np.shape(gnn_transformer_epoch_losses))\n",
    "print(\"Shape of gnn_transformer_epoch_maes:\", np.shape(gnn_transformer_epoch_maes))\n",
    "print(\"Shape of transformer_gnn_epoch_losses:\", np.shape(transformer_gnn_epoch_losses))\n",
    "print(\"Shape of transformer_gnn_epoch_maes:\", np.shape(transformer_gnn_epoch_maes))\n",
    "print(\"Shape of single_gnn_epoch_losses:\", np.shape(single_gnn_epoch_losses))\n",
    "print(\"Shape of single_gnn_epoch_maes:\", np.shape(single_gnn_epoch_maes))\n",
    "print(\"Shape of single_transformer_epoch_losses:\", np.shape(single_transformer_epoch_losses))\n",
    "print(\"Shape of single_transformer_epoch_maes:\", np.shape(single_transformer_epoch_maes))\n",
    "# print(\"Shape of parallel_epoch_losses:\", np.shape(parallel_epoch_losses))\n",
    "# print(\"Shape of parallel_epoch_maes:\", np.shape(parallel_epoch_maes))\n",
    "\n",
    "# Flatten all arrays\n",
    "gnn_transformer_epoch_losses = np.array(gnn_transformer_epoch_losses).flatten()\n",
    "gnn_transformer_epoch_maes = np.array(gnn_transformer_epoch_maes).flatten()\n",
    "transformer_gnn_epoch_losses = np.array(transformer_gnn_epoch_losses).flatten()\n",
    "transformer_gnn_epoch_maes = np.array(transformer_gnn_epoch_maes).flatten()\n",
    "single_gnn_epoch_losses = np.array(single_gnn_epoch_losses).flatten()\n",
    "single_gnn_epoch_maes = np.array(single_gnn_epoch_maes).flatten()\n",
    "single_transformer_epoch_losses = np.array(single_transformer_epoch_losses).flatten()\n",
    "single_transformer_epoch_maes = np.array(single_transformer_epoch_maes).flatten()\n",
    "# parallel_epoch_losses = np.array(parallel_epoch_losses).flatten()\n",
    "# parallel_epoch_maes = np.array(parallel_epoch_maes).flatten()\n",
    "\n",
    "\n",
    "# Plotting the epoch losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(gnn_transformer_epoch_losses, label='GNN Transformer Loss')\n",
    "plt.plot(transformer_gnn_epoch_losses, label='Transformer GNN Loss')\n",
    "plt.plot(single_gnn_epoch_losses, label='GNN Loss')\n",
    "plt.plot(single_transformer_epoch_losses, label='Transformer Loss')\n",
    "# plt.plot(parallel_epoch_losses, label='Parallel Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch Losses')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the epoch MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(gnn_transformer_epoch_maes, label='GNN Transformer MAE')\n",
    "plt.plot(transformer_gnn_epoch_maes, label='Transformer GNN MAE')\n",
    "plt.plot(single_gnn_epoch_maes, label='GNN MAE')\n",
    "plt.plot(single_transformer_epoch_maes, label='Transformer MAE')\n",
    "# plt.plot(parallel_epoch_maes, label='Parallel MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Epoch MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loss_fn, num_batches_test, batched_input_test, batched_output_test, device):\n",
    "    model.eval()\n",
    "    # Initialize lists to store losses and MAEs\n",
    "    test_losses = []\n",
    "    test_maes = []\n",
    "\n",
    "    test_losses_per_matrix = []\n",
    "    test_maes_per_matrix = []\n",
    "\n",
    "    # Disable gradient calculation for evaluation\n",
    "    with torch.no_grad():\n",
    "        for b in range(num_batches_test):\n",
    "            # Get the batched node features and desired output\n",
    "            node_features_batch = batched_input_test[b].to(device)\n",
    "            desired_output_batch = batched_output_test[b].to(device)\n",
    "            \n",
    "            # Reshape node_features_batch to match the expected input shape for the model\n",
    "            node_features_batch = node_features_batch.view(-1, node_features_batch.size(2))\n",
    "            \n",
    "            # Get the model output\n",
    "            model_output_batch = model(node_features_batch, edge_index, edge_attr)\n",
    "            \n",
    "            # Reshape model_output_batch back to the original shape\n",
    "            model_output_batch = model_output_batch.view(batched_input_test.size(1), -1, model_output_batch.size(1))\n",
    "            \n",
    "            # Compute loss and MAE\n",
    "            loss = loss_fn(model_output_batch, desired_output_batch)\n",
    "            mae = torch.mean(torch.abs(model_output_batch - desired_output_batch))\n",
    "            \n",
    "            # Store the loss and MAE\n",
    "            test_losses.append(loss.item())\n",
    "            test_maes.append(mae.item())\n",
    "\n",
    "            print(f\"Batch {b+1} - Model Output and Desired Output Matrices:\")\n",
    "            model_output_np = model_output_batch.cpu().numpy()\n",
    "            desired_output_np = desired_output_batch.cpu().numpy()\n",
    "\n",
    "            for i in range(model_output_np.shape[0]):\n",
    "                print()\n",
    "                print(f\"Model Output Matrix {i+1}:\")\n",
    "                np.set_printoptions(formatter={'float_kind':lambda x: \"%.4f\" % x})\n",
    "                print(model_output_np[i])\n",
    "                print(f\"Desired Output Matrix {i+1}:\")\n",
    "                print(desired_output_np[i])\n",
    "                \n",
    "                # Calculate loss and MAE for each matrix\n",
    "                matrix_loss = loss_fn(torch.tensor(model_output_np[i], device=device), torch.tensor(desired_output_np[i], device=device))\n",
    "                matrix_mae = torch.mean(torch.abs(torch.tensor(model_output_np[i], device=device) - torch.tensor(desired_output_np[i], device=device)))\n",
    "                print(f\"Loss for Matrix {i+1}: {matrix_loss.item()}\")\n",
    "                print(f\"MAE for Matrix {i+1}: {matrix_mae.item()}\")\n",
    "\n",
    "                test_losses_per_matrix.append(matrix_loss.item())\n",
    "                test_maes_per_matrix.append(matrix_mae.item())\n",
    "\n",
    "    # Print the average loss and MAE for the test set\n",
    "    average_test_loss = sum(test_losses) / len(test_losses)\n",
    "    average_test_mae = sum(test_maes) / len(test_maes)\n",
    "    print(f\"Average Test Loss: {average_test_loss}, Average Test MAE: {average_test_mae}\")\n",
    "\n",
    "    return test_losses, test_maes, test_losses_per_matrix, test_maes_per_matrix, average_test_loss, average_test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluate_model(model_gnn_transformer, loss_fn, num_batches_test, batched_input_test, batched_output_test, device)\n",
    "evaluate_model(model_transformer_gnn, loss_fn, num_batches_test, batched_input_test, batched_output_test, device)\n",
    "evaluate_model(model_parallel, loss_fn, num_batches_test, batched_input_test, batched_output_test, device)\n",
    "evaluate_model(model_single_transformer, loss_fn, num_batches_test, batched_input_test, batched_output_test, device)\n",
    "evaluate_model(model_single_gnn, loss_fn, num_batches_test, batched_input_test, batched_output_test, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
