{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([72790024141, 72785524114, 72789094197, 72793024233, 72785794129, 72220804224, 72788594266, 72797624217, 72797094240, 72027294282, 72798594276, 72792424223, 74207124201, 72792894263, 72781024243, 72698824219, 74206024207, 72782724110, 72793724222, 72782594239, 72794504205, 72792024227, 72025400119])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = '../draft-final-data'\n",
    "\n",
    "# Dictionary to store the dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the file name without extension and convert it to int\n",
    "        key = int(os.path.splitext(filename)[0])\n",
    "        \n",
    "        # Read the CSV file into a dataframe\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        # Drop columns that contain non-numerical data\n",
    "        df = df.select_dtypes(include=[np.number])\n",
    "        \n",
    "        # Check if the dataframe has 13 columns\n",
    "        if df.shape[1] == 13:\n",
    "            # Store the dataframe in the dictionary\n",
    "            dataframes[key] = df\n",
    "\n",
    "# Print the dictionary keys to verify\n",
    "print(dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNNWithEdgeFeatures(torch.nn.Module):\n",
    "    def __init__(self, in_channels, edge_in_channels, hidden_channels, out_channels):\n",
    "        super(GNNWithEdgeFeatures, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)  # Additional hidden layer\n",
    "        self.edge_mlp = torch.nn.Linear(edge_in_channels, hidden_channels)\n",
    "        self.output_layer = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Apply the edge MLP to the edge features\n",
    "        edge_features = self.edge_mlp(edge_attr)\n",
    "        \n",
    "        # Apply the first GCN convolution\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Apply the second GCN convolution\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Combine node and edge features (this is a simple example, you might want to use a more complex method)\n",
    "        x = x + edge_features.mean(dim=0)\n",
    "        \n",
    "        # Apply the output layer\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with key 72790024141 has 13 columns.\n",
      "DataFrame with key 72785524114 has 13 columns.\n",
      "DataFrame with key 72789094197 has 13 columns.\n",
      "DataFrame with key 72793024233 has 13 columns.\n",
      "DataFrame with key 72785794129 has 13 columns.\n",
      "DataFrame with key 72220804224 has 13 columns.\n",
      "DataFrame with key 72788594266 has 13 columns.\n",
      "DataFrame with key 72797624217 has 13 columns.\n",
      "DataFrame with key 72797094240 has 13 columns.\n",
      "DataFrame with key 72027294282 has 13 columns.\n",
      "DataFrame with key 72798594276 has 13 columns.\n",
      "DataFrame with key 72792424223 has 13 columns.\n",
      "DataFrame with key 74207124201 has 13 columns.\n",
      "DataFrame with key 72792894263 has 13 columns.\n",
      "DataFrame with key 72781024243 has 13 columns.\n",
      "DataFrame with key 72698824219 has 13 columns.\n",
      "DataFrame with key 74206024207 has 13 columns.\n",
      "DataFrame with key 72782724110 has 13 columns.\n",
      "DataFrame with key 72793724222 has 13 columns.\n",
      "DataFrame with key 72782594239 has 13 columns.\n",
      "DataFrame with key 72794504205 has 13 columns.\n",
      "DataFrame with key 72792024227 has 13 columns.\n",
      "DataFrame with key 72025400119 has 13 columns.\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes.items():\n",
    "    print(f\"DataFrame with key {key} has {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with key 72790024141 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72785524114 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindDirection          0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72789094197 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          6\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72793024233 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72785794129 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72220804224 null values:\n",
      "STATION                       0\n",
      "DailyAltimeterSetting         0\n",
      "DailyDewPointTemperature      0\n",
      "DailyDryBulbTemperature       0\n",
      "DailyPrecipitation            0\n",
      "DailyPressureChange         666\n",
      "DailyPressureTendency       666\n",
      "DailyRelativeHumidity         0\n",
      "DailySeaLevelPressure       666\n",
      "DailyStationPressure          0\n",
      "DailyVisibility               0\n",
      "DailyWetBulbTemperature       0\n",
      "DailyWindSpeed                0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72788594266 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72797624217 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72797094240 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72027294282 null values:\n",
      "STATION                       0\n",
      "DailyAltimeterSetting         0\n",
      "DailyDewPointTemperature      0\n",
      "DailyDryBulbTemperature       0\n",
      "DailyPrecipitation            0\n",
      "DailyPressureChange         666\n",
      "DailyPressureTendency       666\n",
      "DailyRelativeHumidity         0\n",
      "DailySeaLevelPressure       666\n",
      "DailyStationPressure          0\n",
      "DailyVisibility               0\n",
      "DailyWetBulbTemperature       0\n",
      "DailyWindSpeed                0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72798594276 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          1\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72792424223 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 74207124201 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindDirection          0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72792894263 null values:\n",
      "STATION                     1\n",
      "DailyAltimeterSetting       1\n",
      "DailyDewPointTemperature    1\n",
      "DailyDryBulbTemperature     1\n",
      "DailyPressureChange         1\n",
      "DailyPressureTendency       1\n",
      "DailyRelativeHumidity       1\n",
      "DailySeaLevelPressure       1\n",
      "DailyStationPressure        1\n",
      "DailyVisibility             1\n",
      "DailyWetBulbTemperature     1\n",
      "DailyWindGustSpeed          1\n",
      "DailyWindSpeed              1\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72781024243 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72698824219 null values:\n",
      "STATION                     1\n",
      "DailyAltimeterSetting       1\n",
      "DailyDewPointTemperature    1\n",
      "DailyDryBulbTemperature     1\n",
      "DailyPressureChange         1\n",
      "DailyPressureTendency       1\n",
      "DailyRelativeHumidity       1\n",
      "DailySeaLevelPressure       1\n",
      "DailyStationPressure        1\n",
      "DailyVisibility             1\n",
      "DailyWetBulbTemperature     1\n",
      "DailyWindGustSpeed          4\n",
      "DailyWindSpeed              1\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 74206024207 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindDirection          0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72782724110 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72793724222 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72782594239 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72794504205 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72792024227 null values:\n",
      "STATION                     0\n",
      "DailyAltimeterSetting       0\n",
      "DailyDewPointTemperature    0\n",
      "DailyDryBulbTemperature     0\n",
      "DailyPressureChange         0\n",
      "DailyPressureTendency       0\n",
      "DailyRelativeHumidity       0\n",
      "DailySeaLevelPressure       0\n",
      "DailyStationPressure        0\n",
      "DailyVisibility             0\n",
      "DailyWetBulbTemperature     0\n",
      "DailyWindGustSpeed          0\n",
      "DailyWindSpeed              0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame with key 72025400119 null values:\n",
      "STATION                       0\n",
      "DailyAltimeterSetting         0\n",
      "DailyDewPointTemperature      0\n",
      "DailyDryBulbTemperature       0\n",
      "DailyPrecipitation          666\n",
      "DailyPressureChange         666\n",
      "DailyPressureTendency       666\n",
      "DailyRelativeHumidity         0\n",
      "DailySeaLevelPressure       666\n",
      "DailyStationPressure          0\n",
      "DailyVisibility               0\n",
      "DailyWetBulbTemperature       0\n",
      "DailyWindSpeed                0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in each dataframe\n",
    "for key, df in dataframes.items():\n",
    "    null_values = df.isnull().sum()\n",
    "    print(f\"DataFrame with key {key} null values:\\n{null_values}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([72790024141, 72785524114, 72793024233, 72785794129, 72788594266, 72797624217, 72797094240, 72792424223, 74207124201, 72781024243, 74206024207, 72782724110, 72793724222, 72782594239, 72794504205, 72792024227])\n"
     ]
    }
   ],
   "source": [
    "# Drop any dataframe with null values\n",
    "dataframes = {key: df for key, df in dataframes.items() if not df.isnull().values.any()}\n",
    "\n",
    "# Print the keys of the remaining dataframes to verify\n",
    "print(dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 16\n",
      "Number of edges: 120\n"
     ]
    }
   ],
   "source": [
    "num_nodes = len(dataframes)\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "# Calculate the number of edges if every node is connected to every other node\n",
    "num_edges = num_nodes * (num_nodes - 1) // 2\n",
    "print(f\"Number of edges: {num_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,\n",
      "          5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,\n",
      "          7,  7,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
      "         10, 10, 11, 11, 11, 11, 12, 12, 12, 13, 13, 14],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,  2,  3,  4,\n",
      "          5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,  3,  4,  5,  6,  7,  8,  9,\n",
      "         10, 11, 12, 13, 14, 15,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
      "          5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,  6,  7,  8,  9, 10, 11, 12,\n",
      "         13, 14, 15,  7,  8,  9, 10, 11, 12, 13, 14, 15,  8,  9, 10, 11, 12, 13,\n",
      "         14, 15,  9, 10, 11, 12, 13, 14, 15, 10, 11, 12, 13, 14, 15, 11, 12, 13,\n",
      "         14, 15, 12, 13, 14, 15, 13, 14, 15, 14, 15, 15]])\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "\n",
    "# Generate all possible pairs of nodes\n",
    "edge_index = torch.tensor(list(itertools.combinations(range(num_nodes), 2)), dtype=torch.long).t()\n",
    "\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([72790024141, 72785524114, 72793024233, 72785794129, 72788594266, 72797624217, 72797094240, 72792424223, 74207124201, 72781024243, 74206024207, 72782724110, 72793724222, 72782594239, 72794504205, 72792024227])\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the split dataframes\n",
    "split_dataframes = {}\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    # Calculate the split index\n",
    "    split_index = int(len(df) * 0.8)\n",
    "    \n",
    "    # Split the dataframe\n",
    "    train_df = df.iloc[:split_index]\n",
    "    test_df = df.iloc[split_index:]\n",
    "    \n",
    "    # Store the split dataframes in the dictionary\n",
    "    split_dataframes[key] = {'train': train_df, 'test': test_df}\n",
    "\n",
    "# Print the keys of the split dataframes to verify\n",
    "print(split_dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([72790024141, 72785524114, 72793024233, 72785794129, 72788594266, 72797624217, 72797094240, 72792424223, 74207124201, 72781024243, 74206024207, 72782724110, 72793724222, 72782594239, 72794504205, 72792024227])\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the train dataframes for each node\n",
    "node_train_dataframes = {}\n",
    "\n",
    "# Iterate over the split_dataframes and assign the train_df to each node\n",
    "for key, split_df in split_dataframes.items():\n",
    "    node_train_dataframes[key] = split_df['train']\n",
    "\n",
    "# Print the keys of the node_train_dataframes to verify\n",
    "print(node_train_dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels: 13, out_channels: 13, edge_in_channels: 1\n"
     ]
    }
   ],
   "source": [
    "# Assign in_channels and out_channels as the number of columns in the dataframe\n",
    "in_channels = 13\n",
    "# Assign edge_in_channels as the number of connections to every other dataframe\n",
    "edge_in_channels = 1\n",
    "hidden_channels = 128  # Number of hidden features\n",
    "out_channels = in_channels  # Number of output features per node\n",
    "\n",
    "print(f\"in_channels: {in_channels}, out_channels: {out_channels}, edge_in_channels: {edge_in_channels}\")\n",
    "# Initialize the GNN model with edge features\n",
    "gnn = GNNWithEdgeFeatures(in_channels, edge_in_channels, hidden_channels, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        STATION  LONGITUDE  LATITUDE  ELEVATION\n",
      "0  7.279372e+10 -122.28308  47.92322      167.1\n",
      "1  7.278462e+10 -118.28572  46.09456      356.7\n",
      "2  7.420712e+10 -122.58333  47.08333       91.4\n",
      "3  7.279762e+10 -122.54069  48.79910       45.9\n",
      "4  7.279239e+10 -123.93074  46.97288        4.5\n"
     ]
    }
   ],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Import the location-datamap.csv file as a dataframe\n",
    "location_datamap_df = pd.read_csv('../location-datamap.csv')\n",
    "\n",
    "# Print the first few rows of the dataframe to verify\n",
    "print(location_datamap_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2, el1=0, el2=0):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Difference in coordinates\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Haversine formula\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "\n",
    "    # Elevation difference\n",
    "    height = el2 - el1\n",
    "\n",
    "    # Calculate the total distance considering elevation\n",
    "    total_distance = sqrt(distance**2 + height**2)\n",
    "\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): 395.4679457314314, (0, 2): 342.5330553210191, (0, 3): 438.10430559873856, (0, 4): 432.0504921333856, (0, 5): 437.11321302131137, (0, 6): 503.7031148557305, (0, 7): 474.59654599988056, (0, 8): 372.6269101788848, (0, 9): 128.6980383337319, (0, 10): 362.1843030623904, (0, 11): 32.53657446575969, (0, 12): 306.4908073667999, (0, 13): 52.81240627430448, (0, 14): 404.8085057270694, (0, 15): 412.6227567328569, (1, 2): 727.6917541369755, (1, 3): 109.85904921372176, (1, 4): 798.995937782049, (1, 5): 802.4581375032445, (1, 6): 865.1737430163511, (1, 7): 860.6728795779842, (1, 8): 758.7243205326865, (1, 9): 495.92270395996894, (1, 10): 748.5486591666476, (1, 11): 416.12981588895354, (1, 12): 678.7815012654146, (1, 13): 419.79175595055284, (1, 14): 786.18443118649, (1, 15): 798.318691116012, (2, 3): 775.0588941479449, (2, 4): 120.26611512741678, (2, 5): 165.52848353942377, (2, 6): 185.28412975619443, (2, 7): 187.27787071696568, (2, 8): 49.712417563568934, (2, 9): 266.9618608270944, (2, 10): 37.9895765777111, (2, 11): 333.6917238582668, (2, 12): 76.27723241526142, (2, 13): 309.0749255571238, (2, 14): 107.09860018045799, (2, 15): 85.99186556469607, (3, 4): 856.701667766572, (3, 5): 865.4792367557994, (3, 6): 921.4842980890041, (3, 7): 890.5893542480043, (3, 8): 801.3070411143229, (3, 9): 524.6337306289196, (3, 10): 791.9148221844617, (3, 11): 454.1201925958629, (3, 12): 734.2694292819892, (3, 13): 467.37603414879794, (3, 14): 840.9110561664348, (3, 15): 839.7968409183139, (4, 5): 110.15242913456197, (4, 6): 85.13925057078639, (4, 7): 240.43942234567194, (4, 8): 134.89270214205223, (4, 9): 369.69695959787833, (4, 10): 133.34207595548997, (4, 11): 428.7153028579556, (4, 12): 125.7282441840991, (4, 13): 392.60154297249403, (4, 14): 108.31645122446824, (4, 15): 137.25092367847324, (5, 6): 177.46961023734613, (5, 7): 302.0846527899822, (5, 8): 196.16120952562224, (5, 9): 399.97805818217563, (5, 10): 190.70446482220075, (5, 11): 431.096161984872, (5, 12): 156.64330089805705, (5, 13): 405.4909815288361, (5, 14): 76.4859126118275, (5, 15): 205.33116784821942, (6, 7): 243.7073144688935, (6, 8): 179.49530267807492, (6, 9): 430.6615227573649, (6, 10): 183.39281681071296, (6, 11): 501.4584011725272, (6, 12): 202.41419212127153, (6, 13): 461.61393826175714, (6, 14): 180.6112148305096, (6, 15): 164.101942102309, (7, 8): 139.25732991564092, (7, 9): 366.6429361022303, (7, 10): 150.49523188191975, (7, 11): 459.96707604415764, (7, 12): 261.56576121699044, (7, 13): 447.531376407682, (7, 14): 236.6757463314917, (7, 15): 109.93432994721853, (8, 9): 283.44312292165955, (8, 10): 12.53419119171894, (8, 11): 362.54715700430546, (8, 12): 122.31559896763046, (8, 13): 339.7198100156352, (8, 14): 133.490798105978, (8, 15): 40.902158523632544, (9, 10): 275.46064771106325, (9, 11): 121.40670159689395, (9, 12): 252.86361822595595, (9, 13): 111.45482222908821, (9, 14): 352.74223587837065, (9, 15): 319.85603194172165, (10, 11): 352.2158347034709, (10, 12): 111.26188855442645, (10, 13): 329.3368670529716, (10, 14): 128.01154758942099, (10, 15): 52.80087090274467, (11, 12): 303.31516235822005, (11, 13): 73.74026824660453, (11, 14): 394.74559894207687, (11, 15): 402.1731282608459, (12, 13): 268.31498195846285, (12, 14): 128.38153131965652, (12, 15): 156.88223261226412, (13, 14): 375.88513957717953, (13, 15): 379.7335338263519, (14, 15): 144.61575947894278}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the distances between nodes\n",
    "distances = {}\n",
    "\n",
    "# Iterate over each pair of nodes\n",
    "for i, j in itertools.combinations(range(num_nodes), 2):\n",
    "    # Get the station IDs for the nodes\n",
    "    station_i = list(dataframes.keys())[i]\n",
    "    station_j = list(dataframes.keys())[j]\n",
    "    \n",
    "    # Get the location data for the stations\n",
    "    location_i = location_datamap_df[location_datamap_df['STATION'] == station_i].iloc[0]\n",
    "    location_j = location_datamap_df[location_datamap_df['STATION'] == station_j].iloc[0]\n",
    "    \n",
    "    # Calculate the distance between the stations\n",
    "    distance = haversine_distance(location_i['LATITUDE'], location_i['LONGITUDE'], location_j['LATITUDE'], location_j['LONGITUDE'], location_i['ELEVATION'], location_j['ELEVATION'])\n",
    "    \n",
    "    # Store the distance in the dictionary\n",
    "    distances[(i, j)] = distance\n",
    "\n",
    "# Print the distances to verify\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create edge index and edge attributes from distances dictionary\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "\n",
    "for (i, j), distance in distances.items():\n",
    "    edge_index.append([i, j])\n",
    "    edge_index.append([j, i])  # Assuming undirected graph\n",
    "    edge_attr.append([distance])\n",
    "    edge_attr.append([distance])  # Assuming undirected graph\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 4.058255900562151e+20\n",
      "Epoch 2, Average Loss: 4.058255900562151e+20\n",
      "Epoch 3, Average Loss: 4.058255900562151e+20\n",
      "Epoch 4, Average Loss: 4.058255900562151e+20\n",
      "Epoch 5, Average Loss: 4.058255900562151e+20\n",
      "Epoch 6, Average Loss: 4.058255900562151e+20\n",
      "Epoch 7, Average Loss: 4.058255900562151e+20\n",
      "Epoch 8, Average Loss: 4.058255900562151e+20\n",
      "Epoch 9, Average Loss: 4.058255900562151e+20\n",
      "Epoch 10, Average Loss: 4.058255900562151e+20\n",
      "Epoch 11, Average Loss: 4.058255900562151e+20\n",
      "Epoch 12, Average Loss: 4.058255900562151e+20\n",
      "Epoch 13, Average Loss: 4.058255900562151e+20\n",
      "Epoch 14, Average Loss: 4.058255900562151e+20\n",
      "Epoch 15, Average Loss: 4.058255900562151e+20\n",
      "Epoch 16, Average Loss: 4.058255900562151e+20\n",
      "Epoch 17, Average Loss: 4.058255900562151e+20\n",
      "Epoch 18, Average Loss: 4.058255900562151e+20\n",
      "Epoch 19, Average Loss: 4.058255900562151e+20\n",
      "Epoch 20, Average Loss: 4.058255900562151e+20\n",
      "Epoch 21, Average Loss: 4.058255900562151e+20\n",
      "Epoch 22, Average Loss: 4.058255900562151e+20\n",
      "Epoch 23, Average Loss: 4.058255900562151e+20\n",
      "Epoch 24, Average Loss: 4.058255900562151e+20\n",
      "Epoch 25, Average Loss: 4.058255900562151e+20\n",
      "Epoch 26, Average Loss: 4.058255900562151e+20\n",
      "Epoch 27, Average Loss: 4.058255900562151e+20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m target \u001b[38;5;241m=\u001b[39m node_features_future_sequence[t]  \u001b[38;5;66;03m# Shape: [num_nodes, num_features]\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n",
      "File \u001b[0;32m/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[36], line 22\u001b[0m, in \u001b[0;36mGNNWithEdgeFeatures.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Apply the second GCN convolution\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Combine node and edge features (this is a simple example, you might want to use a more complex method)\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m/mnt/HDD/RyanFolder/projects/Weather-Predition-Project/.venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:110\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m deg \u001b[38;5;241m=\u001b[39m scatter(edge_weight, idx, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dim_size\u001b[38;5;241m=\u001b[39mnum_nodes, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    109\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m--> 110\u001b[0m \u001b[43mdeg_inv_sqrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeg_inv_sqrt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m edge_weight \u001b[38;5;241m=\u001b[39m deg_inv_sqrt[row] \u001b[38;5;241m*\u001b[39m edge_weight \u001b[38;5;241m*\u001b[39m deg_inv_sqrt[col]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_weight\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare the list of dataframes from node_train_dataframes\n",
    "dataframe_list = list(node_train_dataframes.values())\n",
    "\n",
    "# Find the minimum length among all dataframes to align time steps\n",
    "min_length = min(df.shape[0] for df in dataframe_list)\n",
    "\n",
    "# Truncate dataframes to the minimum length\n",
    "truncated_dataframes = [df.iloc[:min_length] for df in dataframe_list]\n",
    "\n",
    "# Convert dataframes to tensors, selecting only numerical columns and filling NaN values with 0\n",
    "node_features_sequence = torch.stack(\n",
    "    [torch.tensor(df.select_dtypes(include=[np.number]).fillna(0).values, dtype=torch.float) for df in truncated_dataframes],\n",
    "    dim=1  # Stack along a new dimension for nodes\n",
    ")  # Shape: [time_steps, num_nodes, num_features]\n",
    "\n",
    "# Prepare the target by shifting node_features_sequence by one time step\n",
    "node_features_future_sequence = node_features_sequence[1:]  # Shape: [time_steps - 1, num_nodes, num_features]\n",
    "node_features_sequence = node_features_sequence[:-1]  # Align with target\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(gnn.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200  # Adjust the number of epochs as needed\n",
    "time_steps = node_features_sequence.shape[0]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for t in range(time_steps):\n",
    "        gnn.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get the node features at current time step\n",
    "        node_features = node_features_sequence[t]  # Shape: [num_nodes, num_features]\n",
    "        target = node_features_future_sequence[t]  # Shape: [num_nodes, num_features]\n",
    "        \n",
    "        # Forward pass\n",
    "        output = gnn(node_features, edge_index, edge_attr)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(output, target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    average_loss = total_loss / time_steps\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {average_loss}\")\n",
    "\n",
    "# After training, you can make predictions\n",
    "gnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 features:\n",
      "tensor([ 7.2820e+10, -4.8418e+07, -3.1947e+07,  2.0847e+07,  4.2840e+07,\n",
      "         8.8175e+05, -2.7285e+07, -5.3300e+07,  4.3184e+07,  6.4392e+07,\n",
      "        -2.8386e+06, -3.6995e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 1 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8226e+05, -2.7284e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8388e+06, -3.6994e+07,  3.9369e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 2 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8244e+05, -2.7285e+07, -5.3301e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8385e+06, -3.6995e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 3 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8123e+05, -2.7285e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8391e+06, -3.6995e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 4 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0848e+07,  4.2838e+07,\n",
      "         8.8136e+05, -2.7285e+07, -5.3301e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8388e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 5 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2838e+07,\n",
      "         8.8123e+05, -2.7285e+07, -5.3301e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8393e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 6 features:\n",
      "tensor([ 7.2820e+10, -4.8418e+07, -3.1946e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8168e+05, -2.7284e+07, -5.3301e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8386e+06, -3.6995e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 7 features:\n",
      "tensor([ 7.2820e+10, -4.8418e+07, -3.1947e+07,  2.0847e+07,  4.2838e+07,\n",
      "         8.8141e+05, -2.7285e+07, -5.3301e+07,  4.3184e+07,  6.4392e+07,\n",
      "        -2.8386e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 8 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2838e+07,\n",
      "         8.8123e+05, -2.7285e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8395e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 9 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1946e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8167e+05, -2.7285e+07, -5.3300e+07,  4.3184e+07,  6.4392e+07,\n",
      "        -2.8390e+06, -3.6994e+07,  3.9367e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 10 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1948e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8167e+05, -2.7285e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8387e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 11 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1948e+07,  2.0848e+07,  4.2837e+07,\n",
      "         8.8149e+05, -2.7285e+07, -5.3300e+07,  4.3183e+07,  6.4391e+07,\n",
      "        -2.8386e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 12 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1948e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8239e+05, -2.7285e+07, -5.3300e+07,  4.3183e+07,  6.4391e+07,\n",
      "        -2.8386e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 13 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0848e+07,  4.2838e+07,\n",
      "         8.8218e+05, -2.7284e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8386e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 14 features:\n",
      "tensor([ 7.2820e+10, -4.8418e+07, -3.1947e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8167e+05, -2.7285e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8382e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 15 features:\n",
      "tensor([ 7.2820e+10, -4.8418e+07, -3.1947e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8186e+05, -2.7284e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8392e+06, -3.6995e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 16 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8175e+05, -2.7285e+07, -5.3300e+07,  4.3184e+07,  6.4392e+07,\n",
      "        -2.8381e+06, -3.6995e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 17 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2838e+07,\n",
      "         8.8180e+05, -2.7285e+07, -5.3300e+07,  4.3184e+07,  6.4392e+07,\n",
      "        -2.8382e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 18 features:\n",
      "tensor([ 7.2820e+10, -4.8418e+07, -3.1947e+07,  2.0848e+07,  4.2838e+07,\n",
      "         8.8167e+05, -2.7284e+07, -5.3300e+07,  4.3183e+07,  6.4392e+07,\n",
      "        -2.8381e+06, -3.6994e+07,  3.9369e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 19 features:\n",
      "tensor([ 7.2820e+10, -4.8418e+07, -3.1947e+07,  2.0847e+07,  4.2838e+07,\n",
      "         8.8186e+05, -2.7285e+07, -5.3300e+07,  4.3184e+07,  6.4392e+07,\n",
      "        -2.8390e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 20 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2838e+07,\n",
      "         8.8175e+05, -2.7285e+07, -5.3299e+07,  4.3184e+07,  6.4391e+07,\n",
      "        -2.8386e+06, -3.6994e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 21 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1947e+07,  2.0847e+07,  4.2838e+07,\n",
      "         8.8200e+05, -2.7284e+07, -5.3300e+07,  4.3184e+07,  6.4391e+07,\n",
      "        -2.8384e+06, -3.6995e+07,  3.9368e+07], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Node 22 features:\n",
      "tensor([ 7.2820e+10, -4.8417e+07, -3.1948e+07,  2.0847e+07,  4.2839e+07,\n",
      "         8.8175e+05, -2.7284e+07, -5.3300e+07,  4.3184e+07,  6.4391e+07,\n",
      "        -2.8386e+06, -3.6994e+07,  3.9367e+07], grad_fn=<UnbindBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the feature of each node\n",
    "for i, features in enumerate(output):\n",
    "    print(f\"Node {i} features:\\n{features}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
